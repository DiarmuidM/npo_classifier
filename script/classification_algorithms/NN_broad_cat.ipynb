{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- [x] Build NTEE-10 major groups.\n",
    "- [x] Vectorize output labels.\n",
    "- [x] Vectorize input texts.\n",
    "- [x] Spell check.\n",
    "- [ ] Add more records of 'VI' (International, Foreign Affairs - Q).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# Check GPU device.\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "# Specify GPU to use. \n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"; \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/\n",
    "#https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "#RNN\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# For encoding labels.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code as 10 major groups.\n",
    "major_group_dict={'I': ['A'],\n",
    "                  'II': ['B'],\n",
    "                  'III': ['C', 'D'],\n",
    "                  'IV': ['E', 'F', 'G', 'H'],\n",
    "                  'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                  'VI': ['Q'],\n",
    "                  'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                  'VIII': ['X'],\n",
    "                  'IX': ['Y'],\n",
    "                  'X': ['Z'],\n",
    "                 }\n",
    "def ntee2major(string):\n",
    "    global major_group_dict\n",
    "    return [s for s in major_group_dict.keys() if string in major_group_dict[s]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229472, 25, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list=os.listdir('../../dataset/df_train.pkl.gz/')\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, \n",
    "                        pd.read_pickle('../../dataset/df_train.pkl.gz/'+file, compression='gzip')])\n",
    "df_train['mission_prgrm']=df_train['mission']+'; '+df_train['prgrm_dsc']\n",
    "df_train['NTEE_M']=df_train['NTEE1'].apply(ntee2major)\n",
    "\n",
    "len(df_train['mission_prgrm']), len(df_train['NTEE1'].drop_duplicates()), len(df_train['NTEE_M'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data frame.\n",
    "small_num=0\n",
    "while small_num<1000: # Make sure each category has at least 500 records.\n",
    "    trainDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(120000)\n",
    "    small_num=trainDF.groupby('NTEE_M').count().sort_values('EIN').iloc[0]['EIN']\n",
    "\n",
    "# Build validation data frame.\n",
    "small_num=0\n",
    "while small_num<1000: # Make sure each category has at least 500 records.\n",
    "    valDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(120000)\n",
    "    small_num=valDF.groupby('NTEE_M').count().sort_values('EIN').iloc[0]['EIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTEE_M\n",
      "I       0.111467\n",
      "II      0.167017\n",
      "III     0.051650\n",
      "IV      0.116175\n",
      "IX      0.038117\n",
      "V       0.299917\n",
      "VI      0.013392\n",
      "VII     0.173567\n",
      "VIII    0.028700\n",
      "Name: EIN, dtype: float64 \n",
      "\n",
      " NTEE_M\n",
      "I       0.111725\n",
      "II      0.167750\n",
      "III     0.050842\n",
      "IV      0.115883\n",
      "IX      0.038592\n",
      "V       0.300100\n",
      "VI      0.012992\n",
      "VII     0.173175\n",
      "VIII    0.028942\n",
      "Name: EIN, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the composition by NTEE major groups.\n",
    "print(trainDF.groupby('NTEE_M').count()['EIN']/len(trainDF), '\\n'*2, valDF.groupby('NTEE_M').count()['EIN']/len(valDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label_list, class_list):\n",
    "    int_encoder=LabelEncoder().fit(class_list) # Build the encoder.\n",
    "    label_int_encoded=int_encoder.transform(label_list) # One-dimensional integer encoded.\n",
    "    return np_utils.to_categorical(label_int_encoded) # Multi-dimensional binary/one-hot encoded.\n",
    "\n",
    "y_train=one_hot(label_list=trainDF['NTEE_M'], class_list=list(major_group_dict.keys()))\n",
    "y_val=one_hot(label_list=valDF['NTEE_M'], class_list=list(major_group_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list=stopwords.words('english')+list(string.punctuation)\n",
    "def tokenize_stopwords_remove(string):\n",
    "    global stop_list\n",
    "    return [s for s in nltk.word_tokenize(string) if s not in stop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token_list_train=trainDF['mission_prgrm'].apply(tokenize_stopwords_remove)\n",
    "text_token_list_val=valDF['mission_prgrm'].apply(tokenize_stopwords_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moved to preprocessing pipeline.**\n",
    "```Python\n",
    "# Spell check function. Return corrected word if unknown; return original word if known.\n",
    "def spellcheck(word_string_list):\n",
    "    return [SpellChecker().correction(word=s).upper() for s in word_string_list]\n",
    "\n",
    "# Parallel computing\n",
    "p = Pool(48)\n",
    "text_token_list_train=p.map(spellcheck, text_token_list_train)\n",
    "text_token_list_val=p.map(spellcheck, text_token_list_val)\n",
    "# Pool.map keep the original order of data passed to map.\n",
    "# https://stackoverflow.com/questions/41273960/python-3-does-pool-keep-the-original-order-of-data-passed-to-map\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 1), ('the', 2), ('to', 3), ('of', 4), ('in', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Build word index for train and validation texts.\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(text_token_list_train.to_list()+text_token_list_val.to_list())\n",
    "print(list(tokenizer.word_index.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoding_text_train=tokenizer.texts_to_sequences(text_token_list_train)\n",
    "seq_encoding_text_val=tokenizer.texts_to_sequences(text_token_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads sequences to the same length.\n",
    "x_train=pad_sequences(sequences=seq_encoding_text_train,\n",
    "                      maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                      dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                      value = 0 # Zero is used for representing None or Unknown.\n",
    "                     )\n",
    "x_val=pad_sequences(sequences=seq_encoding_text_val,\n",
    "                    maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                    dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                    value = 0 # Zero is used for representing None or Unknown.\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@Petuum/embeddings-a-matrix-of-meaning-4de877c9aa27\n",
    "# Note that in the embedding matrix above, each row corresponds to a word and each column corresponds to a dimension (axis). \n",
    "# Typically, we store this in a dense fashion, where we have a list of words and row IDâ€™s which map to the corresponding row of the matrix. \n",
    "# For the above example, weâ€™d have the following list in addition to the matrix:\n",
    "# { hello: 0, there: 1, texas: 2, world: 3, â€¦ }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not using pre-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index), # Size of vocabulary.\n",
    "                            input_length=max([len(s) for s in seq_encoding_text_train]), # Length of input, i.e., length of padded sequence.\n",
    "                            output_dim=32, # Size of the vector space in which words will be embedded.\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(max([len(s) for s in seq_encoding_text_train]),), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=len(y_train[0]), activation='softmax')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics.\n",
    "# https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras\n",
    "import tensorflow as tf\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='sigmoid'))\n",
    "model.add(Dense(units=256, activation='sigmoid'))\n",
    "model.add(Dense(units=len(y_train[0]), activation='relu'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', precision, recall])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# Batch size: https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
    "history=model.fit(x_train, y_train, validation_split=0.3, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained GloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "EMBEDDING_DIM=100\n",
    "glove_word_vector=api.load('glove-wiki-gigaword-'+str(EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 253313/253313 [00:00<00:00, 370562.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for word, index in tqdm(tokenizer.word_index.items()):\n",
    "    try:\n",
    "        embedding_matrix[index] = glove_word_vector.get_vector(word)\n",
    "    except:\n",
    "        pass\n",
    "        # words not found in embedding index will be all-zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index)+1, # Size of vocabulary.\n",
    "                            input_length=max([len(s) for s in seq_encoding_text_train]), # Length of input, i.e., length of padded sequence.\n",
    "                            output_dim=EMBEDDING_DIM, # Size of the vector space in which words will be embedded.\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics.\n",
    "# https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras\n",
    "import tensorflow as tf\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)\n",
    "f1 = as_keras_metric(tf.contrib.metrics.f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 28647, 100)        25331400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 28643, 128)        64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 153       \n",
      "=================================================================\n",
      "Total params: 25,400,881\n",
      "Trainable params: 69,481\n",
      "Non-trainable params: 25,331,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 84000 samples, validate on 36000 samples\n",
      "Epoch 1/100\n",
      "84000/84000 [==============================] - 235s 3ms/step - loss: 0.1899 - acc: 0.9312 - val_loss: 0.1496 - val_acc: 0.9461\n",
      "Epoch 2/100\n",
      "84000/84000 [==============================] - 231s 3ms/step - loss: 0.1364 - acc: 0.9519 - val_loss: 0.1420 - val_acc: 0.9498\n",
      "Epoch 3/100\n",
      "84000/84000 [==============================] - 230s 3ms/step - loss: 0.1213 - acc: 0.9574 - val_loss: 0.1368 - val_acc: 0.9510\n",
      "Epoch 4/100\n",
      "84000/84000 [==============================] - 230s 3ms/step - loss: 0.1112 - acc: 0.9612 - val_loss: 0.1355 - val_acc: 0.9515\n",
      "Epoch 5/100\n",
      "84000/84000 [==============================] - 229s 3ms/step - loss: 0.1030 - acc: 0.9644 - val_loss: 0.1397 - val_acc: 0.9506\n",
      "Epoch 6/100\n",
      "84000/84000 [==============================] - 231s 3ms/step - loss: 0.0958 - acc: 0.9669 - val_loss: 0.1453 - val_acc: 0.9503\n",
      "Epoch 7/100\n",
      "84000/84000 [==============================] - 230s 3ms/step - loss: 0.0901 - acc: 0.9691 - val_loss: 0.1413 - val_acc: 0.9504\n",
      "Epoch 8/100\n",
      " 5664/84000 [=>............................] - ETA: 3:05 - loss: 0.0805 - acc: 0.9731"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, GlobalMaxPool1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# model.add(Flatten())\n",
    "model.add(Conv1D(128, 5, activation='softplus'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(units=32, activation='sigmoid'))\n",
    "model.add(Dense(units=16, activation='softplus'))\n",
    "# model.add(PReLU()) # https://medium.com/tinymind/a-practical-guide-to-relu-b83ca804f1f7\n",
    "model.add(Dense(units=16, activation='tanh'))\n",
    "model.add(Dense(units=16, activation='softplus'))\n",
    "model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', \n",
    "#                                                                      precision, recall\n",
    "                                                                    ])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "history=model.fit(x_train, y_train, validation_split=0.3, epochs=100, verbose=1)\n",
    "\n",
    "'''\n",
    "(10, sigmoid; 9, relu): loss: 0.4414 - acc: 0.8896 - precision: 0.1604 - recall: 0.8439 - val_loss: 0.3964 - val_acc: 0.8943 - val_precision: 0.1632 - val_recall: 0.8974\n",
    "(10, softmax; 9, relu): loss: 0.5685 - acc: 0.8888 - precision: 0.1371 - recall: 0.8051 - val_loss: 0.5532 - val_acc: 0.8895 - val_precision: 0.1394 - val_recall: 0.8151\n",
    "(10, relu;    9, relu): loss: 0.5377 - acc: 0.8838 - precision: 0.1646 - recall: 0.8411 - val_loss: 0.4271 - val_acc: 0.8903 - val_precision: 0.1558 - val_recall: 0.8884\n",
    "(10, relu; 9, softmax): loss: 0.2596 - acc: 0.9037 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2303 - val_acc: 0.9135 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, relu; 9, sigmoid): loss: 0.2681 - acc: 0.8975 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2272 - val_acc: 0.9121 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, tanh; 9, sigmoid): loss: 0.2959 - acc: 0.8940 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2572 - val_acc: 0.9066 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, relu;    9, tanh): loss: 0.4241 - acc: 0.8599 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.3609 - val_acc: 0.8885 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "\n",
    "(32, relu; 16, tanh; 9, sigmoid): loss: 0.2590 - acc: 0.9034 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2186 - val_acc: 0.9180 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(32, relu; 16, tanh; 9,    relu): loss: 0.5613 - acc: 0.8654 - precision: 0.1360 - recall: 0.7180 - val_loss: 0.3850 - val_acc: 0.8889 - val_precision: 0.1394 - val_recall: 0.8721\n",
    "(32, relu; 16, relu; 9,    relu): loss: 0.3902 - acc: 0.8876 - precision: 0.1396 - recall: 0.9328 - val_loss: 0.3618 - val_acc: 0.8889 - val_precision: 0.1377 - val_recall: 0.9532\n",
    "(32, softmax; 16, relu; 9, relu): loss: 0.6418 - acc: 0.8916 - precision: 0.1212 - recall: 0.7585 - val_loss: 0.6097 - val_acc: 0.8942 - val_precision: 0.1276 - val_recall: 0.7584\n",
    "(32, sigmoid; 16, relu; 9, relu): loss: 0.5048 - acc: 0.8885 - precision: 0.1421 - recall: 0.7762 - val_loss: 0.3169 - val_acc: 0.8889 - val_precision: 0.1363 - val_recall: 0.8788\n",
    "\n",
    "(32, sigmoid; 32, sigmoid; 16, relu; 16, relu; 9, relu): loss: 0.3325 - acc: 0.8879 - precision: 0.1251 - recall: 0.9766 - val_loss: 0.4644 - val_acc: 0.7910 - val_precision: 0.1257 - val_recall: 0.9785\n",
    "(32, softmax; 32, softmax; 16, relu; 16, relu; 9, relu): loss: 1.1298 - acc: 0.8889 - precision: 0.0933 - recall: 0.4219 - val_loss: 1.1113 - val_acc: 0.8889 - val_precision: 0.0952 - val_recall: 0.4569\n",
    "\n",
    "1. Don't use sigmoid/softmax/tanh for output layer.\n",
    "2. Using relu near output layer increases loss but improve precision.\n",
    "3. sigmoid/tanh/softmax decreases loss, but also decreases precision.\n",
    "4. Possible strategy: use softmax near input layer, use relu near output layer.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000/120000 [==============================] - 118s 980us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8065"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "In the case of a two-class (binary) classification problem, the sigmoid activation function is often used in the output layer. \n",
    "The predicted probability is taken as the likelihood of the observation belonging to class 1, or inverted (1 â€“ probability) to give the probability for class 0.\n",
    "In the case of a multi-class classification problem, the softmax activation function \n",
    "is often used on the output layer and the likelihood of the observation for each class is returned as a vector.\n",
    "'''\n",
    "\n",
    "y_prob = model.predict(x_val, verbose=1)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_classes_prob=[s.max() for s in y_prob]\n",
    "y_classes_val=y_val.argmax(axis=-1)\n",
    "\n",
    "df_val=pd.DataFrame({'pred':y_classes, \n",
    "                     'true':y_classes_val, \n",
    "                     'prob':y_classes_prob})\n",
    "len(df_val[df_val.pred==df_val.true])/len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8855383130305224 0.794225\n"
     ]
    }
   ],
   "source": [
    "df_95=df_val[df_val.prob>.95]\n",
    "print(len(df_95[df_95.pred==df_95.true])/len(df_95), len(df_95)/len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12731</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77231</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39466</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40808</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55521</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98084</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32629</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97716</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48723</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.512429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  true      prob\n",
       "2715      7     2  0.545607\n",
       "12731     3     7  0.994292\n",
       "77231     5     5  0.998583\n",
       "39466     2     2  0.993600\n",
       "40808     7     7  0.997733\n",
       "55521     0     5  0.993345\n",
       "98084     5     5  0.998267\n",
       "32629     3     1  0.227505\n",
       "97716     5     5  0.998162\n",
       "48723     8     8  0.512429"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14574.0</td>\n",
       "      <td>0.947898</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>0.181094</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20047.0</td>\n",
       "      <td>0.938727</td>\n",
       "      <td>0.150843</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>0.982048</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.999559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6813.0</td>\n",
       "      <td>0.937554</td>\n",
       "      <td>0.145990</td>\n",
       "      <td>0.230144</td>\n",
       "      <td>0.983532</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.997143</td>\n",
       "      <td>0.999125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13946.0</td>\n",
       "      <td>0.919894</td>\n",
       "      <td>0.163432</td>\n",
       "      <td>0.202485</td>\n",
       "      <td>0.950082</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.997833</td>\n",
       "      <td>0.999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4788.0</td>\n",
       "      <td>0.915918</td>\n",
       "      <td>0.158874</td>\n",
       "      <td>0.223830</td>\n",
       "      <td>0.934571</td>\n",
       "      <td>0.991566</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34993.0</td>\n",
       "      <td>0.951979</td>\n",
       "      <td>0.125865</td>\n",
       "      <td>0.173467</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>0.997629</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>0.999602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2456.0</td>\n",
       "      <td>0.769482</td>\n",
       "      <td>0.228869</td>\n",
       "      <td>0.182271</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>0.862013</td>\n",
       "      <td>0.967078</td>\n",
       "      <td>0.996433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18602.0</td>\n",
       "      <td>0.923707</td>\n",
       "      <td>0.159183</td>\n",
       "      <td>0.198981</td>\n",
       "      <td>0.957083</td>\n",
       "      <td>0.996431</td>\n",
       "      <td>0.998265</td>\n",
       "      <td>0.999453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3781.0</td>\n",
       "      <td>0.864114</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>0.189253</td>\n",
       "      <td>0.806864</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>0.997941</td>\n",
       "      <td>0.999207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob                                                              \\\n",
       "        count      mean       std       min       25%       50%       75%   \n",
       "pred                                                                        \n",
       "0     14574.0  0.947898  0.140834  0.181094  0.994786  0.997717  0.998336   \n",
       "1     20047.0  0.938727  0.150843  0.199948  0.982048  0.996910  0.998982   \n",
       "2      6813.0  0.937554  0.145990  0.230144  0.983532  0.995575  0.997143   \n",
       "3     13946.0  0.919894  0.163432  0.202485  0.950082  0.994085  0.997833   \n",
       "4      4788.0  0.915918  0.158874  0.223830  0.934571  0.991566  0.997457   \n",
       "5     34993.0  0.951979  0.125865  0.173467  0.987138  0.997629  0.998319   \n",
       "6      2456.0  0.769482  0.228869  0.182271  0.593661  0.862013  0.967078   \n",
       "7     18602.0  0.923707  0.159183  0.198981  0.957083  0.996431  0.998265   \n",
       "8      3781.0  0.864114  0.213472  0.189253  0.806864  0.985537  0.997941   \n",
       "\n",
       "                \n",
       "           max  \n",
       "pred            \n",
       "0     0.999913  \n",
       "1     0.999559  \n",
       "2     0.999125  \n",
       "3     0.999361  \n",
       "4     0.999467  \n",
       "5     0.999602  \n",
       "6     0.996433  \n",
       "7     0.999453  \n",
       "8     0.999207  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('pred')[['prob']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6472.0</td>\n",
       "      <td>0.926960</td>\n",
       "      <td>0.161377</td>\n",
       "      <td>0.201276</td>\n",
       "      <td>0.967786</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.999708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10120.0</td>\n",
       "      <td>0.932083</td>\n",
       "      <td>0.141317</td>\n",
       "      <td>0.187849</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.998673</td>\n",
       "      <td>0.999277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2929.0</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.163671</td>\n",
       "      <td>0.259162</td>\n",
       "      <td>0.904953</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.998996</td>\n",
       "      <td>0.999484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7110.0</td>\n",
       "      <td>0.916791</td>\n",
       "      <td>0.161245</td>\n",
       "      <td>0.262828</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>0.998905</td>\n",
       "      <td>0.999202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.161161</td>\n",
       "      <td>0.235908</td>\n",
       "      <td>0.882732</td>\n",
       "      <td>0.990259</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.999328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16172.0</td>\n",
       "      <td>0.931750</td>\n",
       "      <td>0.135043</td>\n",
       "      <td>0.200071</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>0.995243</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>0.999214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>843.0</td>\n",
       "      <td>0.696661</td>\n",
       "      <td>0.217745</td>\n",
       "      <td>0.242645</td>\n",
       "      <td>0.509826</td>\n",
       "      <td>0.695344</td>\n",
       "      <td>0.918251</td>\n",
       "      <td>0.999637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12870.0</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.153473</td>\n",
       "      <td>0.261656</td>\n",
       "      <td>0.931813</td>\n",
       "      <td>0.997049</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.999863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.850485</td>\n",
       "      <td>0.203469</td>\n",
       "      <td>0.266933</td>\n",
       "      <td>0.727755</td>\n",
       "      <td>0.976792</td>\n",
       "      <td>0.996452</td>\n",
       "      <td>0.998747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob                                                              \\\n",
       "        count      mean       std       min       25%       50%       75%   \n",
       "pred                                                                        \n",
       "0      6472.0  0.926960  0.161377  0.201276  0.967786  0.998207  0.999427   \n",
       "1     10120.0  0.932083  0.141317  0.187849  0.963087  0.996856  0.998673   \n",
       "2      2929.0  0.907906  0.163671  0.259162  0.904953  0.994907  0.998996   \n",
       "3      7110.0  0.916791  0.161245  0.262828  0.938327  0.996855  0.998905   \n",
       "4      1986.0  0.903018  0.161161  0.235908  0.882732  0.990259  0.997365   \n",
       "5     16172.0  0.931750  0.135043  0.200071  0.948975  0.995243  0.998743   \n",
       "6       843.0  0.696661  0.217745  0.242645  0.509826  0.695344  0.918251   \n",
       "7     12870.0  0.919407  0.153473  0.261656  0.931813  0.997049  0.999624   \n",
       "8      1498.0  0.850485  0.203469  0.266933  0.727755  0.976792  0.996452   \n",
       "\n",
       "                \n",
       "           max  \n",
       "pred            \n",
       "0     0.999708  \n",
       "1     0.999277  \n",
       "2     0.999484  \n",
       "3     0.999202  \n",
       "4     0.999328  \n",
       "5     0.999214  \n",
       "6     0.999637  \n",
       "7     0.999863  \n",
       "8     0.998747  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('pred')[['prob']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 200)         6692600   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 200000)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               102400512 \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 109,159,937\n",
      "Trainable params: 102,467,337\n",
      "Non-trainable params: 6,692,600\n",
      "_________________________________________________________________\n",
      "Train on 8399 samples, validate on 33601 samples\n",
      "Epoch 1/2\n",
      "8399/8399 [==============================] - 125s 15ms/step - loss: 0.2489 - acc: 0.9057 - precision: 0.1104 - recall: 0.9940 - val_loss: 0.2185 - val_acc: 0.9155 - val_precision: 0.1111 - val_recall: 1.0000\n",
      "Epoch 2/2\n",
      "8399/8399 [==============================] - 121s 14ms/step - loss: 0.1594 - acc: 0.9394 - precision: 0.1111 - recall: 1.0000 - val_loss: 0.2231 - val_acc: 0.9167 - val_precision: 0.1111 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "'''\n",
    "x = GRU(units=128, activation='tanh', return_sequences=True)(embedded_sequences)\n",
    "\n",
    "x = LSTM(units=256, activation='tanh', return_sequences=False)(embedded_sequences)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#x = LSTM(units=128, activation='tanh', return_sequences=True)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "'''\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=9, activation='softmax')(x) #softmax\n",
    "\n",
    "# x = Dense(units=512, activation='relu')(x)\n",
    "# x = Dense(units=128, activation='relu')(x)\n",
    "# preds = Dense(units=25, activation='sigmoid')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 25s 412us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19112927243113517, 0.9295742606123288, 0.1111111119389534, 1.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=500, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37694"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val[df_val.pred==df_val.true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 7, 5, 3, 4, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_95.pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
