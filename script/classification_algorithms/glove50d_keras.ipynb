{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- [x] Build NTEE-10 major groups.\n",
    "- [x] Vectorize output labels.\n",
    "- [ ] Vectorize input texts.\n",
    "- [x] Spell check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/\n",
    "#https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "#RNN\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "# For encoding labels.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code as 10 major groups.\n",
    "major_group_dict={'I': ['A'],\n",
    "                  'II': ['B'],\n",
    "                  'III': ['C', 'D'],\n",
    "                  'IV': ['E', 'F', 'G', 'H'],\n",
    "                  'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                  'VI': ['Q'],\n",
    "                  'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                  'VIII': ['X'],\n",
    "                  'IX': ['Y'],\n",
    "                  'X': ['Z'],\n",
    "                 }\n",
    "def ntee2major(string):\n",
    "    global major_group_dict\n",
    "    return [s for s in major_group_dict.keys() if string in major_group_dict[s]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229472, 25, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list=os.listdir('../../dataset/df_train.pkl.gz/')\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, \n",
    "                        pd.read_pickle('../../dataset/df_train.pkl.gz/'+file, compression='gzip')])\n",
    "df_train['mission_prgrm']=df_train['mission']+'; '+df_train['prgrm_dsc']\n",
    "df_train['NTEE_M']=df_train['NTEE1'].apply(ntee2major)\n",
    "\n",
    "len(df_train['mission_prgrm']), len(df_train['NTEE1'].drop_duplicates()), len(df_train['NTEE_M'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data frame.\n",
    "small_num=0\n",
    "while small_num<500: # Make sure each category has at least 500 records.\n",
    "    trainDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(60000)\n",
    "    small_num=trainDF.groupby('NTEE_M').count().sort_values('EIN').iloc[0]['EIN']\n",
    "\n",
    "# Build validation data frame.\n",
    "small_num=0\n",
    "while small_num<500: # Make sure each category has at least 500 records.\n",
    "    valDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(60000)\n",
    "    small_num=valDF.groupby('NTEE_M').count().sort_values('EIN').iloc[0]['EIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTEE_M\n",
      "I       0.113850\n",
      "II      0.166033\n",
      "III     0.050317\n",
      "IV      0.115817\n",
      "IX      0.038883\n",
      "V       0.299717\n",
      "VI      0.013233\n",
      "VII     0.173300\n",
      "VIII    0.028850\n",
      "Name: EIN, dtype: float64 \n",
      "\n",
      " NTEE_M\n",
      "I       0.111683\n",
      "II      0.165683\n",
      "III     0.049433\n",
      "IV      0.117383\n",
      "IX      0.038417\n",
      "V       0.301333\n",
      "VI      0.013250\n",
      "VII     0.174450\n",
      "VIII    0.028367\n",
      "Name: EIN, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the composition by NTEE major groups.\n",
    "print(trainDF.groupby('NTEE_M').count()['EIN']/len(trainDF), '\\n'*2, valDF.groupby('NTEE_M').count()['EIN']/len(valDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label_list, class_list):\n",
    "    int_encoder=LabelEncoder().fit(class_list) # Build the encoder.\n",
    "    label_int_encoded=int_encoder.transform(label_list) # One-dimensional integer encoded.\n",
    "    return np_utils.to_categorical(label_int_encoded) # Multi-dimensional binary/one-hot encoded.\n",
    "\n",
    "y_train=one_hot(label_list=trainDF['NTEE_M'], class_list=list(major_group_dict.keys()))\n",
    "y_val=one_hot(label_list=valDF['NTEE_M'], class_list=list(major_group_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list=stopwords.words('english')+list(string.punctuation)\n",
    "def tokenize_stopwords_remove(string):\n",
    "    global stop_list\n",
    "    return [s for s in nltk.word_tokenize(string) if s not in stop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token_list_train=trainDF['mission_prgrm'].apply(tokenize_stopwords_remove)\n",
    "text_token_list_val=valDF['mission_prgrm'].apply(tokenize_stopwords_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'LazyCorpusLoader' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-95-347b9c670b92>\", line 3, in spellcheck\n    return [SpellChecker().correction(word=s).upper() for s in word_string_list if s not in stopwords]\n  File \"<ipython-input-95-347b9c670b92>\", line 3, in <listcomp>\n    return [SpellChecker().correction(word=s).upper() for s in word_string_list if s not in stopwords]\nTypeError: argument of type 'LazyCorpusLoader' is not iterable\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-347b9c670b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Parallel computing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtext_token_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspellcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_token_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Pool.map keep the original order of data passed to map.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/41273960/python-3-does-pool-keep-the-original-order-of-data-passed-to-map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'LazyCorpusLoader' is not iterable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-51:\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-49:\n",
      "Process ForkPoolWorker-72:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-53:\n",
      "Process ForkPoolWorker-70:\n",
      "Process ForkPoolWorker-86:\n",
      "Process ForkPoolWorker-71:\n",
      "Process ForkPoolWorker-69:\n",
      "Process ForkPoolWorker-76:\n",
      "Process ForkPoolWorker-88:\n",
      "Process ForkPoolWorker-68:\n",
      "Process ForkPoolWorker-67:\n",
      "Process ForkPoolWorker-66:\n",
      "Process ForkPoolWorker-55:\n",
      "Process ForkPoolWorker-52:\n",
      "Process ForkPoolWorker-75:\n",
      "Process ForkPoolWorker-74:\n",
      "Process ForkPoolWorker-73:\n",
      "Process ForkPoolWorker-80:\n",
      "Process ForkPoolWorker-79:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-78:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-77:\n",
      "Process ForkPoolWorker-82:\n",
      "Process ForkPoolWorker-81:\n",
      "Process ForkPoolWorker-85:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-93:\n",
      "Process ForkPoolWorker-87:\n",
      "Process ForkPoolWorker-91:\n",
      "Process ForkPoolWorker-84:\n",
      "Process ForkPoolWorker-96:\n",
      "Process ForkPoolWorker-94:\n",
      "Process ForkPoolWorker-83:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-92:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-89:\n",
      "Process ForkPoolWorker-90:\n",
      "Process ForkPoolWorker-95:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-65:\n",
      "Process ForkPoolWorker-64:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Process ForkPoolWorker-62:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-63:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n"
     ]
    }
   ],
   "source": [
    "# Spell check function. Return corrected word if unknown; return original word if known.\n",
    "def spellcheck(word_string_list):\n",
    "    return [SpellChecker().correction(word=s).upper() for s in word_string_list]\n",
    "\n",
    "# Parallel computing\n",
    "p = Pool(48)\n",
    "text_token_list=p.map(spellcheck, text_token_list[0:10])\n",
    "# Pool.map keep the original order of data passed to map.\n",
    "# https://stackoverflow.com/questions/41273960/python-3-does-pool-keep-the-original-order-of-data-passed-to-map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 1), ('the', 2), ('to', 3), ('of', 4), ('in', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Build word index for train and validation texts.\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(text_token_list_train.to_list()+text_token_list_val.to_list())\n",
    "print(list(tokenizer.word_index.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoding_text_train=tokenizer.texts_to_sequences(text_token_list_train)\n",
    "seq_encoding_text_val=tokenizer.texts_to_sequences(text_token_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads sequences to the same length.\n",
    "x_train=pad_sequences(sequences=seq_encoding_text_train,\n",
    "                      maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                      dtype = \"int32\", padding = \"post\", truncating = \"post\", value = 0\n",
    "                     )\n",
    "x_val=pad_sequences(sequences=seq_encoding_text_val,\n",
    "                      maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                      dtype = \"int32\", padding = \"post\", truncating = \"post\", value = 0\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@Petuum/embeddings-a-matrix-of-meaning-4de877c9aa27\n",
    "# Note that in the embedding matrix above, each row corresponds to a word and each column corresponds to a dimension (axis). \n",
    "# Typically, we store this in a dense fashion, where we have a list of words and row ID’s which map to the corresponding row of the matrix. \n",
    "# For the above example, we’d have the following list in addition to the matrix:\n",
    "# { hello: 0, there: 1, texas: 2, world: 3, … }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ~/work_dir/npo_classifier/dataset; mkdir glove.6B; wget http://nlp.stanford.edu/data/glove.6B.zip; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not using pre-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index), # Size of vocabulary.\n",
    "                            input_length=max([len(s) for s in seq_encoding_text_train]), # Length of input, i.e., length of padded sequence.\n",
    "                            output_dim=100, # Size of the vector space in which words will be embedded.\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(max([len(s) for s in seq_encoding_text_train]),), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=len(y_train[0]), activation='softmax')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics.\n",
    "# https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras\n",
    "import tensorflow as tf\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 33350, 100)        17884800  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3335000)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 30015009  \n",
      "=================================================================\n",
      "Total params: 47,899,809\n",
      "Trainable params: 47,899,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(y_train[0]), activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', precision, recall])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "26400/48000 [===============>..............] - ETA: 7:35 - loss: 1.7896 - acc: 0.8883 - precision: 0.1110 - recall: 0.0165"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "[-7.1549e-02  9.3459e-02  2.3738e-02 -9.0339e-02  5.6123e-02  3.2547e-01\n",
      " -3.9796e-01 -9.2139e-02  6.1181e-02 -1.8950e-01  1.3061e-01  1.4349e-01\n",
      "  1.1479e-02  3.8158e-01  5.4030e-01 -1.4088e-01  2.4315e-01  2.3036e-01\n",
      " -5.5339e-01  4.8154e-02  4.5662e-01  3.2338e+00  2.0199e-02  4.9019e-02\n",
      " -1.4132e-02  7.6017e-02 -1.1527e-01  2.0060e-01 -7.7657e-02  2.4328e-01\n",
      "  1.6368e-01 -3.4118e-01 -6.6070e-02  1.0152e-01  3.8232e-02 -1.7668e-01\n",
      " -8.8153e-01 -3.3895e-01 -3.5481e-02 -5.5095e-01 -1.6899e-02 -4.3982e-01\n",
      "  3.9004e-02  4.0447e-01 -2.5880e-01  6.4594e-01  2.6641e-01  2.8009e-01\n",
      " -2.4625e-02  6.3302e-01 -3.1700e-01  1.0271e-01  3.0886e-01  9.7792e-02\n",
      " -3.8227e-01  8.6552e-02  4.7075e-02  2.3511e-01 -3.2127e-01 -2.8538e-01\n",
      "  1.6670e-01 -4.9707e-03 -6.2714e-01 -2.4904e-01  2.9713e-01  1.4379e-01\n",
      " -1.2325e-01 -5.8178e-02 -1.0290e-03 -8.2126e-02  3.6935e-01 -5.8442e-04\n",
      "  3.4286e-01  2.8426e-01 -6.8599e-02  6.5747e-01 -2.9087e-02  1.6184e-01\n",
      "  7.3672e-02 -3.0343e-01  9.5733e-02 -5.2860e-01 -2.2898e-01  6.4079e-02\n",
      "  1.5218e-02  3.4921e-01 -4.3960e-01 -4.3983e-01  7.7515e-01 -8.7767e-01\n",
      " -8.7504e-02  3.9598e-01  6.2362e-01 -2.6211e-01 -3.0539e-01 -2.2964e-02\n",
      "  3.0567e-01  6.7660e-02  1.5383e-01 -1.1211e-01 -9.1540e-02  8.2562e-02\n",
      "  1.6897e-01 -3.2952e-02 -2.8775e-01 -2.2320e-01 -9.0426e-02  1.2407e+00\n",
      " -1.8244e-01 -7.5219e-03 -4.1388e-02 -1.1083e-02  7.8186e-02  3.8511e-01\n",
      "  2.3334e-01  1.4414e-01 -9.1070e-04 -2.6388e-01 -2.0481e-01  1.0099e-01\n",
      "  1.4076e-01  2.8834e-01 -4.5429e-02  3.7247e-01  1.3645e-01 -6.7457e-01\n",
      "  2.2786e-01  1.2599e-01  2.9091e-02  3.0428e-02 -1.3028e-01  1.9408e-01\n",
      "  4.9014e-01 -3.9121e-01 -7.5952e-02  7.4731e-02  1.8902e-01 -1.6922e-01\n",
      " -2.6019e-01 -3.9771e-02 -2.4153e-01  1.0875e-01  3.0434e-01  3.6009e-02\n",
      "  1.4264e+00  1.2759e-01 -7.3811e-02 -2.0418e-01  8.0016e-03  1.5381e-01\n",
      "  2.0223e-01  2.8274e-01  9.6206e-02 -3.3634e-01  5.0983e-01  3.2625e-01\n",
      " -2.6535e-01  3.7400e-01 -3.0388e-01 -4.0033e-01 -4.2910e-02 -6.7897e-02\n",
      " -2.9332e-01  1.0978e-01 -4.5365e-02  2.3222e-01 -3.1134e-01 -2.8983e-01\n",
      " -6.6687e-01  5.3097e-01  1.9461e-01  3.6670e-01  2.6185e-01 -6.5187e-01\n",
      "  1.0266e-01  1.1363e-01 -1.2953e-01 -6.8246e-01 -1.8751e-01  1.4760e-01\n",
      "  1.0765e+00 -2.2908e-01 -9.3435e-03 -2.0651e-01 -3.5225e-01 -2.6720e-01\n",
      " -3.4307e-03  2.5906e-01  2.1759e-01  6.6158e-01  1.2180e-01  1.9957e-01\n",
      " -2.0303e-01  3.4474e-01 -2.4328e-01  1.3139e-01 -8.8767e-03  3.3617e-01\n",
      "  3.0591e-02  2.5577e-01]\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../../dataset/glove.6B/glove.6B.200d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "print(embeddings_index['the'])\n",
    "\n",
    "EMBEDDING_DIM=200\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index), EMBEDDING_DIM))\n",
    "for word, index in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.20327   ,  0.47347999,  0.050877  , ..., -0.21358   ,\n",
       "        -0.62248999,  0.14386   ],\n",
       "       [-0.071549  ,  0.093459  ,  0.023738  , ...,  0.33616999,\n",
       "         0.030591  ,  0.25577   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.17625999,  0.14951   ,  0.17261   , ...,  0.39155   ,\n",
       "         0.14      , -0.071701  ],\n",
       "       [ 0.25670001, -0.51446003,  0.10277   , ..., -0.14658999,\n",
       "         0.18509001,  0.31108001]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../dataset/glove.6B/glove.6B.200d.txt', encoding='utf8')\n",
    "t=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[852].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 200)         6692600   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 200000)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               102400512 \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 109,159,937\n",
      "Trainable params: 102,467,337\n",
      "Non-trainable params: 6,692,600\n",
      "_________________________________________________________________\n",
      "Train on 8399 samples, validate on 33601 samples\n",
      "Epoch 1/2\n",
      "8399/8399 [==============================] - 125s 15ms/step - loss: 0.2489 - acc: 0.9057 - precision: 0.1104 - recall: 0.9940 - val_loss: 0.2185 - val_acc: 0.9155 - val_precision: 0.1111 - val_recall: 1.0000\n",
      "Epoch 2/2\n",
      "8399/8399 [==============================] - 121s 14ms/step - loss: 0.1594 - acc: 0.9394 - precision: 0.1111 - recall: 1.0000 - val_loss: 0.2231 - val_acc: 0.9167 - val_precision: 0.1111 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "'''\n",
    "x = GRU(units=128, activation='tanh', return_sequences=True)(embedded_sequences)\n",
    "\n",
    "x = LSTM(units=256, activation='tanh', return_sequences=False)(embedded_sequences)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#x = LSTM(units=128, activation='tanh', return_sequences=True)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "'''\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=9, activation='softmax')(x) #softmax\n",
    "\n",
    "# x = Dense(units=512, activation='relu')(x)\n",
    "# x = Dense(units=128, activation='relu')(x)\n",
    "# preds = Dense(units=25, activation='sigmoid')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 25s 412us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19112927243113517, 0.9295742606123288, 0.1111111119389534, 1.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=500, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9686"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s.argmax() for s in y_prob if s.max()>.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(x_val)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_classes_prob=[s.max() for s in y_prob]\n",
    "\n",
    "y_classes_val=y_val.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5756111111111111"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val=pd.DataFrame({'pred':y_classes, \n",
    "                     'true':y_classes_val, \n",
    "                     'prob':y_classes_prob})\n",
    "\n",
    "len(df_val[df_val.pred==df_val.true])/len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_95=df_val[df_val.prob>.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167043911272069"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_95[df_95.pred==df_95.true])/len(df_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10361"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val[df_val.pred==df_val.true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 6, 0, 1, 8, 7, 2, 5])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229472"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.741038</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.179195</td>\n",
       "      <td>0.553635</td>\n",
       "      <td>0.800109</td>\n",
       "      <td>0.957718</td>\n",
       "      <td>0.999084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3321.0</td>\n",
       "      <td>0.702909</td>\n",
       "      <td>0.214974</td>\n",
       "      <td>0.187883</td>\n",
       "      <td>0.518963</td>\n",
       "      <td>0.736724</td>\n",
       "      <td>0.901462</td>\n",
       "      <td>0.992873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>385.0</td>\n",
       "      <td>0.707682</td>\n",
       "      <td>0.196514</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.548713</td>\n",
       "      <td>0.721776</td>\n",
       "      <td>0.889960</td>\n",
       "      <td>0.996574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577.0</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.208047</td>\n",
       "      <td>0.196918</td>\n",
       "      <td>0.486272</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.846662</td>\n",
       "      <td>0.994456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7764.0</td>\n",
       "      <td>0.685369</td>\n",
       "      <td>0.207416</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>0.515284</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>0.874676</td>\n",
       "      <td>0.999471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.338724</td>\n",
       "      <td>0.112924</td>\n",
       "      <td>0.220680</td>\n",
       "      <td>0.266556</td>\n",
       "      <td>0.306376</td>\n",
       "      <td>0.369489</td>\n",
       "      <td>0.789248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2375.0</td>\n",
       "      <td>0.598226</td>\n",
       "      <td>0.192021</td>\n",
       "      <td>0.199413</td>\n",
       "      <td>0.445903</td>\n",
       "      <td>0.580828</td>\n",
       "      <td>0.746043</td>\n",
       "      <td>0.993534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>236.0</td>\n",
       "      <td>0.603263</td>\n",
       "      <td>0.216469</td>\n",
       "      <td>0.192203</td>\n",
       "      <td>0.424609</td>\n",
       "      <td>0.594151</td>\n",
       "      <td>0.801677</td>\n",
       "      <td>0.990671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.613142</td>\n",
       "      <td>0.214152</td>\n",
       "      <td>0.205274</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>0.595048</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>0.999094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prob                                                              \\\n",
       "       count      mean       std       min       25%       50%       75%   \n",
       "pred                                                                       \n",
       "0     2003.0  0.741038  0.226161  0.179195  0.553635  0.800109  0.957718   \n",
       "1     3321.0  0.702909  0.214974  0.187883  0.518963  0.736724  0.901462   \n",
       "2      385.0  0.707682  0.196514  0.227800  0.548713  0.721776  0.889960   \n",
       "3     1577.0  0.660265  0.208047  0.196918  0.486272  0.667132  0.846662   \n",
       "4     7764.0  0.685369  0.207416  0.132313  0.515284  0.694191  0.874676   \n",
       "5       57.0  0.338724  0.112924  0.220680  0.266556  0.306376  0.369489   \n",
       "6     2375.0  0.598226  0.192021  0.199413  0.445903  0.580828  0.746043   \n",
       "7      236.0  0.603263  0.216469  0.192203  0.424609  0.594151  0.801677   \n",
       "8      282.0  0.613142  0.214152  0.205274  0.430801  0.595048  0.762561   \n",
       "\n",
       "                \n",
       "           max  \n",
       "pred            \n",
       "0     0.999084  \n",
       "1     0.992873  \n",
       "2     0.996574  \n",
       "3     0.994456  \n",
       "4     0.999471  \n",
       "5     0.789248  \n",
       "6     0.993534  \n",
       "7     0.990671  \n",
       "8     0.999094  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('pred')[['prob']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17678</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.362340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9351</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.433261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10323</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.441266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.520562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7418</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.831384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.883136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.482429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.252871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15564</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.771747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.510198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.696457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15092</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  true      prob\n",
       "17678     1     1  0.937727\n",
       "12243     4     4  0.362340\n",
       "5267      4     0  0.824200\n",
       "2411      4     1  0.576921\n",
       "9351      3     8  0.433261\n",
       "10323     1     1  0.926592\n",
       "8791      4     3  0.441266\n",
       "9406      1     3  0.520562\n",
       "7418      4     2  0.831384\n",
       "3140      7     7  0.883136\n",
       "11048     4     1  0.493783\n",
       "7         6     6  0.482429\n",
       "5382      0     8  0.252871\n",
       "15564     4     4  0.771747\n",
       "4044      1     1  0.544884\n",
       "665       3     8  0.510198\n",
       "7298      4     6  0.696457\n",
       "3525      4     2  0.385592\n",
       "15092     6     0  0.453290\n",
       "14215     0     0  0.867280"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 3, 6, 8, 7, 2])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_95.pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
