{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "import keras.backend as K\n",
    "\n",
    "#precision & recall by: https://github.com/keras-team/keras/issues/5400\n",
    "#Code Source: https://cloud.google.com/blog/products/gcp/intro-to-text-classification-with-keras-automatically-tagging-stack-overflow-posts\n",
    "\n",
    "trainDF = pd.concat([pd.read_pickle('../../data/raw_data/MasterData_2015.pkl.gz'),\n",
    "                    pd.read_pickle('../../data/raw_data/MasterData_2014.pkl.gz'),\n",
    "                    pd.read_pickle('../../data/raw_data/MasterData_2013.pkl.gz'),\n",
    "                    pd.read_pickle('../../data/raw_data/MasterData_2012.pkl.gz')])\n",
    "                                   \n",
    "trainDF = trainDF[trainDF.TEXT.notna() & trainDF.NTEECC.notna()]\n",
    "trainDF['text'] = trainDF['TEXT'].astype(str)\n",
    "trainDF['label'] = trainDF['NTEE'].astype(str)\n",
    "\n",
    "trainDF = trainDF.drop(['NTEE', 'NTEECC', 'IRS_URL', 'TEXT'], axis=1)\n",
    "trainDF = trainDF[~ (trainDF.label == 'nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len:  464303\n",
      "['E' 'T' 'C' 'X' 'N' 'A' 'L' 'P' 'K' 'O' 'B' 'D' 'S' 'W' 'F' 'M' 'G' 'Q'\n",
      " 'I' 'H' 'U' 'Y' 'J' 'Z' 'R' 'V']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total len: \", len(trainDF))\n",
    "print(trainDF['label'].unique())\n",
    "\n",
    "#test_df = pd.DataFrame(trainDF['label'].unique())\n",
    "#test_df.to_csv(\"../../data/classification_results/results_nteecc/list_of_classes.csv\")\n",
    "\n",
    "#total classes: 1327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Rushi/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 292510 samples, validate on 32502 samples\n",
      "Epoch 1/40\n",
      "292510/292510 [==============================] - 21s 71us/step - loss: 1.5260 - acc: 0.5946 - precision: 0.7675 - recall: 0.4086 - val_loss: 1.3169 - val_acc: 0.6342 - val_precision: 0.7917 - val_recall: 0.4838\n",
      "Epoch 2/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 1.2752 - acc: 0.6454 - precision: 0.7931 - recall: 0.5059 - val_loss: 1.2249 - val_acc: 0.6554 - val_precision: 0.7976 - val_recall: 0.5218\n",
      "Epoch 3/40\n",
      "292510/292510 [==============================] - 20s 67us/step - loss: 1.1764 - acc: 0.6685 - precision: 0.8082 - recall: 0.5400 - val_loss: 1.1497 - val_acc: 0.6771 - val_precision: 0.8137 - val_recall: 0.5474\n",
      "Epoch 4/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 1.0847 - acc: 0.6937 - precision: 0.8261 - recall: 0.5724 - val_loss: 1.0828 - val_acc: 0.6969 - val_precision: 0.8325 - val_recall: 0.5681\n",
      "Epoch 5/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.9923 - acc: 0.7207 - precision: 0.8460 - recall: 0.6070 - val_loss: 1.0085 - val_acc: 0.7194 - val_precision: 0.8402 - val_recall: 0.6102\n",
      "Epoch 6/40\n",
      "292510/292510 [==============================] - 21s 71us/step - loss: 0.9013 - acc: 0.7474 - precision: 0.8636 - recall: 0.6419 - val_loss: 0.9485 - val_acc: 0.7366 - val_precision: 0.8533 - val_recall: 0.6326\n",
      "Epoch 7/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.8168 - acc: 0.7728 - precision: 0.8796 - recall: 0.6766 - val_loss: 0.8846 - val_acc: 0.7578 - val_precision: 0.8653 - val_recall: 0.6629\n",
      "Epoch 8/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.7381 - acc: 0.7969 - precision: 0.8949 - recall: 0.7083 - val_loss: 0.8337 - val_acc: 0.7750 - val_precision: 0.8743 - val_recall: 0.6858\n",
      "Epoch 9/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.6710 - acc: 0.8169 - precision: 0.9067 - recall: 0.7373 - val_loss: 0.7896 - val_acc: 0.7891 - val_precision: 0.8798 - val_recall: 0.7101\n",
      "Epoch 10/40\n",
      "292510/292510 [==============================] - 20s 67us/step - loss: 0.6099 - acc: 0.8356 - precision: 0.9172 - recall: 0.7630 - val_loss: 0.7522 - val_acc: 0.8041 - val_precision: 0.8871 - val_recall: 0.7315\n",
      "Epoch 11/40\n",
      "292510/292510 [==============================] - 20s 67us/step - loss: 0.5579 - acc: 0.8502 - precision: 0.9247 - recall: 0.7850 - val_loss: 0.7184 - val_acc: 0.8161 - val_precision: 0.8949 - val_recall: 0.7507\n",
      "Epoch 12/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.5140 - acc: 0.8629 - precision: 0.9315 - recall: 0.8040 - val_loss: 0.6942 - val_acc: 0.8245 - val_precision: 0.8971 - val_recall: 0.7654\n",
      "Epoch 13/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.4741 - acc: 0.8746 - precision: 0.9368 - recall: 0.8207 - val_loss: 0.6749 - val_acc: 0.8315 - val_precision: 0.9006 - val_recall: 0.7762\n",
      "Epoch 14/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.4395 - acc: 0.8842 - precision: 0.9415 - recall: 0.8358 - val_loss: 0.6596 - val_acc: 0.8370 - val_precision: 0.9026 - val_recall: 0.7875\n",
      "Epoch 15/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.4089 - acc: 0.8930 - precision: 0.9455 - recall: 0.8490 - val_loss: 0.6400 - val_acc: 0.8458 - val_precision: 0.9003 - val_recall: 0.8029\n",
      "Epoch 16/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.3832 - acc: 0.8995 - precision: 0.9479 - recall: 0.8600 - val_loss: 0.6340 - val_acc: 0.8487 - val_precision: 0.9036 - val_recall: 0.8063\n",
      "Epoch 17/40\n",
      "292510/292510 [==============================] - 20s 69us/step - loss: 0.3610 - acc: 0.9060 - precision: 0.9513 - recall: 0.8690 - val_loss: 0.6208 - val_acc: 0.8590 - val_precision: 0.9038 - val_recall: 0.8214\n",
      "Epoch 18/40\n",
      "292510/292510 [==============================] - 22s 74us/step - loss: 0.3404 - acc: 0.9114 - precision: 0.9540 - recall: 0.8775 - val_loss: 0.6180 - val_acc: 0.8616 - val_precision: 0.9037 - val_recall: 0.8268\n",
      "Epoch 19/40\n",
      "292510/292510 [==============================] - 20s 69us/step - loss: 0.3251 - acc: 0.9152 - precision: 0.9551 - recall: 0.8847 - val_loss: 0.6158 - val_acc: 0.8622 - val_precision: 0.9045 - val_recall: 0.8330\n",
      "Epoch 20/40\n",
      "292510/292510 [==============================] - 21s 71us/step - loss: 0.3079 - acc: 0.9202 - precision: 0.9578 - recall: 0.8920 - val_loss: 0.6112 - val_acc: 0.8668 - val_precision: 0.9102 - val_recall: 0.8337\n",
      "Epoch 21/40\n",
      "292510/292510 [==============================] - 21s 71us/step - loss: 0.2953 - acc: 0.9242 - precision: 0.9593 - recall: 0.8975 - val_loss: 0.6059 - val_acc: 0.8703 - val_precision: 0.9142 - val_recall: 0.8384\n",
      "Epoch 22/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2834 - acc: 0.9269 - precision: 0.9609 - recall: 0.9016 - val_loss: 0.6071 - val_acc: 0.8736 - val_precision: 0.9086 - val_recall: 0.8468\n",
      "Epoch 23/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2732 - acc: 0.9296 - precision: 0.9621 - recall: 0.9058 - val_loss: 0.6034 - val_acc: 0.8742 - val_precision: 0.9155 - val_recall: 0.8455\n",
      "Epoch 24/40\n",
      "292510/292510 [==============================] - 20s 69us/step - loss: 0.2642 - acc: 0.9320 - precision: 0.9631 - recall: 0.9099 - val_loss: 0.6026 - val_acc: 0.8764 - val_precision: 0.9095 - val_recall: 0.8549\n",
      "Epoch 25/40\n",
      "292510/292510 [==============================] - 20s 69us/step - loss: 0.2559 - acc: 0.9341 - precision: 0.9644 - recall: 0.9132 - val_loss: 0.6100 - val_acc: 0.8778 - val_precision: 0.9095 - val_recall: 0.8553\n",
      "Epoch 26/40\n",
      "292510/292510 [==============================] - 20s 70us/step - loss: 0.2502 - acc: 0.9357 - precision: 0.9644 - recall: 0.9163 - val_loss: 0.6076 - val_acc: 0.8780 - val_precision: 0.9132 - val_recall: 0.8538\n",
      "Epoch 27/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.2423 - acc: 0.9374 - precision: 0.9655 - recall: 0.9183 - val_loss: 0.6054 - val_acc: 0.8809 - val_precision: 0.9148 - val_recall: 0.8555\n",
      "Epoch 28/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2362 - acc: 0.9393 - precision: 0.9662 - recall: 0.9214 - val_loss: 0.6056 - val_acc: 0.8811 - val_precision: 0.9119 - val_recall: 0.8607\n",
      "Epoch 29/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2322 - acc: 0.9402 - precision: 0.9663 - recall: 0.9230 - val_loss: 0.6021 - val_acc: 0.8835 - val_precision: 0.9113 - val_recall: 0.8652\n",
      "Epoch 30/40\n",
      "292510/292510 [==============================] - 21s 73us/step - loss: 0.2269 - acc: 0.9413 - precision: 0.9669 - recall: 0.9248 - val_loss: 0.6114 - val_acc: 0.8814 - val_precision: 0.9107 - val_recall: 0.8651\n",
      "Epoch 31/40\n",
      "292510/292510 [==============================] - 21s 73us/step - loss: 0.2230 - acc: 0.9425 - precision: 0.9675 - recall: 0.9267 - val_loss: 0.6113 - val_acc: 0.8837 - val_precision: 0.9166 - val_recall: 0.8631\n",
      "Epoch 32/40\n",
      "292510/292510 [==============================] - 21s 73us/step - loss: 0.2181 - acc: 0.9439 - precision: 0.9686 - recall: 0.9281 - val_loss: 0.6103 - val_acc: 0.8835 - val_precision: 0.9111 - val_recall: 0.8684\n",
      "Epoch 33/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2161 - acc: 0.9442 - precision: 0.9680 - recall: 0.9293 - val_loss: 0.6134 - val_acc: 0.8858 - val_precision: 0.9109 - val_recall: 0.8695\n",
      "Epoch 34/40\n",
      "292510/292510 [==============================] - 21s 72us/step - loss: 0.2116 - acc: 0.9452 - precision: 0.9687 - recall: 0.9310 - val_loss: 0.6208 - val_acc: 0.8841 - val_precision: 0.9106 - val_recall: 0.8684\n",
      "Epoch 35/40\n",
      "292510/292510 [==============================] - 21s 71us/step - loss: 0.2101 - acc: 0.9458 - precision: 0.9689 - recall: 0.9316 - val_loss: 0.6165 - val_acc: 0.8873 - val_precision: 0.9117 - val_recall: 0.8720\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292510/292510 [==============================] - 19s 66us/step - loss: 0.2073 - acc: 0.9462 - precision: 0.9688 - recall: 0.9326 - val_loss: 0.6219 - val_acc: 0.8869 - val_precision: 0.9116 - val_recall: 0.8722\n",
      "Epoch 37/40\n",
      "292510/292510 [==============================] - 20s 67us/step - loss: 0.2034 - acc: 0.9474 - precision: 0.9693 - recall: 0.9341 - val_loss: 0.6253 - val_acc: 0.8863 - val_precision: 0.9117 - val_recall: 0.8719\n",
      "Epoch 38/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.2035 - acc: 0.9475 - precision: 0.9693 - recall: 0.9347 - val_loss: 0.6230 - val_acc: 0.8868 - val_precision: 0.9124 - val_recall: 0.8746\n",
      "Epoch 39/40\n",
      "292510/292510 [==============================] - 20s 68us/step - loss: 0.2014 - acc: 0.9481 - precision: 0.9696 - recall: 0.9357 - val_loss: 0.6178 - val_acc: 0.8888 - val_precision: 0.9134 - val_recall: 0.8740\n",
      "Epoch 40/40\n",
      "292510/292510 [==============================] - 20s 70us/step - loss: 0.1981 - acc: 0.9487 - precision: 0.9700 - recall: 0.9364 - val_loss: 0.6235 - val_acc: 0.8881 - val_precision: 0.9155 - val_recall: 0.8701\n",
      "139291/139291 [==============================] - 5s 34us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0891c0ae9a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "counts = trainDF['label'].value_counts().sort_index().to_frame()\n",
    "counts['category'] = counts.index\n",
    "counts['train_sample']=(counts['label']/2).astype(int)\n",
    "    \n",
    "train_df, test_df = np.split(trainDF, [int(.7*len(trainDF))])\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "train_posts = train_df['text']\n",
    "train_tags = train_df['label']\n",
    "test_posts = test_df['text']\n",
    "test_tags = test_df['label']\n",
    "vocab_size = 1000\n",
    
    "#precision & recall by: Other text preprocessing: https://keras.io/preprocessing/text/ \n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(train_posts)\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "    \n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "     Only computes a batch-wise average of recall.\n",
    "     Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "num_labels=len(train_df['label'].drop_duplicates())\n",
    "batch_size = 500\n",
    "epochs = 40\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dense(num_labels))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              #metrics=['accuracy'],\n",
    "             metrics=['acc', precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.1)\n",
    "    \n",
    "score = model.evaluate(x_test, y_test, \n",
    "                   batch_size=batch_size, verbose=1)\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c1b3a43c7140cb88b5caffbca41237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=139291), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#acc till 85: increases by 2% every epoch\n",
    "#acc 85 - 95: increases by 1% each epoch\n",
    "# 95 - 96: 4 epochs\n",
    "# 96 - 97: >18 epochs\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "all_pred = pd.DataFrame(columns=['EIN', 'text', 'actual_label', 'predicted_label', 'true_pred'])\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(x_test))):\n",
    "    prediction = model.predict(np.array([x_test[i]]))    \n",
    "    text_labels = encoder.classes_ \n",
    "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
    "    text = test_posts.iloc[i]\n",
    "    ein = trainDF[trainDF['text']==test_posts.iloc[i]]['EIN'].astype(int).drop_duplicates().tolist()\n",
    "    actual_label = trainDF[trainDF['text']==test_posts.iloc[i]]['label'].drop_duplicates().tolist()\n",
    "    if(predicted_label == test_tags.iloc[i]):\n",
    "        true_pred = 'true'\n",
    "    else:\n",
    "        true_pred = 'false'\n",
    "\n",
    "    all_pred.loc[len(all_pred)] = [ein, text, actual_label, predicted_label, true_pred]\n",
    "\n",
    "\n",
    "if(os.path.exists('../../data/classification_results/all_predictions_V3.pkl.gz')):\n",
    "    all_pred = pd.concat([pd.read_pickle('../../data/classification_results/all_predictions_V3.pkl.gz'), all_pred]).drop_duplicates()\n",
    "    \n",
    "all_pred.to_pickle('../../data/classification_results/all_predictions_V3.pkl.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      EIN  \\\n",
      "8                                             [205404353]   \n",
      "20                                            [330724044]   \n",
      "33                                            [352102110]   \n",
      "40                                            [911956621]   \n",
      "42                                            [260237807]   \n",
      "44                                            [954659261]   \n",
      "47                                            [510465035]   \n",
      "51                                            [942581062]   \n",
      "53                                            [990352548]   \n",
      "62                                            [311655576]   \n",
      "78                                            [232835435]   \n",
      "104                                           [742550748]   \n",
      "115                                           [200547957]   \n",
      "118                                           [205704991]   \n",
      "145                     [382780230, 581486729, 710815304]   \n",
      "146                     [382780230, 581486729, 710815304]   \n",
      "148                                           [953814185]   \n",
      "149                                           [200037972]   \n",
      "150                                           [200037992]   \n",
      "154                                           [800141935]   \n",
      "161                                           [841724342]   \n",
      "172          [133067236, 133227442, 133566484, 133760575]   \n",
      "174          [133067236, 133227442, 133566484, 133760575]   \n",
      "179                                           [208870624]   \n",
      "180     [411261639, 470744455, 272700701, 411954944, 4...   \n",
      "183     [205952939, 316402408, 111630900, 111633549, 3...   \n",
      "206                                           [134042178]   \n",
      "265                                           [350883520]   \n",
      "266                                           [912059167]   \n",
      "322                                           [133969722]   \n",
      "...                                                   ...   \n",
      "139235                                        [261422559]   \n",
      "139237                                        [133666642]   \n",
      "139238                                        [261200184]   \n",
      "139241                                        [571195947]   \n",
      "139242                                        [391594831]   \n",
      "139243                                        [166016486]   \n",
      "139246  [161774114, 237042291, 311011605, 391786897, 5...   \n",
      "139247                                        [205616611]   \n",
      "139248                                        [411638879]   \n",
      "139251                                        [205539938]   \n",
      "139254  [111630822, 261626902, 320265031, 330039466, 3...   \n",
      "139255                                        [271752838]   \n",
      "139256                                        [953411552]   \n",
      "139257                                        [141964306]   \n",
      "139261                                        [274757211]   \n",
      "139265                                        [300229747]   \n",
      "139266                                        [270448505]   \n",
      "139267                                        [453143506]   \n",
      "139268                                        [470745887]   \n",
      "139269                                        [556014875]   \n",
      "139270                                        [621638941]   \n",
      "139272                                        [942825440]   \n",
      "139274                                        [582526255]   \n",
      "139276                                        [990354745]   \n",
      "139277                                        [381753187]   \n",
      "139279                                        [770558977]   \n",
      "139280                                        [223098990]   \n",
      "139281                                        [631064191]   \n",
      "139282                                        [421564135]   \n",
      "139284                                        [593719177]   \n",
      "\n",
      "                                                     text  \\\n",
      "8       THE PRIMARY EXEMPT PURPOSE OF CHRIST COMMUNITY...   \n",
      "20      America On Track is an award-winning nonprofit...   \n",
      "33            To provide housing & arts to the community.   \n",
      "40      LEGACY'S MISSION IS TO BUILD A WORLD WHERE YOU...   \n",
      "42      For the Love of Chocolate Foundation provides ...   \n",
      "44      To develop comunity involvement in charitable ...   \n",
      "47      THE JOHNNY FOUNDATION SEEKS TO ENCOURAGE OTHER...   \n",
      "51      HALLECK CREEK RANCH IMPROVES THE LIVES OF BAY ...   \n",
      "53                  DEVELOP AFFORDABLE HOUSING IN HAWAII.   \n",
      "62      To provide a safe place for people to receive ...   \n",
      "78      THE COLLABORATIVE IS A VOLUNTEER-BASED COMMUNI...   \n",
      "104     THE MISSION OF FRIENDS FOR LIFE IS TO ASSIST T...   \n",
      "115     KENDAL NORTHERN OHIO WAS ESTABLISHED AS A SUPP...   \n",
      "118     The Carter Center Collaborative, Inc. (CCCI)wa...   \n",
      "145                                   SEE STATEMENT BELOW   \n",
      "146                                   SEE STATEMENT BELOW   \n",
      "148     RCHRC conducts medical research,develops clini...   \n",
      "149     SOLE MEMBER AND HOLDING COMPANY FOR 4 EXEMPT O...   \n",
      "150     TO OWN AND MAINTAIN THE REAL PROPERTY CONVEYED...   \n",
      "154     ORGANIZING, TRAINING AND PLAYING GRADE SCHOOL ...   \n",
      "161     MACC CommonWealth supports the mission of MACC...   \n",
      "172     TO PROVIDE AFFORDABLE HOUSING TO THE LOW INCOM...   \n",
      "174     TO PROVIDE AFFORDABLE HOUSING TO THE LOW INCOM...   \n",
      "179     NURTURING MINDS, INC.'S MISSION IS TO PROVIDE ...   \n",
      "180                                  COMMUNITY BETTERMENT   \n",
      "183                                        SEE SCHEDULE O   \n",
      "206                     TO PROVIDE INTERNSHIPS FOR WOMEN.   \n",
      "265     THE ORGANIZATION IS A CHRIST-CENTERED ORGANIZA...   \n",
      "266     The mission is to assure the development of th...   \n",
      "322     The What to Expect Foundation provides empower...   \n",
      "...                                                   ...   \n",
      "139235  TUMBLEWEED BOYS RANCH'S MISSION IS TO EMPOWER ...   \n",
      "139237                      TO PROVIDE CULTURAL EDUCATION   \n",
      "139238  TO OPERATE A NONCOMMERCIAL EDUCATIONAL BROADCA...   \n",
      "139241  To serve as a community centered provider of s...   \n",
      "139242  THE SBAWI SERVES WISCONSIN INDIVIDUALS WITH SP...   \n",
      "139243  SUPPORT THE BOY SCOUTS OF AMERICA SENECA WATER...   \n",
      "139246                            ENVIRONMENTAL EDUCATION   \n",
      "139247  THE FOUNDATIONS MISSION IS TO PROVIDE SUPPORT ...   \n",
      "139248  Provide direct services to parents with presch...   \n",
      "139251  THE ORGAINZATION FUNCTIONS TO PROVIDE A LACROS...   \n",
      "139254                                    See Schedule O.   \n",
      "139255  THE FOUNDATION ENGAGES IN EDUCATIONAL, CHARITA...   \n",
      "139256                   To Support UNA San Diego Chapter   \n",
      "139257  BRING JEWISH TRADITIONS AND LIFE CYCLES TO THE...   \n",
      "139261  Our mission is to provide financial support to...   \n",
      "139265  The ARTreach mission is to support the develop...   \n",
      "139266  ADMINISTER THE NATIONAL STANDARDS FOR U.S. COM...   \n",
      "139267  HELPS PEOPLE WHO ARE UNINSURED OR UNDERINSURED...   \n",
      "139268                  ASSIST CEMETARY AND LOCAL MUSEUM.   \n",
      "139269  DISTRIBUTE TO FIRST PRESBYTERIAN CHURCH OF CHA...   \n",
      "139270  to support and promote Irish culture throughou...   \n",
      "139272  Classroom training in alternative health pract...   \n",
      "139274  TO EDUCATE THE PUBLIC ABOUT AVIATION BY SPONSO...   \n",
      "139276  TO ENCOURAGE AND PROMOTE CULTURE AND ARTS IN T...   \n",
      "139277  A nonprofit organization which assists young p...   \n",
      "139279  TO TEACH, PREACH, TRAIN AND EDUCATE PEOPLE EVE...   \n",
      "139280                             HISTIOCYTOSIS RESEARCH   \n",
      "139281  SERVES AS A HOST AND SPONSOR OF A CHARITY GOLF...   \n",
      "139282  Ventana del Soul's mission is to provide train...   \n",
      "139284  It's All About Kids is committed to providing ...   \n",
      "\n",
      "                                             actual_label predicted_label  \\\n",
      "8                                                     [E]               X   \n",
      "20                                                    [I]               F   \n",
      "33                                                    [B]               A   \n",
      "40                                                    [F]               T   \n",
      "42                                                    [X]               A   \n",
      "44                                                    [M]               T   \n",
      "47                                                    [X]               B   \n",
      "51                                                    [N]               D   \n",
      "53                                                    [P]               L   \n",
      "62                                                 [E, P]               E   \n",
      "78                                                    [S]               W   \n",
      "104                                                   [E]               P   \n",
      "115                                                [E, P]               E   \n",
      "118                                                [J, Q]               J   \n",
      "145                                             [I, T, S]               P   \n",
      "146                                             [I, T, S]               P   \n",
      "148                                                   [H]               G   \n",
      "149                                                   [P]               T   \n",
      "150                                                   [P]               T   \n",
      "154                                                   [N]               B   \n",
      "161                                                   [S]               P   \n",
      "172                                             [T, L, N]               L   \n",
      "174                                             [T, L, N]               L   \n",
      "179                                                [Q, B]               Q   \n",
      "180                                    [P, T, S, B, J, E]               S   \n",
      "183     [B, A, P, E, C, X, D, L, G, U, W, Q, S, J, T, ...               E   \n",
      "206                                                   [B]               P   \n",
      "265                                                   [P]               B   \n",
      "266                                                   [H]               G   \n",
      "322                                                   [E]               B   \n",
      "...                                                   ...             ...   \n",
      "139235                                                [F]               O   \n",
      "139237                                                [A]               P   \n",
      "139238                                                [A]               B   \n",
      "139241                                                [B]               P   \n",
      "139242                                                [G]               T   \n",
      "139243                                                [T]               O   \n",
      "139246                                       [A, C, U, X]               C   \n",
      "139247                                                [P]               N   \n",
      "139248                                                [P]               O   \n",
      "139251                                                [N]               B   \n",
      "139254  [B, Q, E, A, P, X, F, T, N, W, Y, I, U, S, L, ...               E   \n",
      "139255                                                [S]               T   \n",
      "139256                                                [Q]               P   \n",
      "139257                                                [A]               T   \n",
      "139261                                                [P]               Q   \n",
      "139265                                                [A]               I   \n",
      "139266                                                [T]               W   \n",
      "139267                                                [N]               G   \n",
      "139268                                                [T]               A   \n",
      "139269                                                [T]               X   \n",
      "139270                                                [A]               N   \n",
      "139272                                                [B]               E   \n",
      "139274                                                [U]               A   \n",
      "139276                                                [A]               S   \n",
      "139277                                                [O]               P   \n",
      "139279                                                [J]               P   \n",
      "139280                                                [A]               H   \n",
      "139281                                                [B]               T   \n",
      "139282                                                [O]               Q   \n",
      "139284                                                [P]               B   \n",
      "\n",
      "       true_pred  \n",
      "8          false  \n",
      "20         false  \n",
      "33         false  \n",
      "40         false  \n",
      "42         false  \n",
      "44         false  \n",
      "47         false  \n",
      "51         false  \n",
      "53         false  \n",
      "62         false  \n",
      "78         false  \n",
      "104        false  \n",
      "115        false  \n",
      "118        false  \n",
      "145        false  \n",
      "146        false  \n",
      "148        false  \n",
      "149        false  \n",
      "150        false  \n",
      "154        false  \n",
      "161        false  \n",
      "172        false  \n",
      "174        false  \n",
      "179        false  \n",
      "180        false  \n",
      "183        false  \n",
      "206        false  \n",
      "265        false  \n",
      "266        false  \n",
      "322        false  \n",
      "...          ...  \n",
      "139235     false  \n",
      "139237     false  \n",
      "139238     false  \n",
      "139241     false  \n",
      "139242     false  \n",
      "139243     false  \n",
      "139246     false  \n",
      "139247     false  \n",
      "139248     false  \n",
      "139251     false  \n",
      "139254     false  \n",
      "139255     false  \n",
      "139256     false  \n",
      "139257     false  \n",
      "139261     false  \n",
      "139265     false  \n",
      "139266     false  \n",
      "139267     false  \n",
      "139268     false  \n",
      "139269     false  \n",
      "139270     false  \n",
      "139272     false  \n",
      "139274     false  \n",
      "139276     false  \n",
      "139277     false  \n",
      "139279     false  \n",
      "139280     false  \n",
      "139281     false  \n",
      "139282     false  \n",
      "139284     false  \n",
      "\n",
      "[18978 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_pred[all_pred.true_pred==\"false\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
