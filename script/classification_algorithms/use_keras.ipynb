{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# [Keras + Universal Sentence Encoder = Transfer Learning for text data](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) Tutorial\n",
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha",
    "outputId": "62db0062-49cf-4b42-efb4-71a314157c69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "#import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "MElqkcDiDKsp",
    "outputId": "2dcf04b0-c631-484c-9137-363fae821197"
   },
   "outputs": [],
   "source": [
    "file_list=os.listdir('../../dataset/df_train.pkl.gz/')\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, \n",
    "                        pd.read_pickle('../../dataset/df_train.pkl.gz/'+file, compression='gzip')])\n",
    "df_train['mission_prgrm']=df_train['mission']+'; '+df_train['prgrm_dsc']\n",
    "\n",
    "small_num=0\n",
    "while small_num<100: # Make sure each category has at least 100 records.\n",
    "    trainDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(40000)\n",
    "    small_num=trainDF.groupby('NTEE1').count().sort_values('EIN').iloc[0]['EIN']\n",
    "    \n",
    "#### Shuffle ####\n",
    "trainDF = trainDF.sample(frac=1)\n",
    "\n",
    "X = trainDF['mission_prgrm'].apply(lambda x: x.split())\n",
    "\n",
    "Y = []\n",
    "for one in X.values:\n",
    "    if(len(one)<100):\n",
    "        one = one + (['NaN']*(100-len(one)))\n",
    "    else:\n",
    "        one = one[:100]\n",
    "    Y.append(one)\n",
    "\n",
    "trainDF['missionprgrm'] = Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1851452</th>\n",
       "      <td>[TO, PROMOTE, THE, PROPAGATION, OF, WILDLIFE,,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643413</th>\n",
       "      <td>[FRIENDS, SCHOOL, IS, AN, INDEPENDENT,, COEDUC...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165595</th>\n",
       "      <td>[Encourage, High, School, seniors, to, explore...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424733</th>\n",
       "      <td>[TO, COORDINATE, AND, PROMOTE, THE, GROWTH, OF...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571969</th>\n",
       "      <td>[TO, PROVIDE, RELIEF, TO, POOR,, DISTRESSED, A...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text label\n",
       "1851452  [TO, PROMOTE, THE, PROPAGATION, OF, WILDLIFE,,...     N\n",
       "1643413  [FRIENDS, SCHOOL, IS, AN, INDEPENDENT,, COEDUC...     B\n",
       "1165595  [Encourage, High, School, seniors, to, explore...     B\n",
       "424733   [TO, COORDINATE, AND, PROMOTE, THE, GROWTH, OF...     N\n",
       "571969   [TO, PROVIDE, RELIEF, TO, POOR,, DISTRESSED, A...     P"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_train['text'] = trainDF['missionprgrm'][:35000]\n",
    "df_train['label'] = trainDF['NTEE1'][:35000].astype('category')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3HAtd4X5DayF",
    "outputId": "73ada7e8-e7c9-48d7-de4e-97874207a60d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = len(df_train.label.cat.categories)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sf9A4Xl6J7c6"
   },
   "source": [
    "## Wrap embed module in a Lambda layer\n",
    "Explicitly cast the input as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ube1DvYEJ3q"
   },
   "outputs": [],
   "source": [
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.asarray(train_text, dtype=object)\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)\n",
    "#train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WX3s8yIVFWHI",
    "outputId": "5468a7ae-f1c3-4019-8f76-91dab02ec482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9PfsPdG8FZBI",
    "outputId": "b7d95197-8bad-4280-fc43-5a2e2373f1f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9MJnOnKI6F0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1923689</th>\n",
       "      <td>[IN, AN, ENVIRONMENT, OF, CHRISTIAN, LOVE, AND...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282676</th>\n",
       "      <td>[PROVIDE, A, MEETING, PLACE, FOR, AND, ASSISTA...</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121670</th>\n",
       "      <td>[TO, RAISE, FUNDS, TO, ASSIST, OTHER, ONN-PROF...</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997700</th>\n",
       "      <td>[PROVIDE, SUPPORT, TO, THE, SIGMA, ALPHA, EPSI...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360642</th>\n",
       "      <td>[TO, PROVIDE, HOUSING, TO, THE, ELDERLY, OR, D...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text label\n",
       "1923689  [IN, AN, ENVIRONMENT, OF, CHRISTIAN, LOVE, AND...     P\n",
       "2282676  [PROVIDE, A, MEETING, PLACE, FOR, AND, ASSISTA...     W\n",
       "1121670  [TO, RAISE, FUNDS, TO, ASSIST, OTHER, ONN-PROF...     W\n",
       "1997700  [PROVIDE, SUPPORT, TO, THE, SIGMA, ALPHA, EPSI...     B\n",
       "2360642  [TO, PROVIDE, HOUSING, TO, THE, ELDERLY, OR, D...     L"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['text'] = trainDF['missionprgrm'][35000:]\n",
    "df_test['label'] = trainDF['NTEE1'][35000:].astype('category')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWAjtjdeI9P4"
   },
   "outputs": [],
   "source": [
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.asarray(test_text, dtype=object)\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "embed = hub.Module(module_url, trainable=False, name='text_embedding')\n",
    "\n",
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
    "\n",
    "SEQ_LENGTH = 100\n",
    "EMBEDDING_DIM = embed_size\n",
    "\n",
    "def Embed_sentence(sentences):\n",
    "    batch_size = tf.shape(sentences)[0]\n",
    "    flat_sentences = tf.reshape(sentences, [-1])\n",
    "    embeddings = embed(tf.squeeze(tf.cast(flat_sentences, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "    sentence_embedding = tf.reshape(embeddings, [batch_size, SEQ_LENGTH, EMBEDDING_DIM])\n",
    "    return sentence_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 2,922,777\n",
      "Trainable params: 2,922,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = layers.Input(shape=(100,), dtype=tf.string)\n",
    "embedding = layers.Lambda(Embed_sentence)(input_text)\n",
    "lstm = layers.LSTM(units=512, return_sequences=True, activation='tanh')(embedding)\n",
    "lstm2 = layers.LSTM(units=256, return_sequences=False, activation='tanh')(lstm)\n",
    "drp = layers.Dropout(0.5)(lstm2)\n",
    "pred = layers.Dense(128, activation='tanh')(drp)\n",
    "#conv = layers.GRU(units=512, activation='tanh', return_sequences=True)(embedding)\n",
    "#conv2 = layers.GRU(units=256, activation='tanh', return_sequences=True)(conv)\n",
    "#conv3 = layers.GRU(units=128, activation='tanh', return_sequences=False)(conv2)\n",
    "#drp = layers.Dropout(0.1)(conv3)\n",
    "#dense = layers.Dense(128, activation='tanh')(drp)\n",
    "pred1 = layers.Dense(category_counts, activation='softmax')(pred)\n",
    "model = Model(inputs=[input_text], outputs=pred1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqcRy_JWXe0u"
   },
   "source": [
    "## Train Keras model and save weights\n",
    "This only train and save our Keras layers not the embed module' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "_stfC_7VFhS8",
    "outputId": "09262f88-ed9d-4f2a-bda1-7112d0a219b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "35000/35000 [==============================] - 205s 6ms/step - loss: 2.8824 - acc: 0.1378 - val_loss: 2.8249 - val_acc: 0.1628\n",
      "Epoch 2/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.8391 - acc: 0.1553 - val_loss: 2.8250 - val_acc: 0.1628\n",
      "Epoch 3/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.8050 - acc: 0.1654 - val_loss: 2.8105 - val_acc: 0.1628\n",
      "Epoch 4/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.8020 - acc: 0.1679 - val_loss: 2.8167 - val_acc: 0.1634\n",
      "Epoch 5/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.7882 - acc: 0.1733 - val_loss: 2.8431 - val_acc: 0.1460\n",
      "Epoch 6/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 2.7475 - acc: 0.1786 - val_loss: 2.8034 - val_acc: 0.1586\n",
      "Epoch 7/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.7010 - acc: 0.1890 - val_loss: 2.5687 - val_acc: 0.2098\n",
      "Epoch 8/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 2.5886 - acc: 0.2091 - val_loss: 2.4987 - val_acc: 0.2326\n",
      "Epoch 9/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.5576 - acc: 0.2266 - val_loss: 2.5226 - val_acc: 0.2222\n",
      "Epoch 10/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 2.4745 - acc: 0.2578 - val_loss: 2.8148 - val_acc: 0.1976\n",
      "Epoch 11/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 2.4476 - acc: 0.2775 - val_loss: 2.3848 - val_acc: 0.2956\n",
      "Epoch 12/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.3302 - acc: 0.3308 - val_loss: 2.1810 - val_acc: 0.3886\n",
      "Epoch 13/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.1724 - acc: 0.3907 - val_loss: 2.2096 - val_acc: 0.3832\n",
      "Epoch 14/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 2.0952 - acc: 0.4104 - val_loss: 2.0865 - val_acc: 0.3916\n",
      "Epoch 15/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 1.9876 - acc: 0.4414 - val_loss: 1.9751 - val_acc: 0.4390\n",
      "Epoch 16/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 1.9287 - acc: 0.4615 - val_loss: 1.8364 - val_acc: 0.4854\n",
      "Epoch 17/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 1.8743 - acc: 0.4760 - val_loss: 1.9221 - val_acc: 0.4488\n",
      "Epoch 18/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 1.7706 - acc: 0.5016 - val_loss: 1.8331 - val_acc: 0.4888\n",
      "Epoch 19/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 1.7260 - acc: 0.5175 - val_loss: 1.6643 - val_acc: 0.5360\n",
      "Epoch 20/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 1.6514 - acc: 0.5463 - val_loss: 1.6088 - val_acc: 0.5606\n",
      "Epoch 21/30\n",
      "35000/35000 [==============================] - 196s 6ms/step - loss: 1.5899 - acc: 0.5622 - val_loss: 1.5721 - val_acc: 0.5802\n",
      "Epoch 22/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 1.5285 - acc: 0.5821 - val_loss: 1.6157 - val_acc: 0.5562\n",
      "Epoch 23/30\n",
      "35000/35000 [==============================] - 195s 6ms/step - loss: 1.4803 - acc: 0.5958 - val_loss: 1.4588 - val_acc: 0.6048\n",
      "Epoch 24/30\n",
      " 1000/35000 [..............................] - ETA: 2:53 - loss: 1.3749 - acc: 0.6340"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d19c87eb3194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             batch_size=1000)\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=30,\n",
    "            batch_size=1000)\n",
    "  model.save_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UW1CiBhnXnxa",
    "outputId": "1c9f90b9-3757-461e-d06e-076e524bd792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 isha isha  12M Dec 20 02:46 model.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -alh | grep model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQux6qLdXabG"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSDxetlfUEiD"
   },
   "outputs": [],
   "source": [
    "new_text = [\"Mission statement\"]\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./model.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning - Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
