{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# [Keras + Universal Sentence Encoder = Transfer Learning for text data](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) Tutorial\n",
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha",
    "outputId": "62db0062-49cf-4b42-efb4-71a314157c69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O2cYc2WEkSGP",
    "outputId": "627031de-f995-4bf8-fe55-b8837ff33356"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "MElqkcDiDKsp",
    "outputId": "2dcf04b0-c631-484c-9137-363fae821197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66185</th>\n",
       "      <td>DISASTER RELIEF FOR HAITI. THIS IS AN OFFSHOOT...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482050</th>\n",
       "      <td>PROVIDE AFFORDABLE AND SAFE HOUSING FOR ADULTS...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89888</th>\n",
       "      <td>Promote literacy through book ownership; For t...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122953</th>\n",
       "      <td>To advance the art and craft of writing by enc...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580623</th>\n",
       "      <td>DEFEND AND EDUCATE MEMBERSHIP; DEFENDED THE ME...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "66185   DISASTER RELIEF FOR HAITI. THIS IS AN OFFSHOOT...     X\n",
       "482050  PROVIDE AFFORDABLE AND SAFE HOUSING FOR ADULTS...     L\n",
       "89888   Promote literacy through book ownership; For t...     B\n",
       "122953  To advance the art and craft of writing by enc...     A\n",
       "580623  DEFEND AND EDUCATE MEMBERSHIP; DEFENDED THE ME...     J"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list=os.listdir('../../dataset/df_train.pkl.gz/')\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, \n",
    "                        pd.read_pickle('../../dataset/df_train.pkl.gz/'+file, compression='gzip')])\n",
    "df_train['mission_prgrm']=df_train['mission']+'; '+df_train['prgrm_dsc']\n",
    "\n",
    "small_num=0\n",
    "while small_num<100: # Make sure each category has at least 100 records.\n",
    "    trainDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(40000)\n",
    "    small_num=trainDF.groupby('NTEE1').count().sort_values('EIN').iloc[0]['EIN']\n",
    "    \n",
    "#### Shuffle ####\n",
    "trainDF = trainDF.sample(frac=1)\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_train['text'] = trainDF['mission_prgrm'][:35000]\n",
    "df_train['label'] = trainDF['NTEE1'][:35000].astype('category')\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3HAtd4X5DayF",
    "outputId": "73ada7e8-e7c9-48d7-de4e-97874207a60d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
       "       'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = len(df_train.label.cat.categories)\n",
    "category_counts\n",
    "df_train.label.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sf9A4Xl6J7c6"
   },
   "source": [
    "## Wrap embed module in a Lambda layer\n",
    "Explicitly cast the input as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRD3fWgJjOrP"
   },
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ube1DvYEJ3q"
   },
   "outputs": [],
   "source": [
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WX3s8yIVFWHI",
    "outputId": "5468a7ae-f1c3-4019-8f76-91dab02ec482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9PfsPdG8FZBI",
    "outputId": "b7d95197-8bad-4280-fc43-5a2e2373f1f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9MJnOnKI6F0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1608050</th>\n",
       "      <td>UCP OF CENTRAL FLORIDA IS A VOLUNTARY HEALTH A...</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371450</th>\n",
       "      <td>Educating Today ... Preserving for TomorrowOur...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191610</th>\n",
       "      <td>TO SUPPORT THE CHARITABLE AND EDUCATIONAL ACTI...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35700</th>\n",
       "      <td>THE MISSION OF MIDVALE ARTS COUNCIL, INC. IS T...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>OUR ORGANIZATION PROVIDES FOR THE OPERATION AN...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text label\n",
       "1608050  UCP OF CENTRAL FLORIDA IS A VOLUNTARY HEALTH A...     G\n",
       "1371450  Educating Today ... Preserving for TomorrowOur...     C\n",
       "2191610  TO SUPPORT THE CHARITABLE AND EDUCATIONAL ACTI...     P\n",
       "35700    THE MISSION OF MIDVALE ARTS COUNCIL, INC. IS T...     A\n",
       "9972     OUR ORGANIZATION PROVIDES FOR THE OPERATION AN...     M"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['text'] = trainDF['mission_prgrm'][35000:]\n",
    "df_test['label'] = trainDF['NTEE1'][35000:].astype('category')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWAjtjdeI9P4"
   },
   "outputs": [],
   "source": [
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 430,105\n",
      "Trainable params: 430,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "embedding1 = layers.Embedding(input_dim = 1000, output_dim = 512)(embedding)\n",
    "lstm = layers.GRU(units=512, activation='tanh', return_sequences=False)(embedding1)\n",
    "drp = layers.Dropout(0.2)(lstm)\n",
    "dense = layers.Dense(256, activation='tanh')(drp)\n",
    "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "dense1 = layers.Dense(512, activation='tanh')(embedding)\n",
    "dense2 = layers.Dense(256, activation='tanh')(dense1)\n",
    "dense3 = layers.Dense(128, activation = 'tanh')(dense2)\n",
    "pred = layers.Dense(category_counts, activation='softmax')(dense3)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])  #rmsprop: 71\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqcRy_JWXe0u"
   },
   "source": [
    "## Train Keras model and save weights\n",
    "This only train and save our Keras layers not the embed module' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "_stfC_7VFhS8",
    "outputId": "09262f88-ed9d-4f2a-bda1-7112d0a219b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "35000/35000 [==============================] - 153s 4ms/step - loss: 1.7178 - acc: 0.5322 - val_loss: 1.2748 - val_acc: 0.6548\n",
      "Epoch 2/10\n",
      "35000/35000 [==============================] - 144s 4ms/step - loss: 1.2268 - acc: 0.6629 - val_loss: 1.1910 - val_acc: 0.6726\n",
      "Epoch 3/10\n",
      "35000/35000 [==============================] - 144s 4ms/step - loss: 1.1589 - acc: 0.6794 - val_loss: 1.1378 - val_acc: 0.6904\n",
      "Epoch 4/10\n",
      "35000/35000 [==============================] - 147s 4ms/step - loss: 1.1186 - acc: 0.6894 - val_loss: 1.1326 - val_acc: 0.6928\n",
      "Epoch 5/10\n",
      "35000/35000 [==============================] - 149s 4ms/step - loss: 1.0997 - acc: 0.6943 - val_loss: 1.1208 - val_acc: 0.6960\n",
      "Epoch 6/10\n",
      "35000/35000 [==============================] - 147s 4ms/step - loss: 1.0814 - acc: 0.6991 - val_loss: 1.1024 - val_acc: 0.6968\n",
      "Epoch 7/10\n",
      "35000/35000 [==============================] - 139s 4ms/step - loss: 1.0700 - acc: 0.7006 - val_loss: 1.0797 - val_acc: 0.7056\n",
      "Epoch 8/10\n",
      "35000/35000 [==============================] - 143s 4ms/step - loss: 1.0525 - acc: 0.7061 - val_loss: 1.0778 - val_acc: 0.7044\n",
      "Epoch 9/10\n",
      "35000/35000 [==============================] - 139s 4ms/step - loss: 1.0472 - acc: 0.7056 - val_loss: 1.0657 - val_acc: 0.7076\n",
      "Epoch 10/10\n",
      "35000/35000 [==============================] - 142s 4ms/step - loss: 1.0342 - acc: 0.7118 - val_loss: 1.0774 - val_acc: 0.7026\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=10,\n",
    "            batch_size=1000)\n",
    "  model.save_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UW1CiBhnXnxa",
    "outputId": "1c9f90b9-3757-461e-d06e-076e524bd792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 534K Jun 10 03:54 model.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -alh | grep model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQux6qLdXabG"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSDxetlfUEiD"
   },
   "outputs": [],
   "source": [
    "new_text = [\"Mission statement\"]\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./model.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning - Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
