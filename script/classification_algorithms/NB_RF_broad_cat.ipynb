{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from imblearn.metrics import make_index_balanced_accuracy as iba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154424"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path='../../dataset/df_ntee_universal/train/'\n",
    "file_list=os.listdir(train_file_path)\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, pd.read_pickle(train_file_path+file, compression='gzip')])\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154424, 25, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code as 10 broad categories.\n",
    "broad_cat_dict={'I': ['A'],\n",
    "                'II': ['B'],\n",
    "                'III': ['C', 'D'],\n",
    "                'IV': ['E', 'F', 'G', 'H'],\n",
    "                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                'VI': ['Q'],\n",
    "                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                'VIII': ['X'],\n",
    "                'IX': ['Y'],\n",
    "                'X': ['Z'],\n",
    "               }\n",
    "def ntee2cat(string):\n",
    "    global broad_cat_dict\n",
    "    return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n",
    "\n",
    "df_train['mission_prgrm']=df_train['TAXPAYER_NAME']+' '+df_train['mission']+' '+df_train['prgrm_dsc']\n",
    "df_train['mission_prgrm_spellchk']=df_train['TAXPAYER_NAME']+' '+df_train['mission_spellchk']+' '+df_train['prgrm_dsc_spellchk'] # Using spell-checked.\n",
    "df_train['broad_cat']=df_train['NTEE1'].apply(ntee2cat)\n",
    "len(df_train['mission_prgrm_spellchk']), len(df_train['NTEE1'].drop_duplicates()), len(df_train['broad_cat'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broad_cat\n",
      "I       13568\n",
      "II      20593\n",
      "III      6051\n",
      "IV      13527\n",
      "IX       5321\n",
      "V       37404\n",
      "VI       1577\n",
      "VII     21872\n",
      "VIII     3626\n",
      "Name: EIN, dtype: int64 \n",
      "\n",
      " broad_cat\n",
      "I       3442\n",
      "II      5234\n",
      "III     1511\n",
      "IV      3309\n",
      "IX      1319\n",
      "V       9330\n",
      "VI       410\n",
      "VII     5390\n",
      "VIII     940\n",
      "Name: EIN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Check if the sampling criteria can be satisfied.\n",
    "# small_num=0\n",
    "# while small_num<500: # Make sure each category in training dataset has at least 500 records.\n",
    "#     trainDF, valDF = model_selection.train_test_split(df_train, test_size=.2)\n",
    "#     small_num=trainDF.groupby('broad_cat').count().sort_values('EIN').iloc[0]['EIN']\n",
    "\n",
    "trainDF, testDF = model_selection.train_test_split(df_train, test_size=.2)\n",
    "# See the composition by broad category.\n",
    "print(trainDF.groupby('broad_cat').count()['EIN'], '\\n'*2, testDF.groupby('broad_cat').count()['EIN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Prepare classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine vectorizer.\n",
    "def text_vectorizer(tokenizer_type=None, vectorizer_type=None):\n",
    "    ########################################################\n",
    "    ######### Define and choose tokenizers #################\n",
    "    def porter_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "        tokens = word_tokenize(str_input)\n",
    "        return [PorterStemmer().stem(token) for token in tokens]\n",
    "    # Lemmatize using POS tags, assume improving accuracy.\n",
    "    # Ref: \n",
    "    #   - https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "    #   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "    def lemma_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "        tokens=word_tokenize(str_input)\n",
    "        return [WordNetLemmatizer().lemmatize(word=word, pos=get_wordnet_pos(pos)) for word, pos in nltk.pos_tag(tokens)]\n",
    "    # Choose tokenizer using parameter passed.\n",
    "    if tokenizer_type=='lemma':\n",
    "        tokenizer=lemma_tokenizer\n",
    "    elif tokenizer_type=='porter':\n",
    "        tokenizer=porter_tokenizer\n",
    "    ########################################################\n",
    "    ######### Define and choose vectorizer #################\n",
    "    # 1. Use word level, character level does not make sense for current situation.\n",
    "    # 2. Use count (freq) and tf-idf vectorizer. see: \n",
    "    # Bengfort, B., Bilbro, R., & Ojeda, T. (2018). Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning (1 edition). Beijing Boston Farnham Sebastopol Tokyo: Oâ€™Reilly Media.\n",
    "    # Page: 67.\n",
    "    if vectorizer_type=='count':\n",
    "        ##### Token counts #####\n",
    "        vectorizer = CountVectorizer(stop_words='english', \n",
    "                                     tokenizer=tokenizer, \n",
    "                                     analyzer='word'\n",
    "                                    )\n",
    "        return vectorizer\n",
    "    elif vectorizer_type=='tfidf':\n",
    "        ##### TF-IDF #####\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                     tokenizer=tokenizer, \n",
    "                                     analyzer='word'\n",
    "                                    )\n",
    "        return vectorizer\n",
    "    ########################################################\n",
    "\n",
    "# Define resample strategy.\n",
    "def func_resample(method, sampling_strategy, x_train_vect, y_train, categorical_features):\n",
    "    if method=='ADASYN':\n",
    "        from imblearn.over_sampling import ADASYN\n",
    "        resample = ADASYN(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    elif method=='RandomOverSampler':\n",
    "        from imblearn.over_sampling import RandomOverSampler\n",
    "        resample = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    elif method=='SMOTE':\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        resample = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    # SMOTENC not used.\n",
    "    # --> 947         X_continuous = check_array(X_continuous, accept_sparse=['csr', 'csc'])\n",
    "    # ...\n",
    "    # ValueError: Found array with 0 feature(s) (shape=(123539, 0)) while a minimum of 1 is required.\n",
    "    # Must have continuous feature, but all features (columns) in x_train_vect are specified as categorical.\n",
    "#     elif method=='SMOTENC':\n",
    "#         from imblearn.over_sampling import SMOTENC\n",
    "#         resample = SMOTENC(sampling_strategy=sampling_strategy, random_state=42, categorical_features=categorical_features)\n",
    "    elif method=='SMOTEENN':\n",
    "        from imblearn.combine import SMOTEENN\n",
    "        resample = SMOTEENN(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    elif method=='SMOTETomek':\n",
    "        from imblearn.combine import SMOTETomek\n",
    "        resample = SMOTETomek(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    x_train_vect_res, y_train_res = resample.fit_resample(x_train_vect, y_train)\n",
    "    return [x_train_vect_res, y_train_res]\n",
    "\n",
    "# Compile the workflow as a function.\n",
    "def func_classifier(param_list):\n",
    "    global gmean, iba, lb\n",
    "    # Pass parameters.\n",
    "    x_train, y_train, x_test, y_test, resample_method, sampling_strategy, classifier, tokenizer, vect_type = param_list\n",
    "    # Encode text input.\n",
    "    vectorizer=text_vectorizer(tokenizer_type=tokenizer, vectorizer_type=vect_type)\n",
    "    vectorizer.fit(x_train.append(x_test)) # Fit on all texts.\n",
    "    x_train_vect=vectorizer.transform(x_train)\n",
    "    x_test_vect=vectorizer.transform(x_test)\n",
    "    # Encode class labels -- Not necessary for NB/RF algorithms: https://stats.stackexchange.com/questions/288095/what-algorithms-require-one-hot-encoding\n",
    "    # See test results below.\n",
    "#     y_train_vect=le.fit_transform(y_train)\n",
    "#     y_test_vect=le.fit_transform(y_test)\n",
    "    # Resample imbalanced dataset.\n",
    "    categorical_features=list(range(0, x_train_vect.shape[1])) # All indices are categorical.\n",
    "    resample_x_y=func_resample(method=resample_method, sampling_strategy=sampling_strategy,\n",
    "                               x_train_vect=x_train_vect, y_train=y_train, categorical_features=categorical_features)\n",
    "    classifier.fit(resample_x_y[0], resample_x_y[1])\n",
    "    predictions = classifier.predict(x_test_vect)\n",
    "    gmean = iba(alpha=0.1, squared=True)(gmean)\n",
    "\n",
    "    return {'resample_method':resample_method,\n",
    "            'sampling_strategy':sampling_strategy,\n",
    "            'classifier':str(classifier), \n",
    "            'tokenizer':tokenizer, \n",
    "            'vect_type':vect_type, \n",
    "            'weighted_acc': gmean(y_true=y_test, y_pred=predictions, average='weighted')\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameter combinations: 240\n"
     ]
    }
   ],
   "source": [
    "param_llist=[]\n",
    "x_train, y_train, x_test, y_test = [trainDF['mission_prgrm_spellchk'], trainDF['broad_cat'],\n",
    "                                    testDF['mission_prgrm_spellchk'], testDF['broad_cat']]\n",
    "for resample_method in ['ADASYN', 'RandomOverSampler', 'SMOTE', 'SMOTEENN', 'SMOTETomek']:\n",
    "    for sampling_strategy in ['minority','not minority','not majority','all']:\n",
    "        for classifier in [naive_bayes.MultinomialNB(), naive_bayes.ComplementNB(), ensemble.RandomForestClassifier()]:\n",
    "            for tokenizer in ['lemma', 'porter']:\n",
    "                for vect_type in ['count', 'tfidf']:\n",
    "                    param_llist+=[[x_train, y_train, x_test, y_test, resample_method, sampling_strategy, classifier, tokenizer, vect_type]]\n",
    "print('total parameter combinations:', len(param_llist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_llist_1, param_llist_2, param_llist_3, param_llist_4, param_llist_5 = [param_llist[0:48], param_llist[48:48*2], param_llist[48*2:48*3], \n",
    "                                                                             param_llist[48*3:48*4], param_llist[48*4:48*5],\n",
    "                                                                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Pool(48)\n",
    "result_dicts=p.map(func_classifier, param_llist_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>resample_method</th>\n",
       "      <th>sampling_strategy</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>vect_type</th>\n",
       "      <th>weighted_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.742963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.530346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.739831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.519062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.751159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.717964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.746316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.716104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.627893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.650016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.612114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.738989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.715056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.736228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.710769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.733769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.679679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.727628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.673097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.626898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.650202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.629366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.639070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.741549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.714877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.738310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.737526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.676512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.730662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.670489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.631711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.650961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.626131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>not majority</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.642838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.741549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.714877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.738310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.737526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.676512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.730662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.670489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.631711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>lemma</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.650961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.626131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>all</td>\n",
       "      <td>porter</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.642838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           classifier resample_method  \\\n",
       "0   MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "1   MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "2   MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "3   MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "4   ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "5   ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "6   ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "7   ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "8   RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "9   RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "10  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "11  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "12  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "13  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "14  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "15  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "16  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "17  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "18  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "19  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "20  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "21  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "22  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "23  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "24  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "25  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "26  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "27  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "28  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "29  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "30  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "31  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "32  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "33  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "34  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "35  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "36  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "37  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "38  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "39  MultinomialNB(alpha=1.0, class_prior=None, fit...          ADASYN   \n",
       "40  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "41  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "42  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "43  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "44  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "45  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "46  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "47  RandomForestClassifier(bootstrap=True, class_w...          ADASYN   \n",
       "\n",
       "   sampling_strategy tokenizer vect_type  weighted_acc  \n",
       "0           minority     lemma     count      0.742963  \n",
       "1           minority     lemma     tfidf      0.530346  \n",
       "2           minority    porter     count      0.739831  \n",
       "3           minority    porter     tfidf      0.519062  \n",
       "4           minority     lemma     count      0.751159  \n",
       "5           minority     lemma     tfidf      0.717964  \n",
       "6           minority    porter     count      0.746316  \n",
       "7           minority    porter     tfidf      0.716104  \n",
       "8           minority     lemma     count      0.627893  \n",
       "9           minority     lemma     tfidf      0.650016  \n",
       "10          minority    porter     count      0.612114  \n",
       "11          minority    porter     tfidf      0.635964  \n",
       "12      not minority     lemma     count      0.738989  \n",
       "13      not minority     lemma     tfidf      0.715056  \n",
       "14      not minority    porter     count      0.736228  \n",
       "15      not minority    porter     tfidf      0.710769  \n",
       "16      not minority     lemma     count      0.733769  \n",
       "17      not minority     lemma     tfidf      0.679679  \n",
       "18      not minority    porter     count      0.727628  \n",
       "19      not minority    porter     tfidf      0.673097  \n",
       "20      not minority     lemma     count      0.626898  \n",
       "21      not minority     lemma     tfidf      0.650202  \n",
       "22      not minority    porter     count      0.629366  \n",
       "23      not minority    porter     tfidf      0.639070  \n",
       "24      not majority     lemma     count      0.741549  \n",
       "25      not majority     lemma     tfidf      0.714877  \n",
       "26      not majority    porter     count      0.738310  \n",
       "27      not majority    porter     tfidf      0.710700  \n",
       "28      not majority     lemma     count      0.737526  \n",
       "29      not majority     lemma     tfidf      0.676512  \n",
       "30      not majority    porter     count      0.730662  \n",
       "31      not majority    porter     tfidf      0.670489  \n",
       "32      not majority     lemma     count      0.631711  \n",
       "33      not majority     lemma     tfidf      0.650961  \n",
       "34      not majority    porter     count      0.626131  \n",
       "35      not majority    porter     tfidf      0.642838  \n",
       "36               all     lemma     count      0.741549  \n",
       "37               all     lemma     tfidf      0.714877  \n",
       "38               all    porter     count      0.738310  \n",
       "39               all    porter     tfidf      0.710700  \n",
       "40               all     lemma     count      0.737526  \n",
       "41               all     lemma     tfidf      0.676512  \n",
       "42               all    porter     count      0.730662  \n",
       "43               all    porter     tfidf      0.670489  \n",
       "44               all     lemma     count      0.631711  \n",
       "45               all     lemma     tfidf      0.650961  \n",
       "46               all    porter     count      0.626131  \n",
       "47               all    porter     tfidf      0.642838  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_dicts).to_pickle('../../output/df_result_dicts_broad_cat_1.pkl')\n",
    "pd.DataFrame(result_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "## Try encoding/not encoding label, almost identical.\n",
    "# Label not encoded experiment 1.\n",
    "In : func_classifier(param_list=param_llist[3])\n",
    "Out: {'resample_method': 'ADASYN',\n",
    "      'sampling_strategy': 'minority',\n",
    "      'classifier': 'MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)',\n",
    "      'tokenizer': 'porter',\n",
    "      'vect_type': 'tfidf',\n",
    "      'weighted_acc': 0.49227231236613467}\n",
    "    \n",
    "# Label not encoded experiment 2.\n",
    "In : func_classifier(param_list=param_llist[3])\n",
    "Out: {'resample_method': 'ADASYN',\n",
    "      'sampling_strategy': 'minority',\n",
    "      'classifier': 'MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)',\n",
    "      'tokenizer': 'porter',\n",
    "      'vect_type': 'tfidf',\n",
    "      'weighted_acc': 0.5016141725625118}\n",
    "\n",
    "# Label encoded experiment 1.\n",
    "In : func_classifier(param_list=param_llist[3])\n",
    "Out: {'resample_method': 'ADASYN',\n",
    "      'sampling_strategy': 'minority',\n",
    "      'classifier': 'MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)',\n",
    "      'tokenizer': 'porter',\n",
    "      'vect_type': 'tfidf',\n",
    "      'weighted_acc': 0.5070028997209108}\n",
    "    \n",
    "# Label encoded experiment 2.\n",
    "In : func_classifier(param_list=param_llist[3])\n",
    "Out: {'resample_method': 'ADASYN',\n",
    "      'sampling_strategy': 'minority',\n",
    "      'classifier': 'MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)',\n",
    "      'tokenizer': 'porter',\n",
    "      'vect_type': 'tfidf',\n",
    "      'weighted_acc': 0.5015052917827343}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='../../output/result_dicts/'\n",
    "result_file_list=[s for s in os.listdir(folder_path) if 'broad' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>resample_method</th>\n",
       "      <th>sampling_strategy</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>vect_type</th>\n",
       "      <th>weighted_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.751159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.750759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>minority</td>\n",
       "      <td>lemma</td>\n",
       "      <td>count</td>\n",
       "      <td>0.750036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.746316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>minority</td>\n",
       "      <td>porter</td>\n",
       "      <td>count</td>\n",
       "      <td>0.746314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            classifier resample_method  \\\n",
       "100  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "148  ComplementNB(alpha=1.0, class_prior=None, fit_...      SMOTETomek   \n",
       "4    ComplementNB(alpha=1.0, class_prior=None, fit_...           SMOTE   \n",
       "102  ComplementNB(alpha=1.0, class_prior=None, fit_...          ADASYN   \n",
       "150  ComplementNB(alpha=1.0, class_prior=None, fit_...      SMOTETomek   \n",
       "\n",
       "    sampling_strategy tokenizer vect_type  weighted_acc  \n",
       "100          minority     lemma     count      0.751159  \n",
       "148          minority     lemma     count      0.750759  \n",
       "4            minority     lemma     count      0.750036  \n",
       "102          minority    porter     count      0.746316  \n",
       "150          minority    porter     count      0.746314  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results=pd.concat([pd.read_pickle(folder_path+file_name) for file_name in result_file_list], ignore_index=True)\n",
    "df_results.sort_values('weighted_acc', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain model using 100% UCF-Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_classifier(param_list):\n",
    "    global trainDF, valDF\n",
    "    input_text, classifier, tokenizer, vect_type, average_mtd = param_list\n",
    "    \n",
    "    ##########################################################\n",
    "    ################ Prepare dataframe for ML ################\n",
    "    #### Sample ####\n",
    "    # Build training and testing data frame.\n",
    "    x_train=trainDF[input_text]\n",
    "    y_train=trainDF['broad_cat']\n",
    "    x_valid=valDF[input_text]\n",
    "    y_valid=valDF['broad_cat']\n",
    "    ################ Prepare dataframe for ML ################\n",
    "    ##########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    ################ Define tokenizer ################\n",
    "\n",
    "    def porter_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "        tokens = word_tokenize(str_input)\n",
    "        return [PorterStemmer().stem(token) for token in tokens]\n",
    "    \n",
    "    # Lemmatize using POS tags, assume to improve accuracy.\n",
    "    # Ref: \n",
    "    #   - https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "    #   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def lemma_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "        tokens=word_tokenize(str_input)\n",
    "        return [WordNetLemmatizer().lemmatize(word=word, pos=get_wordnet_pos(pos)) for word, pos in nltk.pos_tag(tokens)]\n",
    "            \n",
    "    if tokenizer=='lemma':\n",
    "        tokenizer=lemma_tokenizer\n",
    "    elif tokenizer=='porter':\n",
    "        tokenizer=porter_tokenizer\n",
    "    ################ Define tokenizer ################\n",
    "    ##########################################################\n",
    "    \n",
    "    ##########################################################\n",
    "    ######### Text Vectorization and Transformation ##########\n",
    "    # 1. Use Porter Stemmer.\n",
    "    # 2. Use word level, character level does not make sense for current situation.\n",
    "    # 3. Use count (freq) and tf-idf vectorizer. see: \n",
    "    # Bengfort, B., Bilbro, R., & Ojeda, T. (2018). Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning (1 edition). Beijing Boston Farnham Sebastopol Tokyo: Oâ€™Reilly Media.\n",
    "    # Page: 67.\n",
    "    \n",
    "    if vect_type=='count':\n",
    "        ##### Token counts #####\n",
    "        # create the transform\n",
    "        vectorizer = CountVectorizer(stop_words='english', \n",
    "                                     tokenizer=tokenizer, \n",
    "                                     analyzer='word'\n",
    "                                    )\n",
    "        # tokenize and build vocab.\n",
    "        vectorizer.fit(x_train)\n",
    "        # Encode document: transform the training and validation data using count vectorizer object\n",
    "        x_train_vect =  vectorizer.transform(x_train)\n",
    "        x_valid_vect =  vectorizer.transform(x_valid)\n",
    "    elif vect_type=='tfidf':\n",
    "        ##### TF-IDF #####\n",
    "        # create the transform\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                     tokenizer=tokenizer, \n",
    "                                     analyzer='word'\n",
    "                                    )\n",
    "        # tokenize and build vocab\n",
    "        vectorizer.fit(x_train)\n",
    "        # Encode document: transform the training and validation data using count vectorizer object\n",
    "        x_train_vect =  vectorizer.transform(x_train)\n",
    "        x_valid_vect =  vectorizer.transform(x_valid)\n",
    "\n",
    "    ######### Text Vectorization and Transformation ##########\n",
    "    ##########################################################\n",
    "    \n",
    "    classifier.fit(x_train_vect, y_train)\n",
    "    predictions = classifier.predict(x_valid_vect)\n",
    "    return {'input_text':input_text,\n",
    "            'classifier':str(classifier), \n",
    "            'tokenizer':tokenizer.__name__, \n",
    "            'vect_type':vect_type, \n",
    "            'average_mtd':average_mtd,\n",
    "            'accuracy':metrics.accuracy_score(predictions, y_valid), \n",
    "            'precision':metrics.precision_score(y_pred=predictions, y_true=y_valid, average=average_mtd),\n",
    "            'recall':metrics.recall_score(y_pred=predictions, y_true=y_valid, average=average_mtd),\n",
    "            'f1':metrics.f1_score(y_pred=predictions, y_true=y_valid, average=average_mtd)\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of parameters.\n",
    "param_llist=[]\n",
    "for input_text in ['mission', 'prgrm_dsc', 'mission_prgrm', 'mission_spellchk', 'prgrm_dsc_spellchk', 'mission_prgrm_spellchk']:\n",
    "    for classifier in [naive_bayes.MultinomialNB(), naive_bayes.ComplementNB()]:\n",
    "        for tokenizer in ['lemma', 'porter']:\n",
    "            for vect_type in ['count', 'tfidf']:\n",
    "                for average_mtd in ['macro', 'weighted']:\n",
    "                    param_llist+=[[input_text, classifier, tokenizer, vect_type, average_mtd]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Pool(24)\n",
    "df_performance_nb=pd.DataFrame(p.map(func_classifier, param_llist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>average_mtd</th>\n",
       "      <th>classifier</th>\n",
       "      <th>f1</th>\n",
       "      <th>input_text</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.778145</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.774852</td>\n",
       "      <td>0.778145</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.778145</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.699526</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.742740</td>\n",
       "      <td>0.685534</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.777497</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.695233</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.750631</td>\n",
       "      <td>0.676116</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.777497</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.772665</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.775101</td>\n",
       "      <td>0.777497</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.775522</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.771589</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.772726</td>\n",
       "      <td>0.775522</td>\n",
       "      <td>porter_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy average_mtd                                         classifier  \\\n",
       "91  0.778145    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "90  0.778145       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "42  0.777497       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "43  0.777497    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "95  0.775522    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "\n",
       "          f1              input_text  precision    recall         tokenizer  \\\n",
       "91  0.773984  mission_prgrm_spellchk   0.774852  0.778145   lemma_tokenizer   \n",
       "90  0.699526  mission_prgrm_spellchk   0.742740  0.685534   lemma_tokenizer   \n",
       "42  0.695233           mission_prgrm   0.750631  0.676116   lemma_tokenizer   \n",
       "43  0.772665           mission_prgrm   0.775101  0.777497   lemma_tokenizer   \n",
       "95  0.771589  mission_prgrm_spellchk   0.772726  0.775522  porter_tokenizer   \n",
       "\n",
       "   vect_type  \n",
       "91     tfidf  \n",
       "90     tfidf  \n",
       "42     tfidf  \n",
       "43     tfidf  \n",
       "95     tfidf  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance_nb.sort_values('accuracy', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Manually check if acc is correct.\n",
    "In :func_naive_bayes(2)\n",
    "    df_performance['accuracy']\n",
    "Out:0    0.340417\n",
    "    Name: accuracy, dtype: float64\n",
    "In :t=pd.DataFrame([classifier.predict(x_valid_vect), y_valid]).T.rename(columns={0:'a', 1:'b'})\n",
    "    len(t[t.a==t.b])/len(t)\n",
    "Out:0.34041666666666665\n",
    "''' Looks correct, scale the computing '''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of parameters.\n",
    "param_llist=[]\n",
    "for input_text in ['mission', 'prgrm_dsc', 'mission_prgrm', 'mission_spellchk', 'prgrm_dsc_spellchk', 'mission_prgrm_spellchk']:\n",
    "    for classifier in [ensemble.RandomForestClassifier()]:\n",
    "        for tokenizer in ['lemma', 'porter']:\n",
    "            for vect_type in ['count', 'tfidf']:\n",
    "                for average_mtd in ['macro', 'weighted']:\n",
    "                    param_llist+=[[input_text, classifier, tokenizer, vect_type, average_mtd]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Pool(24)\n",
    "df_performance_rf=pd.DataFrame(p.map(func_classifier, param_llist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Select model, test on Universal Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>average_mtd</th>\n",
       "      <th>classifier</th>\n",
       "      <th>f1</th>\n",
       "      <th>input_text</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.778145</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.774852</td>\n",
       "      <td>0.778145</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.778145</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.699526</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.742740</td>\n",
       "      <td>0.685534</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.777497</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.772665</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.775101</td>\n",
       "      <td>0.777497</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.777497</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.695233</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.750631</td>\n",
       "      <td>0.676116</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.775522</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.771589</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.772726</td>\n",
       "      <td>0.775522</td>\n",
       "      <td>porter_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.775522</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.699870</td>\n",
       "      <td>mission_prgrm_spellchk</td>\n",
       "      <td>0.744213</td>\n",
       "      <td>0.684626</td>\n",
       "      <td>porter_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.773709</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.769014</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.771355</td>\n",
       "      <td>0.773709</td>\n",
       "      <td>porter_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.773709</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.692758</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.746558</td>\n",
       "      <td>0.673120</td>\n",
       "      <td>porter_tokenizer</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.768626</td>\n",
       "      <td>weighted</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.764820</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.766744</td>\n",
       "      <td>0.768626</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.768626</td>\n",
       "      <td>macro</td>\n",
       "      <td>ComplementNB(alpha=1.0, class_prior=None, fit_...</td>\n",
       "      <td>0.691887</td>\n",
       "      <td>mission_prgrm</td>\n",
       "      <td>0.729649</td>\n",
       "      <td>0.682032</td>\n",
       "      <td>lemma_tokenizer</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy average_mtd                                         classifier  \\\n",
       "139  0.778145    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "138  0.778145       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "91   0.777497    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "90   0.777497       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "143  0.775522    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "142  0.775522       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "95   0.773709    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "94   0.773709       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "89   0.768626    weighted  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "88   0.768626       macro  ComplementNB(alpha=1.0, class_prior=None, fit_...   \n",
       "\n",
       "           f1              input_text  precision    recall         tokenizer  \\\n",
       "139  0.773984  mission_prgrm_spellchk   0.774852  0.778145   lemma_tokenizer   \n",
       "138  0.699526  mission_prgrm_spellchk   0.742740  0.685534   lemma_tokenizer   \n",
       "91   0.772665           mission_prgrm   0.775101  0.777497   lemma_tokenizer   \n",
       "90   0.695233           mission_prgrm   0.750631  0.676116   lemma_tokenizer   \n",
       "143  0.771589  mission_prgrm_spellchk   0.772726  0.775522  porter_tokenizer   \n",
       "142  0.699870  mission_prgrm_spellchk   0.744213  0.684626  porter_tokenizer   \n",
       "95   0.769014           mission_prgrm   0.771355  0.773709  porter_tokenizer   \n",
       "94   0.692758           mission_prgrm   0.746558  0.673120  porter_tokenizer   \n",
       "89   0.764820           mission_prgrm   0.766744  0.768626   lemma_tokenizer   \n",
       "88   0.691887           mission_prgrm   0.729649  0.682032   lemma_tokenizer   \n",
       "\n",
       "    vect_type  \n",
       "139     tfidf  \n",
       "138     tfidf  \n",
       "91      tfidf  \n",
       "90      tfidf  \n",
       "143     tfidf  \n",
       "142     tfidf  \n",
       "95      tfidf  \n",
       "94      tfidf  \n",
       "89      count  \n",
       "88      count  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance=pd.concat([df_performance_rf, df_performance_nb], ignore_index=True).sort_values(['accuracy', 'f1'], ascending=False)\n",
    "df_performance[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters.\n",
    "input_text='mission_prgrm_spellchk'\n",
    "classifier=naive_bayes.ComplementNB()\n",
    "tokenizer='lemma'\n",
    "vect_type='tfidf'\n",
    "average_mtd='macro'\n",
    "\n",
    "df_universal_test=pd.read_pickle('../../dataset/df_ntee_universal/test/df_ntee_universal_test.pkl.gz', compression='gzip')\n",
    "df_universal_test['mission_prgrm_spellchk']=df_universal_test['mission_spellchk']+' '+df_universal_test['prgrm_dsc_spellchk'] # Using spell-checked.\n",
    "df_universal_test['broad_cat']=df_universal_test['NTEE1'].apply(ntee2cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "################ Prepare dataframe for ML ################\n",
    "#### Sample ####\n",
    "# Build training and testing data frame.\n",
    "x_train=trainDF[input_text]\n",
    "y_train=trainDF['broad_cat']\n",
    "################ Prepare dataframe for ML ################\n",
    "##########################################################\n",
    "\n",
    "##########################################################\n",
    "################ Define tokenizer ################\n",
    "\n",
    "def porter_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "    tokens = word_tokenize(str_input)\n",
    "    return [PorterStemmer().stem(token) for token in tokens]\n",
    "\n",
    "# Lemmatize using POS tags, assume to improve accuracy.\n",
    "# Ref: \n",
    "#   - https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "#   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemma_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "    tokens=word_tokenize(str_input)\n",
    "    return [WordNetLemmatizer().lemmatize(word=word, pos=get_wordnet_pos(pos)) for word, pos in nltk.pos_tag(tokens)]\n",
    "\n",
    "if tokenizer=='lemma':\n",
    "    tokenizer=lemma_tokenizer\n",
    "elif tokenizer=='porter':\n",
    "    tokenizer=porter_tokenizer\n",
    "################ Define tokenizer ################\n",
    "##########################################################\n",
    "\n",
    "##########################################################\n",
    "######### Text Vectorization and Transformation ##########\n",
    "# 1. Use Porter Stemmer.\n",
    "# 2. Use word level, character level does not make sense for current situation.\n",
    "# 3. Use count (freq) and tf-idf vectorizer. see: \n",
    "# Bengfort, B., Bilbro, R., & Ojeda, T. (2018). Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning (1 edition). Beijing Boston Farnham Sebastopol Tokyo: Oâ€™Reilly Media.\n",
    "# Page: 67.\n",
    "\n",
    "if vect_type=='count':\n",
    "    ##### Token counts #####\n",
    "    # create the transform\n",
    "    vectorizer = CountVectorizer(stop_words='english', \n",
    "                                 tokenizer=tokenizer, \n",
    "                                 analyzer='word'\n",
    "                                )\n",
    "    # tokenize and build vocab.\n",
    "    vectorizer.fit(x_train) # Using training dataset to build vocabulary.\n",
    "    # Encode document: transform the training and validation data using count vectorizer object\n",
    "    x_train_vect =  vectorizer.transform(x_train)\n",
    "elif vect_type=='tfidf':\n",
    "    ##### TF-IDF #####\n",
    "    # create the transform\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                 tokenizer=tokenizer, \n",
    "                                 analyzer='word'\n",
    "                                )\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(x_train) # Using training dataset to build vocabulary.\n",
    "    # Encode document: transform the training and validation data using tfidf vectorizer object\n",
    "    x_train_vect =  vectorizer.transform(x_train)\n",
    "######### Text Vectorization and Transformation ##########\n",
    "##########################################################\n",
    "\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "# ada = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "x_train_res, y_train_res = smote_enn.fit_resample(x_train_vect, y_train)\n",
    "classifier.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Test trained model on Universal Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "################ Prepare dataframe for ML ################\n",
    "#### Sample ####\n",
    "# Build training and testing data frame.\n",
    "x_valid=df_universal_test[input_text]\n",
    "y_valid=df_universal_test['broad_cat']\n",
    "################ Prepare dataframe for ML ################\n",
    "##########################################################\n",
    "\n",
    "##########################################################\n",
    "################ Define tokenizer ################\n",
    "\n",
    "def porter_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "    tokens = word_tokenize(str_input)\n",
    "    return [PorterStemmer().stem(token) for token in tokens]\n",
    "\n",
    "# Lemmatize using POS tags, assume to improve accuracy.\n",
    "# Ref: \n",
    "#   - https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "#   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemma_tokenizer(str_input): # '''Pay attention to the input: this is string input, not token!'''\n",
    "    tokens=word_tokenize(str_input)\n",
    "    return [WordNetLemmatizer().lemmatize(word=word, pos=get_wordnet_pos(pos)) for word, pos in nltk.pos_tag(tokens)]\n",
    "\n",
    "if tokenizer=='lemma':\n",
    "    tokenizer=lemma_tokenizer\n",
    "elif tokenizer=='porter':\n",
    "    tokenizer=porter_tokenizer\n",
    "################ Define tokenizer ################\n",
    "##########################################################\n",
    "\n",
    "##########################################################\n",
    "######### Text Vectorization and Transformation ##########\n",
    "# 1. Use Porter Stemmer.\n",
    "# 2. Use word level, character level does not make sense for current situation.\n",
    "# 3. Use count (freq) and tf-idf vectorizer. see: \n",
    "# Bengfort, B., Bilbro, R., & Ojeda, T. (2018). Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning (1 edition). Beijing Boston Farnham Sebastopol Tokyo: Oâ€™Reilly Media.\n",
    "# Page: 67.\n",
    "\n",
    "if vect_type=='count':\n",
    "    ##### Token counts #####\n",
    "    # create the transform\n",
    "    vectorizer = CountVectorizer(stop_words='english', \n",
    "                                 tokenizer=tokenizer, \n",
    "                                 analyzer='word'\n",
    "                                )\n",
    "    # tokenize and build vocab.\n",
    "    vectorizer.fit(x_train)\n",
    "    # Encode document: transform the training and validation data using count vectorizer object\n",
    "    x_valid_vect =  vectorizer.transform(x_valid)\n",
    "elif vect_type=='tfidf':\n",
    "    ##### TF-IDF #####\n",
    "    # create the transform\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                 tokenizer=tokenizer, \n",
    "                                 analyzer='word'\n",
    "                                )\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(x_train)\n",
    "    # Encode document: transform the training and validation data using tfidf vectorizer object\n",
    "    x_valid_vect =  vectorizer.transform(x_valid)\n",
    "######### Text Vectorization and Transformation ##########\n",
    "##########################################################\n",
    "\n",
    "predictions = classifier.predict(x_valid_vect)\n",
    "performance_dict= {'input_text':input_text,\n",
    "                   'classifier':str(classifier), \n",
    "                   'tokenizer':tokenizer.__name__, \n",
    "                   'vect_type':vect_type, \n",
    "                   'average_mtd':average_mtd,\n",
    "                   'accuracy':metrics.accuracy_score(predictions, y_valid), \n",
    "                   'precision':metrics.precision_score(y_pred=predictions, y_true=y_valid, average=average_mtd),\n",
    "                   'recall':metrics.recall_score(y_pred=predictions, y_true=y_valid, average=average_mtd),\n",
    "                   'f1':metrics.f1_score(y_pred=predictions, y_true=y_valid, average=average_mtd)\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': 'mission_prgrm_spellchk',\n",
       " 'classifier': 'ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)',\n",
       " 'tokenizer': 'lemma_tokenizer',\n",
       " 'vect_type': 'tfidf',\n",
       " 'average_mtd': 'macro',\n",
       " 'accuracy': 0.6083093739477297,\n",
       " 'precision': 0.5708095602016783,\n",
       " 'recall': 0.7363826384029141,\n",
       " 'f1': 0.572772059476367}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          I       0.74      0.83      0.96      0.78      0.89      0.79      4291\n",
      "         II       0.79      0.70      0.96      0.74      0.82      0.66      6419\n",
      "        III       0.44      0.93      0.94      0.60      0.94      0.88      1861\n",
      "         IV       0.54      0.83      0.91      0.65      0.87      0.75      4329\n",
      "         IX       0.37      0.91      0.93      0.52      0.92      0.84      1701\n",
      "          V       0.94      0.31      0.99      0.47      0.56      0.29     11723\n",
      "         VI       0.13      0.78      0.94      0.23      0.86      0.72       436\n",
      "        VII       0.81      0.54      0.97      0.65      0.73      0.50      6749\n",
      "       VIII       0.37      0.79      0.96      0.50      0.87      0.75      1098\n",
      "\n",
      "avg / total       0.75      0.61      0.96      0.61      0.75      0.57     38607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_true=y_valid, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5659455417103673"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from imblearn.metrics import make_index_balanced_accuracy as iba\n",
    "gmean = iba(alpha=0.1, squared=True)(gmean)\n",
    "gmean(y_true=y_valid, y_pred=predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "print(classification_report_imbalanced(y_true=y_valid, y_pred=predictions)) # SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "```\n",
    "                       pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "              I       0.74      0.83      0.96      0.78      0.89      0.79      4291\n",
    "             II       0.79      0.70      0.96      0.74      0.82      0.66      6419\n",
    "            III       0.44      0.93      0.94      0.60      0.94      0.88      1861\n",
    "             IV       0.54      0.83      0.91      0.65      0.87      0.75      4329\n",
    "             IX       0.37      0.91      0.93      0.52      0.92      0.84      1701\n",
    "              V       0.94      0.31      0.99      0.47      0.56      0.29     11723\n",
    "             VI       0.13      0.78      0.94      0.23      0.86      0.72       436\n",
    "            VII       0.81      0.54      0.97      0.65      0.73      0.50      6749\n",
    "           VIII       0.37      0.79      0.96      0.50      0.87      0.75      1098\n",
    "\n",
    "    avg / total       0.75      0.61      0.96      0.61      0.75      0.57     38607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "print(classification_report_imbalanced(y_true=y_valid, y_pred=predictions)) # strategy='minority'\n",
    "```\n",
    "                       pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "              I       0.83      0.81      0.98      0.82      0.89      0.78      4291\n",
    "             II       0.82      0.75      0.97      0.78      0.85      0.71      6419\n",
    "            III       0.82      0.79      0.99      0.81      0.89      0.77      1861\n",
    "             IV       0.81      0.66      0.98      0.73      0.80      0.63      4329\n",
    "             IX       0.82      0.69      0.99      0.75      0.83      0.67      1701\n",
    "              V       0.77      0.81      0.90      0.79      0.85      0.72     11723\n",
    "             VI       0.11      0.88      0.92      0.19      0.90      0.80       436\n",
    "            VII       0.79      0.63      0.96      0.70      0.78      0.59      6749\n",
    "           VIII       0.75      0.33      1.00      0.46      0.58      0.31      1098\n",
    "\n",
    "    avg / total       0.79      0.73      0.95      0.75      0.83      0.68     38607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "print(classification_report_imbalanced(y_true=y_valid, y_pred=predictions)) # strategy='auto', = 'not majority'\n",
    "```\n",
    "                       pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "              I       0.77      0.83      0.97      0.80      0.90      0.80      4291\n",
    "             II       0.82      0.71      0.97      0.76      0.83      0.67      6419\n",
    "            III       0.47      0.94      0.95      0.63      0.94      0.89      1861\n",
    "             IV       0.62      0.82      0.94      0.71      0.87      0.76      4329\n",
    "             IX       0.44      0.92      0.95      0.59      0.93      0.86      1701\n",
    "              V       0.88      0.53      0.97      0.66      0.72      0.49     11723\n",
    "             VI       0.20      0.75      0.97      0.32      0.85      0.71       436\n",
    "            VII       0.81      0.56      0.97      0.66      0.74      0.52      6749\n",
    "           VIII       0.40      0.79      0.97      0.53      0.87      0.75      1098\n",
    "\n",
    "    avg / total       0.76      0.68      0.96      0.69      0.80      0.64     38607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "print(classification_report_imbalanced(y_true=y_valid, y_pred=predictions)) # No resampling.\n",
    "```\n",
    "\n",
    "                       pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "              I       0.81      0.84      0.98      0.83      0.91      0.81      4291\n",
    "             II       0.79      0.79      0.96      0.79      0.87      0.75      6419\n",
    "            III       0.80      0.82      0.99      0.81      0.90      0.80      1861\n",
    "             IV       0.77      0.78      0.97      0.77      0.87      0.74      4329\n",
    "             IX       0.82      0.68      0.99      0.74      0.82      0.65      1701\n",
    "              V       0.78      0.84      0.89      0.81      0.87      0.74     11723\n",
    "             VI       0.41      0.09      1.00      0.15      0.30      0.08       436\n",
    "            VII       0.76      0.70      0.95      0.73      0.82      0.65      6749\n",
    "           VIII       0.65      0.62      0.99      0.64      0.78      0.59      1098\n",
    "\n",
    "    avg / total       0.78      0.78      0.95      0.77      0.85      0.72     38607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
