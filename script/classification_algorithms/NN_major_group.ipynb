{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU device.\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "# Specify GPU to use. \n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"; \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/\n",
    "#https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "#RNN\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# For encoding labels.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229472, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list=os.listdir('../../dataset/df_train.pkl.gz/')\n",
    "df_train=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_train=pd.concat([df_train, \n",
    "                        pd.read_pickle('../../dataset/df_train.pkl.gz/'+file, compression='gzip')])\n",
    "df_train['mission_prgrm']=df_train['mission']+'; '+df_train['prgrm_dsc']\n",
    "\n",
    "len(df_train['mission_prgrm']), len(df_train['NTEE1'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data frame.\n",
    "small_num=0\n",
    "while small_num<200: # Make sure each category has at least 500 records.\n",
    "    trainDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(120000)\n",
    "    small_num=trainDF.groupby('NTEE1').count().sort_values('EIN').iloc[0]['EIN']\n",
    "\n",
    "# Build validation data frame.\n",
    "small_num=0\n",
    "while small_num<200: # Make sure each category has at least 500 records.\n",
    "    valDF = df_train[df_train.mission.notna() & df_train.NTEE1.notna()].sample(120000)\n",
    "    small_num=valDF.groupby('NTEE1').count().sort_values('EIN').iloc[0]['EIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTEE1\n",
      "A    0.112142\n",
      "B    0.166717\n",
      "C    0.022450\n",
      "D    0.027600\n",
      "E    0.063658\n",
      "F    0.015350\n",
      "G    0.034408\n",
      "H    0.003142\n",
      "I    0.018700\n",
      "J    0.029150\n",
      "K    0.013042\n",
      "L    0.038308\n",
      "M    0.028850\n",
      "N    0.097517\n",
      "O    0.011075\n",
      "P    0.062925\n",
      "Q    0.013383\n",
      "R    0.006842\n",
      "S    0.091275\n",
      "T    0.014142\n",
      "U    0.005908\n",
      "V    0.002350\n",
      "W    0.053800\n",
      "X    0.028833\n",
      "Y    0.038433\n",
      "Name: EIN, dtype: float64 \n",
      "\n",
      " NTEE1\n",
      "A    0.111483\n",
      "B    0.167417\n",
      "C    0.022667\n",
      "D    0.028358\n",
      "E    0.063708\n",
      "F    0.014975\n",
      "G    0.034292\n",
      "H    0.003242\n",
      "I    0.019050\n",
      "J    0.029083\n",
      "K    0.012717\n",
      "L    0.038433\n",
      "M    0.029325\n",
      "N    0.097417\n",
      "O    0.010875\n",
      "P    0.063567\n",
      "Q    0.013225\n",
      "R    0.006967\n",
      "S    0.090208\n",
      "T    0.013867\n",
      "U    0.006000\n",
      "V    0.002342\n",
      "W    0.053867\n",
      "X    0.028325\n",
      "Y    0.038592\n",
      "Name: EIN, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the composition by NTEE major groups.\n",
    "print(trainDF.groupby('NTEE1').count()['EIN']/len(trainDF), '\\n'*2, valDF.groupby('NTEE1').count()['EIN']/len(valDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label_list, class_list):\n",
    "    int_encoder=LabelEncoder().fit(class_list) # Build the encoder.\n",
    "    label_int_encoded=int_encoder.transform(label_list) # One-dimensional integer encoded.\n",
    "    return np_utils.to_categorical(label_int_encoded) # Multi-dimensional binary/one-hot encoded.\n",
    "\n",
    "y_train=one_hot(label_list=trainDF['NTEE1'], class_list=list(trainDF['NTEE1'].unique()))\n",
    "y_val=one_hot(label_list=valDF['NTEE1'], class_list=list(trainDF['NTEE1'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list=stopwords.words('english')+list(string.punctuation)\n",
    "def tokenize_stopwords_remove(string):\n",
    "    global stop_list\n",
    "    return [s for s in nltk.word_tokenize(string) if s not in stop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token_list_train=trainDF['mission_prgrm'].apply(tokenize_stopwords_remove)\n",
    "text_token_list_val=valDF['mission_prgrm'].apply(tokenize_stopwords_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moved to preprocessing pipeline.**\n",
    "```Python\n",
    "# Spell check function. Return corrected word if unknown; return original word if known.\n",
    "def spellcheck(word_string_list):\n",
    "    return [SpellChecker().correction(word=s).upper() for s in word_string_list]\n",
    "\n",
    "# Parallel computing\n",
    "p = Pool(48)\n",
    "text_token_list_train=p.map(spellcheck, text_token_list_train)\n",
    "text_token_list_val=p.map(spellcheck, text_token_list_val)\n",
    "# Pool.map keep the original order of data passed to map.\n",
    "# https://stackoverflow.com/questions/41273960/python-3-does-pool-keep-the-original-order-of-data-passed-to-map\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 1), ('the', 2), ('to', 3), ('of', 4), ('in', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Build word index for train and validation texts.\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(text_token_list_train.to_list()+text_token_list_val.to_list())\n",
    "print(list(tokenizer.word_index.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoding_text_train=tokenizer.texts_to_sequences(text_token_list_train)\n",
    "seq_encoding_text_val=tokenizer.texts_to_sequences(text_token_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads sequences to the same length.\n",
    "x_train=pad_sequences(sequences=seq_encoding_text_train,\n",
    "                      maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                      dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                      value = 0 # Zero is used for representing None or Unknown.\n",
    "                     )\n",
    "x_val=pad_sequences(sequences=seq_encoding_text_val,\n",
    "                    maxlen=max([len(s) for s in seq_encoding_text_train]), # Max length of the sequence.\n",
    "                    dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                    value = 0 # Zero is used for representing None or Unknown.\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@Petuum/embeddings-a-matrix-of-meaning-4de877c9aa27\n",
    "# Note that in the embedding matrix above, each row corresponds to a word and each column corresponds to a dimension (axis). \n",
    "# Typically, we store this in a dense fashion, where we have a list of words and row ID’s which map to the corresponding row of the matrix. \n",
    "# For the above example, we’d have the following list in addition to the matrix:\n",
    "# { hello: 0, there: 1, texas: 2, world: 3, … }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not using pre-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index), # Size of vocabulary.\n",
    "                            input_length=max([len(s) for s in seq_encoding_text_train]), # Length of input, i.e., length of padded sequence.\n",
    "                            output_dim=32, # Size of the vector space in which words will be embedded.\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(max([len(s) for s in seq_encoding_text_train]),), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=len(y_train[0]), activation='softmax')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics.\n",
    "# https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras\n",
    "import tensorflow as tf\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='sigmoid'))\n",
    "model.add(Dense(units=256, activation='sigmoid'))\n",
    "model.add(Dense(units=len(y_train[0]), activation='relu'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', precision, recall])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# Batch size: https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
    "history=model.fit(x_train, y_train, validation_split=0.3, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained GloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "EMBEDDING_DIM=100\n",
    "glove_word_vector=api.load('glove-wiki-gigaword-'+str(EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251685/251685 [00:00<00:00, 372840.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for word, index in tqdm(tokenizer.word_index.items()):\n",
    "    try:\n",
    "        embedding_matrix[index] = glove_word_vector.get_vector(word)\n",
    "    except:\n",
    "        pass\n",
    "        # words not found in embedding index will be all-zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index)+1, # Size of vocabulary.\n",
    "                            input_length=max([len(s) for s in seq_encoding_text_train]), # Length of input, i.e., length of padded sequence.\n",
    "                            output_dim=EMBEDDING_DIM, # Size of the vector space in which words will be embedded.\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics.\n",
    "# https://stackoverflow.com/questions/43076609/how-to-calculate-precision-and-recall-in-keras\n",
    "import tensorflow as tf\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)\n",
    "f1 = as_keras_metric(tf.contrib.metrics.f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32070, 100)        25168600  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32066, 128)        64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                425       \n",
      "=================================================================\n",
      "Total params: 25,238,353\n",
      "Trainable params: 69,753\n",
      "Non-trainable params: 25,168,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 84000 samples, validate on 36000 samples\n",
      "Epoch 1/20\n",
      "84000/84000 [==============================] - 258s 3ms/step - loss: 0.1027 - acc: 0.9700 - val_loss: 0.0860 - val_acc: 0.9747\n",
      "Epoch 2/20\n",
      "83968/84000 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9775"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, GlobalMaxPool1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# model.add(Flatten())\n",
    "model.add(Conv1D(128, 5, activation='softplus'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(units=32, activation='sigmoid'))\n",
    "model.add(Dense(units=16, activation='softplus'))\n",
    "# model.add(PReLU()) # https://medium.com/tinymind/a-practical-guide-to-relu-b83ca804f1f7\n",
    "model.add(Dense(units=16, activation='tanh'))\n",
    "model.add(Dense(units=16, activation='softplus'))\n",
    "model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', \n",
    "#                                                                      precision, recall\n",
    "                                                                    ])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "history=model.fit(x_train, y_train, validation_split=0.3, epochs=20, verbose=1)\n",
    "\n",
    "'''\n",
    "(10, sigmoid; 9, relu): loss: 0.4414 - acc: 0.8896 - precision: 0.1604 - recall: 0.8439 - val_loss: 0.3964 - val_acc: 0.8943 - val_precision: 0.1632 - val_recall: 0.8974\n",
    "(10, softmax; 9, relu): loss: 0.5685 - acc: 0.8888 - precision: 0.1371 - recall: 0.8051 - val_loss: 0.5532 - val_acc: 0.8895 - val_precision: 0.1394 - val_recall: 0.8151\n",
    "(10, relu;    9, relu): loss: 0.5377 - acc: 0.8838 - precision: 0.1646 - recall: 0.8411 - val_loss: 0.4271 - val_acc: 0.8903 - val_precision: 0.1558 - val_recall: 0.8884\n",
    "(10, relu; 9, softmax): loss: 0.2596 - acc: 0.9037 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2303 - val_acc: 0.9135 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, relu; 9, sigmoid): loss: 0.2681 - acc: 0.8975 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2272 - val_acc: 0.9121 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, tanh; 9, sigmoid): loss: 0.2959 - acc: 0.8940 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2572 - val_acc: 0.9066 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(10, relu;    9, tanh): loss: 0.4241 - acc: 0.8599 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.3609 - val_acc: 0.8885 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "\n",
    "(32, relu; 16, tanh; 9, sigmoid): loss: 0.2590 - acc: 0.9034 - precision: 0.1110 - recall: 0.9992 - val_loss: 0.2186 - val_acc: 0.9180 - val_precision: 0.1111 - val_recall: 1.0000\n",
    "(32, relu; 16, tanh; 9,    relu): loss: 0.5613 - acc: 0.8654 - precision: 0.1360 - recall: 0.7180 - val_loss: 0.3850 - val_acc: 0.8889 - val_precision: 0.1394 - val_recall: 0.8721\n",
    "(32, relu; 16, relu; 9,    relu): loss: 0.3902 - acc: 0.8876 - precision: 0.1396 - recall: 0.9328 - val_loss: 0.3618 - val_acc: 0.8889 - val_precision: 0.1377 - val_recall: 0.9532\n",
    "(32, softmax; 16, relu; 9, relu): loss: 0.6418 - acc: 0.8916 - precision: 0.1212 - recall: 0.7585 - val_loss: 0.6097 - val_acc: 0.8942 - val_precision: 0.1276 - val_recall: 0.7584\n",
    "(32, sigmoid; 16, relu; 9, relu): loss: 0.5048 - acc: 0.8885 - precision: 0.1421 - recall: 0.7762 - val_loss: 0.3169 - val_acc: 0.8889 - val_precision: 0.1363 - val_recall: 0.8788\n",
    "\n",
    "(32, sigmoid; 32, sigmoid; 16, relu; 16, relu; 9, relu): loss: 0.3325 - acc: 0.8879 - precision: 0.1251 - recall: 0.9766 - val_loss: 0.4644 - val_acc: 0.7910 - val_precision: 0.1257 - val_recall: 0.9785\n",
    "(32, softmax; 32, softmax; 16, relu; 16, relu; 9, relu): loss: 1.1298 - acc: 0.8889 - precision: 0.0933 - recall: 0.4219 - val_loss: 1.1113 - val_acc: 0.8889 - val_precision: 0.0952 - val_recall: 0.4569\n",
    "\n",
    "1. Don't use sigmoid/softmax/tanh for output layer.\n",
    "2. Using relu near output layer increases loss but improve precision.\n",
    "3. sigmoid/tanh/softmax decreases loss, but also decreases precision.\n",
    "4. Possible strategy: use softmax near input layer, use relu near output layer.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYFNW5x/Hvj10EAQdEZVfRiAiII0hEQc014IaCUQnuIbjhFk2CYqJBcYvxqtEYidG4oISr0YuJSpSgxGtUhrBjEETEEVRARFZh4L1/nGqmp+mZ7pnpnp7l/TxPP9NVdbrqVFdPvXWWOiUzwznnnCtLvVxnwDnnXPXnwcI551xKHiycc86l5MHCOedcSh4snHPOpeTBwjnnXEoeLFzaJNWXtFFSx0ymzSVJB0nKeP9xSd+TtDxuerGkY9NJW4FtPSbppop+3rl0NMh1Blz2SNoYN9kU+BbYEU1famYTy7M+M9sBNMt02rrAzA7JxHokjQTOM7OBcesemYl1O1cWDxa1mJntOllHV64jzeyN0tJLamBmRVWRN+dS8d9j9eLVUHWYpNsl/VnSc5I2AOdJ6ifpXUlfS1ol6UFJDaP0DSSZpM7R9DPR8lclbZD0L0ldyps2Wj5Y0oeS1kv6raT/k3RRKflOJ4+XSloqaZ2kB+M+W1/Sf0taK+kjYFAZ38/NkiYlzHtY0n3R+5GSPoj256Poqr+0dRVKGhi9byrp6ShvC4Ejk2x3WbTehZJOj+YfDjwEHBtV8a2J+25vjfv8ZdG+r5X0kqT90vluyvM9x/Ij6Q1JX0n6XNLP4rbzi+g7+UZSgaT9k1X5SXo7dpyj73NGtJ2vgJsldZU0PdqXNdH31iLu852ifVwdLX9AUpMoz4fGpdtP0mZJeaXtr0vBzPxVB17AcuB7CfNuB7YBpxEuHPYAjgL6EkqdBwAfAqOj9A0AAzpH088Aa4B8oCHwZ+CZCqTdB9gADImW/QTYDlxUyr6kk8f/BVoAnYGvYvsOjAYWAu2BPGBG+DdIup0DgI3AnnHr/hLIj6ZPi9IIOAHYAvSIln0PWB63rkJgYPT+XuBNoBXQCViUkPZsYL/omPwwykPbaNlI4M2EfD4D3Bq9PynKYy+gCfA74B/pfDfl/J5bAF8A1wCNgb2APtGyG4G5QNdoH3oBewMHJX7XwNux4xztWxFwOVCf8Hs8GDgRaBT9Tv4PuDdufxZE3+eeUfpjomUTgPFx27keeDHX/4c1+ZXzDPirig506cHiHyk+dwPwP9H7ZAHg93FpTwcWVCDtJcA/45YJWEUpwSLNPB4dt/wvwA3R+xmE6rjYspMTT2AJ634X+GH0fjDwYRlp/wpcGb0vK1isiD8WwBXxaZOsdwFwSvQ+VbB4ErgjbtlehHaq9qm+m3J+z+cDBaWk+yiW34T56QSLZSnycBYwM3p/LPA5UD9JumOAjwFF03OAoZn+v6pLL6+Gcp/GT0j6jqS/RdUK3wDjgNZlfP7zuPebKbtRu7S0+8fnw8J/d2FpK0kzj2ltC/ikjPwCPAsMj97/ENjVKUDSqZLei6phviZc1Zf1XcXsV1YeJF0kaW5UlfI18J001wth/3atz8y+AdYB7eLSpHXMUnzPHYClpeShAyFgVETi73FfSZMlfRbl4U8JeVhuoTNFCWb2f4RSSn9J3YGOwN8qmCeHt1m4cKUZ71HClexBZrYX8EvClX42rSJc+QIgSZQ8uSWqTB5XEU4yMam69v4Z+J6k9oRqsmejPO4BPA/cSagiagn8Pc18fF5aHiQdADxCqIrJi9b7n7j1purmu5JQtRVbX3NCdddnaeQrUVnf86fAgaV8rrRlm6I8NY2bt29CmsT9u5vQi+/wKA8XJeShk6T6peTjKeA8Qilospl9W0o6lwYPFi5Rc2A9sClqILy0Crb5V6C3pNMkNSDUg7fJUh4nA9dKahc1dv68rMRm9gWhquQJYLGZLYkWNSbUo68Gdkg6lVC3nm4ebpLUUuE+lNFxy5oRTpirCXFzJKFkEfMF0D6+oTnBc8CPJPWQ1JgQzP5pZqWW1MpQ1vc8BegoabSkRpL2ktQnWvYYcLukAxX0krQ3IUh+TuhIUV/SKOICWxl52ASsl9SBUBUW8y9gLXCHQqeBPSQdE7f8aUK11Q8JgcNVggcLl+h64EJCg/OjhCvrrIpOyOcA9xH++Q8EZhOuKDOdx0eAacB8YCahdJDKs4Q2iGfj8vw1cB3wIqGR+CxC0EvHLYQSznLgVeJOZGY2D3gQeD9K8x3gvbjPvg4sAb6QFF+dFPv8a4Tqohejz3cERqSZr0Slfs9mth74L2AYoUH9Q2BAtPjXwEuE7/kbQmNzk6h68cfATYTODgcl7FsytwB9CEFrCvBCXB6KgFOBQwmljBWE4xBbvpxwnLeZ2Tvl3HeXINb441y1EVUrrATOMrN/5jo/ruaS9BSh0fzWXOelpvOb8ly1IGkQoVphK6HrZRHh6tq5Conaf4YAh+c6L7WBV0O56qI/sIxQPTEIOMMbJF1FSbqTcK/HHWa2Itf5qQ28Gso551xKWStZSHpc0peSFpSyXNFt/UslzZPUO27ZhZKWRK8Ls5VH55xz6clayULScYRhCp4ys+5Jlp8MXEW4g7Yv8ICZ9Y262BUQhoUwYBZwpJmtK2t7rVu3ts6dO2d2J5xzrpabNWvWGjMrq6s6kMUGbjOboWgQuVIMIQQSA96N+pzvBwwEXjezrwAkvU6ow36urO117tyZgoKCTGTdOefqDEmpRjEActvA3Y6St/YXRvNKm78bSaOiES0LVq9enbWMOudcXZfLYJFsWAQrY/7uM80mmFm+meW3aZOyFOWcc66CchksCik5Pk57wo1Ypc13zjmXI7kMFlOAC6JeUUcD681sFTAVOElSK0mtCCN5Ts1hPp1zrs7LWgO3pOcIjdWtJRUSxnhpCGBmvwdeIfSEWkoYJvniaNlXkm4jjNsDMC7W2O2ccy43stkbaniK5QZcWcqyx4HHs5Ev55yrCSZOhLFjYcUK6NgRxo+HERUdEjIDfLgP51y1MHEidO4M9eqFvxMnpvpE5tZbWpr4+a1bh1fi+3TSd+4MV1yR/jYkOP98+OQTMAt/R40KacvaRqa+s6Ry/ai+TL2OPPJIc87VTM88Y9a0qVk4NYZX06ZhfmK6Tp3MJLO8vPCSwrzEtKnWG1sXhHXEp4lNJ84v7VXe9BX9TKr0yb6zVCjl8biJr5yf5DP18mDhXPriT7qlnWgrsq74E3hpJ/Nk246dtJO9YutJdaJs2HD3bVf0pFuTX506le/4ebBwrgZL52RekavsVFfSZa0n2fYycfVdW0/auXpJ5futebBwLoPKeyVeWvrE+Zdfvnu6ZFUniSfzVCfZ8qYv7RW7WveTes15ZatkUWuGKM/PzzcfG8plw8SJoXFx8+bieU2bwoQJ4X2sx8ree4fptWtDA2X8v1ZsOnF+olTLXd1S3t9D7HdZnl5TkmaZWX6qdP6kPFcnxXdLjJ3kv/oq+fu1a3f//ObNcN55Jf+Z49Ml/oPHplP943ugyJ3SAnpsOi8vTCf+NtJJ37EjnHwyvPJK6NmU7mfGjw/TiRcrZaXPWvfadIofNeHl1VB1S7rVPMnq3L1KpXq/8vJ2r4aLfyVrX8nLM2vUqPTPNG0aqvxKq95L9zdUnt9iJj+TyQ4JifA2C1cbpNuoWlrjqde5l/6qaNfN8pzAy3u8Eru1ptt4X9pvpTwXE3WVBwtX7aX6x03W0FsXX5lsyE51JZ3qaj2dXlPlOdZ+8s49DxauypWnu2dZV5vp9JGvCa9UXUXje0MlS1fRq+yKXJVX5pi6ms2DhasS5T351+SqoFT13pWt+vATs8uFdIOFd511FZasS2lNUlYvl8T38T1NqtsAb85VhneddVkTO1l+ktaTe7Mnna6OGzbAtm27L+vUqeIn+REjPDi4usdHnXW7pDPCZuvWcMkluQkUeXnhJYWT/dNPhxP/00+H6cT5a9bA448nX7Z8uZ/wnSsPr4aq4+JLCbm4ezidO5srcleqcy496VZDZbVkIWmQpMWSlkoak2R5J0nTJM2T9Kak9nHL7pa0IHqdk8181jWxEkT8mPmQmUAhlfxbVprSSgeJJQgPFM7lXtaChaT6wMPAYKAbMFxSt4Rk9wJPmVkPYBxwZ/TZU4DeQC+gL/BTSXtlK691SaxROpMBIibdk3+yqqARI8L0zp2h+mjNmvDeq4ucqx6y2cDdB1hqZssAJE0ChgCL4tJ0A66L3k8HXoqb/5aZFQFFkuYCg4DJWcxvrZbNRulk1UTeCOxc7ZLNaqh2wKdx04XRvHhzgWHR+zOB5pLyovmDJTWV1Bo4HuiQuAFJoyQVSCpYvXp1xnegpiutuqmyGjb0aiLn6ppsBotktdaJlR43AAMkzQYGAJ8BRWb2d+AV4B3gOeBfQNFuKzObYGb5Zpbfpk2bjGa+pqpse0SsPSG+6iixGumJJ7yayLm6JpvVUIWULA20B1bGJzCzlcBQAEnNgGFmtj5aNh4YHy17FliSxbzWaKX1aCpPgKjsvQfOudotmyWLmUBXSV0kNQLOBabEJ5DUWlIsDzcCj0fz60fVUUjqAfQA/p7FvNZYlW2w9nsPnHPpyFrJwsyKJI0GpgL1gcfNbKGkcYSxSKYAA4E7JRkwA7gy+nhD4J8KdSLfAOdFjd0uUtkGa793wTlXHn5TXg1S2RvovLrJOZfIx4aqZRIH7fP2COdcVfJgUUOMHZv+6K4eIJxzmeYDCVZzsa6w6bZNeIO1cy4bvGRRjZXneRHeYO2cyyYvWVRjqaqe4gfk80DhnMsmDxbVUDpVT17d5JyrSl4NVc2kU/XUqVMIEM45V1W8ZFENxD+h7sILyw4UTZuGHk7OOVeVvGSRY4kliR07Sk/rXWGdc7niwSLH0r1/wquenHO55NVQObZiReo0XvXknMs1DxY51rFj8vn16/vDhZxz1YcHixyJ7x6rhMdENW0KTz7pDxdyzlUfHixyINkzKPwGO+dcdeYN3DmQrFE7NvCfN2I756ojL1lUoVR3ZqfT2O2cc7ngJYsqks6d2aU1djvnXK5ltWQhaZCkxZKWShqTZHknSdMkzZP0pqT2ccvukbRQ0geSHpQSm4FrllT3U3j3WOdcdZa1YCGpPvAwMBjoBgyX1C0h2b3AU2bWAxgH3Bl99rvAMUAPoDtwFDAgW3mtCmVVMXmjtnOuustmNVQfYKmZLQOQNAkYAiyKS9MNuC56Px14KXpvQBOgESCgIfBFFvOadR07Jm+r8EZt51xNkM1qqHbAp3HThdG8eHOBYdH7M4HmkvLM7F+E4LEqek01sw8SNyBplKQCSQWrV6/O+A5kQqr7KbzqyTlXE2QzWCRrY7CE6RuAAZJmE6qZPgOKJB0EHAq0JwSYEyQdt9vKzCaYWb6Z5bdp0yazuc8Av5/COVdbZLMaqhDoEDfdHlgZn8DMVgJDASQ1A4aZ2XpJo4B3zWxjtOxV4GhgRhbzm3F+P4VzrrbIZsliJtBVUhdJjYBzgSnxCSS1lhTLw43A49H7FYQSRwNJDQmljt2qoaq70hq1/X4K51xNk7VgYWZFwGhgKuFEP9nMFkoaJ+n0KNlAYLGkD4G2QKwG/3ngI2A+oV1jrpm9nK28Zktp9034/RTOuZpGZonNCDVTfn6+FRQU5DobJSS7Ea9pU2+rcM5VH5JmmVl+qnQ+3EcWjRgRAkOnTj7cuHOuZvPhPrJg4sTQuL1iRahy8kehOudqOg8WGZZY9fTJJ2EaPGA452our4bKsGTdZTdvDvOdc66m8mCRYd5d1jlXG3mwyDDvLuucq408WGSIjwHlnKvNPFhkgI8B5Zyr7bw3VAb4GFDOudrOSxYZ4I3azrnazoNFBnijtnOutvNgkQHjx4dG7HjeqO2cq008WGSAjwHlnKvtvIE7Q0aM8ODgnKu9vGThnHMuJQ8WzjnnUspqsJA0SNJiSUsljUmyvJOkaZLmSXpTUvto/vGS5sS9tko6I5t5rYjYXdv16oW/EyfmOkfOOZcdWWuzkFQfeBj4L6AQmClpipktikt2L/CUmT0p6QTgTuB8M5sO9IrWszewFPh7tvJaET4UuXOuLslmyaIPsNTMlpnZNmASMCQhTTdgWvR+epLlAGcBr5rZ5iTLcsaHInfO1SXZDBbtgE/jpgujefHmAsOi92cCzSXlJaQ5F3guKzmsBL9r2zlXl2QzWCjJPEuYvgEYIGk2MAD4DCjatQJpP+BwYGrSDUijJBVIKli9enVmcp0mv2vbOVeXZDNYFAId4qbbAyvjE5jZSjMbamZHAGOjeevjkpwNvGhm25NtwMwmmFm+meW3adMms7lPwe/ads7VJdkMFjOBrpK6SGpEqE6aEp9AUmtJsTzcCDyesI7hVMMqKPC7tp1zdUvWekOZWZGk0YQqpPrA42a2UNI4oMDMpgADgTslGTADuDL2eUmdCSWTt7KVx8ryu7adc3WFzBKbEWqm/Px8KygoyHU2nHOuRpE0y8zyU6XzO7idc86l5MHCOedcSh4sysmH+HDO1UU+RHk5+BAfzrm6yksW5eBDfDjn6qqUwULSaEmtqiIz1Z0P8eGcq6vSKVnsSxgxdnI05HiyYTzqBB/iwzlXV6UMFmZ2M9AV+CNwEbBE0h2SDsxy3qodH+LDOVdXpdVmYeHOvc+jVxHQCnhe0j1ZzFu140N8OOfqqpR3cEu6GrgQWAM8BrxkZtujMZ2WmFm1KGH4HdzOOVd+6d7BnU7X2dbAUDP7JH6mme2UdGpFM+icc67mSKca6hXgq9iEpOaS+gKY2QfZyphzzrnqI51g8QiwMW56UzTPOedcHZFOsJDFNWyY2U78zm/nnKtT0gkWyyRdLalh9LoGWJbtjFUnPh6Uc66uSydYXAZ8l/B87EKgLzAqm5mqTmLjQX3yCZgVjwflAcM5V5f4w49S6Nw5BIhEnTrB8uUZ35xzzlWpjHWdldQE+BFwGNAkNt/MLknjs4OABwiPVX3MzO5KWN6J8NztNoQeV+eZWWG0rCPhvo4OgAEnm9nyVNvMNB8Pyjnn0quGepowPtT3Cc/Dbg9sSPUhSfWBh4HBQDdguKRuCcnuBZ4ysx7AOODOuGVPAb82s0OBPsCXaeQ143w8KOecSy9YHGRmvwA2mdmTwCnA4Wl8rg+w1MyWmdk2YBIwJCFNN2Ba9H56bHkUVBqY2esAZrbRzBIGB68aPh6Uc86lFyy2R3+/ltQdaAF0TuNz7YBP46YLo3nx5gLDovdnAs0l5QEHR9v7i6TZkn4dlVRKkDRKUoGkgtWrV6eRpfLz8aCccy69YDEhep7FzcAUYBFwdxqfSzaUeWJr+g3AAEmzgQGEHldFhLaUY6PlRwEHEEa8Lbkyswlmlm9m+W3atEkjSxUzYkRozN65M/z1QOGcq2vKbOCOBgv8xszWATMIJ+10FRIap2PaAyvjE5jZSmBotK1mwDAzWy+pEJhtZsuiZS8BRxOGSXfOOVfFyixZRHdrj67gumcCXSV1kdQIOJdQMtlFUusoIAHcSOgZFftsK0mx4sIJhBKNc865HEinGup1STdI6iBp79gr1YfMrIgQaKYCHwCTzWyhpHGSTo+SDQQWS/oQaAuMjz67g1AFNU3SfEKV1h/Ku3POOecyI53nWXycZLaZWXmqpLLOn2fhnHPll7Gb8sysS2ay5JxzrqZK5w7uC5LNN7OnMp8d55xz1VE6Q40fFfe+CXAi8G/CHdbOOefqgJQN3GZ2Vdzrx8ARQKPsZy23fFhy55wrVpGHGG0GumY6I9VJbFjyzdEAI7FhycFvyHPO1U3ptFm8TPGd1/UI4zlNzmamcm3s2OJAEbN5c5jvwcI5VxelU7K4N+59EfBJbBjx2sqHJXfOuZLSCRYrgFVmthVA0h6SOufi2RJVpWPH5A888mHJnXN1VTp3cP8PsDNuekc0r9byYcmdc66kdIJFg+h5FABE72t1bygfltw550pKpxpqtaTTzWwKgKQhwJrsZiv3Rozw4OCcczHpBIvLgImSHoqmC4Gkd3U755yrndIZG+oj4OjoeRMys5TP33bOOVe7pGyzkHSHpJbRc7A3SGol6faqyJxzzrnqIZ0G7sFm9nVsInpq3snZy5JzzrnqJp1gUV9S49iEpD2AxmWkd845V8uk08D9DOGJdU9E0xcDT2YvS84556qbdEadvQe4HTiUMC7Ua0CndFYuaZCkxZKWShqTZHknSdMkzZP0pqT2cct2SJoTvaYkftY551zVSXfU2c8Jd3GfDXwMvJDqA5LqAw8D/0XobjtT0hQzWxSX7F7gKTN7UtIJwJ3A+dGyLWbWK838Oeecy6JSg4Wkg4FzgeHAWuDPhK6zx6e57j7AUjNbFq1vEjAEiA8W3YDrovfTgZfKlXvnnHNVoqxqqP8Qnop3mpn1N7PfEsaFSlc74NO46cJoXry5wLDo/ZlAc0l50XQTSQWS3pV0RrINSBoVpSlYvXp1ObLmnHOuPMoKFsMI1U/TJf1B0omAyrHuZGktYfoGYICk2cAA4DPCMOgAHc0sH/ghcL+kA3dbmdkEM8s3s/w2bdqUI2vOOefKo9RgYWYvmtk5wHeANwnVRW0lPSLppDTWXQh0iJtuD6xM2MZKMxtqZkcAY6N562PLor/Lou0fkeY+Zd348XDllbBqVa5z4pxzVSOd3lCbzGyimZ1KOOHPAXbr2ZTETKCrpC6SGhHaP0r0apLUWlIsDzcCj0fzW8Xu7ZDUGjiGkm0dVWLbNrCEstDSpfDLX8LvfgcHHQS/+hVs2lTVOXPOuaqVzk15u5jZV2b2qJmdkEbaImA0MBX4AJhsZgsljZN0epRsILBY0odAWyD2xIhDgQJJcwkN33cl9KLKujlzoEOHUIKId8890LAhvP02nHwy3HornHJKVebMOeeqnizx0rmGys/Pt4KCgoys69//hu99DzZuhO3b4Y034MQT4bPPoEsXGDkylCwAfv1r+NnPYPZs6OUdfZ1zNYykWVH7cJnKVbKo7SZOhP32gyOPhG++gdtvh65dYdSoUNX0m9/Azp3w058Wf2bkSGjSBB59NHf5ds65bPNgEZk4EX78Y/j88zC9Y0dojzjnHFi2DK66KgSEH/4wlC5iWrWCc8+FZ56BDT54u3OulvJgERk7FrZsKTlv82Z4+mm49FJ44okwPSZJ0/5ll4Uqq2efrZq8OudcVfM2i0i9erv3fILwDO5160J7RL9+yQOCGRwRdeydPTt8xjnnagJvsyinjh1Ln9+iBSxaFEoZyUihdDF3Lrz/fvby6JxzueLBIjJ+PNSvX3Je06ZhPsAee+y+PN6IEdCsGYwbB/Pnh4Zw55yrLTxYREaMgLZtQ1CQoFMnmDAhzE9H8+Zw7bXwyivQowfsu2/y9o1588I63303s/l3zrls8mAR+fZb+PJL+MlPQqlg+fL0A0XMbbeFzz3xROh+e/fdMGtWyTS//GVo9+jXD84+Gz76KFN74Jxz2ePBIvLhh1BUBIcdVrn1dOoEF10Ezz0He+4JDz9cvGzFCnj5Zbj6arjlFvjb38L2pk+v3Dadcy7bPFhEFi4MfysbLGJatoTzzgtBY+3aMO/3vw9/r78+DBOyZAkceCAMHQr/+U9mtuucc9ngwSKycGFowD7kkMyt88orYetWePzxUM312GNw+unFPa/23x/++tcw1tQpp4A/ksM5V115sIgsXBiG9mjcOHPrPPxwGDAgjCM1aVIIBokDE3bpAlOmwMqVcMYZIag451x148EismBB5qqg4l15ZWj0vu66UGo58cTd0xx9NPzxj/DOOzB5cubz4JxzleXBglBV9NFH2QkWZ5wRqpvWrYMrrij97u5zzw2ljNJu/HPOuVzyYEFoXN65MzvBomHDUKpo3RouvLD0dPXqhQbxN94IQ6E751x14sGC4p5Q3btnZ/3XXx8CQIsWZac7//wwzpQPSOicq26yGiwkDZK0WNJSSbvdzyypk6RpkuZJelNS+4Tle0n6TNJD2cznggWhBNC1a3bWL0GjRqnTde0abtZ78snkgxrGMwtDqk+ZUna6nTtTr8s551LJWrCQVB94GBgMdAOGS+qWkOxe4Ckz6wGMA+5MWH4b8Fa28hizcCEcfHAIGLl2/vkhP3PmlJ1u6dLQFffSS0t/jsbOnfD978MBB4Tndfh4Vc65imqQxXX3AZaa2TIASZOAIUD8s7S7AddF76cDL8UWSDqS8Fzu14CUw+dWxsKFkJ/VLaTvnHPgmmtCQ3ds2PNkpk4Nfz//PDwX/Lbbdk/z5JOhDaRDh9Ae8pvfhHaTTZvg66/D3x07wuvgg0s+AdA55+JlM1i0Az6Nmy4E+iakmQsMAx4AzgSaS8oD1gG/Ac4HknQ2DSSNAkYBdCxtjPEUNm2Cjz8OQ3RUB3vvDaedFtot7rkHGpRyhKZODXd/9+kD994bHv3aoUPx8rVrw8n/u9+FGTPCfR5jx4bBDiEMmNi0abgRcfv20Fvr5JOz08jvnKv5stlmkayTaGLt+Q3AAEmzgQHAZ0ARcAXwipl9ShnMbIKZ5ZtZfps2bSqUyc2bw3O0jzuuQh/PigsugC++CCWMrVt3X75tWxhP6qST4M47Q5vETTeVTPPzn4fSw+9/HwLCiBGh6urzz8MTATdvhjVrwnb+858QlJ58smr2r7K2b891Dpyrg8wsKy+gHzA1bvpG4MYy0jcDCqP3E4EVwHJgDfANcFdZ2zvyyCOtttixw+yaa8zA7LDDzObOLbl8+vSw7KWXwvSNN4bpp54y+/e/zf761zD905+mv83TTjPbbz+z7duL5y1bZvbzn5t9802ldyljbrvNbO+9w3465yoPKLB0zunpJKrIi1DFtQzoAjQiVDkdlpCmNVAvej8eGJdkPRcBD6XaXm0KFjGvvWa2775mjRqZ/f3vxfPHjDFr0MBs/fowvX69Wfv24WjGXh06mG3YkP62XnghfO7VV8P0zp1m3/temHfGGSGA5dqCBWG/IXwvy5blOkfO1XzpBousVUOZWREwGpgKfABMNrOFksZJOj1KNhBYLOlDQmP2+Gzlpyb6/vfDU/e6dAl3f8fGjZo6NXSx3WvFges5AAAcZklEQVSvML3XXqH77//9H7z4Ijz6aHgIU7Nm6W/rlFNCe8mf/hSmp0wJjeMDBsBLL4VRciGEopdegkGDYPHi0te3cyf87GfhmR6fllmZmJ6dO0PPrxYt4K23QvXcoEGhKi3XNm2CTz7JdS4chEcNeK+/LEknotSEV20sWcRMnRqupu+6y+yLL8L722/P/HZGjzZr3Njs88/NDjggVIFt3252ySVhmw88EKqrYqWX444LJZBkHnusOJ1kNnCg2fvv757u0UfN/uu/zPr3N+vd22zoULM33th9vY8+Gtb1pz+F6RkzQl779DH7+OP09m/hQrNDDy0uPZVm9myzzz5Lb53bt4fvoV698D0VFob5O3eazZ9v9uabpX9HLrPuvz/8Rk44weyTTzK33h07avcxJNfVUFX9qs3BwsxsyBCzPfc0u+eecNRmzsz8NmbODOvu1Sv8ff31MH/rVrPvfjfMa9rU7Ne/NnvkkTD9xBO7r2ftWrPWrUMAWLrU7Fe/CtVGnTubbdpUnG7WrHCS7drV7PjjzQYPDp+DcFIfN87sySfNXn7ZrGXLEHDi/2n/8peQn8aNzW6+2WzjxtL3bc0aswMPDOvu3bv0f/5vvjFr1izk9auvUn9nN99su6rqGjUy22OPEFDbti0OlkOGmH35Zep1VUcvv2zWrl04Lu3bmx18sNnJJ5v97GdmTz9dvqrObHrllfBb6ts3HL+99gpteOme5LdvD218Rx8dfnvt2pm1aBGOaaztcMGC8udr585wgVcR69ebnXlm+N3/5Cdmzzxjtnp1xdZVFg8WtcxHH4WTYv36Znl5ZkVFmd/Gzp3hnyJ28ov3xRdmt95afMW2Y4fZMceEvKxZUzLt5ZeHfMY3zL/1Vljvz39e/Pm+fc322cds3bridFu2hNLDkUcWn2wh/NP+5z+753nFCrPhw0OaNm1CKWXUqBDQYiWObdvC1WajRmaXXhrSvvFG8u8gViKSzE49tey2mtdfD+kuvjhML1sW8tK5s9kPf2j2xz+a3X132O6++6Yu0cTbsMHslFPC/lx4YejEcOutZrfcEl6JnR7MzN55JwTgTHn++dBG1LOn2RVXhJLTD35g1qNH8Um0c2ezf/yj/Ovevj0cl3hFReHYNWtm9p3vmH3/+2YjR5rddJPZf/+32d/+lvzkv2CBWfPm4SJnw4bwv9K/f8jfLbeUTPv55+HC54oritv8Nm0KxxrMBgwwO+ussK9XXRV+r7/4RQj+TZuGALR9e+hc8v3vh+Par5/ZBReY3Xef2ddfF29r7VqzYcPCem+8sXztflu3hguoBg3MjjrKrEmTsJ5WrcLvKvY9bN1q9j//k/yiLV0eLGqhsWPDETv33Oxt47e/DSWYpUtTp50/P/yYL7mkeF5BQTiBXn317ukvvjiknz/f7A9/CPvy5JOlr3/jRrMlS0KgSXZyjPfPf4bvJT8/BLDYCf+kk8IJLlaFtWVL+Mc/6aTk6+nXL1xZPvhg+MwddyRPt2pVCHTdupVdojELee/ePVz5fvhh2WljRo8O+e/TJ1zR169fMnjuuWdxyc8snEDq1w9Xw4nVcvPmhZNJYlCPV1RktmhRCL4bN5o9+2xYX79+JU+AMdu3m02bZnbQQSE/V14ZjlU6J8Rp00Ipr3PncNxi27/ggrCus88OJ9kjjwzHKn7fzzij5H4UFJh16RJO2itWlNyfCy8s+Rv7+usQUBo3Dt9t+/Zmf/5zCCyS2e9+V3qeV64MgQSKS7/77x/yPHBgcQeTVq1CFfGrr4Z5DRqEgA8hIMW+y6KiUNpMFvyKikLAglCaiH3f771XHAQHDgzfeatWYTo/P/X3XhoPFrXQxo2hCmDatOxtY+fO8nWV/fnPw6/omGPCP/jBB4d/8PjSQszq1eFEftRR4e+xx2avLviTT8KVeIcOIX8/+UnxsjvuCPPmzCn5mUWLwvx77w35OvfccIJ/8cWS+fzXv8wOOSRUOaVbNbFihe1qd0plxoyQ9ppriuft3Flcd75ypdnhh5s1bGg2eXLx/hx/fLjC/u53i7tAz5kTqvAgnLhOPjlcHccfn7feKq56jH8NGJD6t7BpU8inFD7TvHk4ro8/vvuxXbculBQgBJkDDgjf7003FQeKceN238aOHeEq/Te/Cfvcrl1ow4r11mvZMpxIE337bShRNmwYqqkGDAjfwauvhmPYrVv4fOx7TGX79vCbOuOMUAUa383cLJTq4tv0unYNVbs7d4ZA1KCBWadOofTeuHHx/83f/x7S7NwZ2tViQe6++5J/F48+Gi4KGjcOv9GpUytX0+DBwlWJjRvDVfDxx4d/vrZty/7He+KJ8KurXz9c8WZbUVFosI6/4v3qq1DVMWJEybTXXx/+oWN1zBs2hBIBhKvcp58O9dr16oUgVN7ql/z8UPVWls2bw0mmS5eySyxffRVONLET03nnhZPjxIlh+pe/DKWYffYJV7ivvRbaGTp2LD5BDhoU6sRjXa0ffjiU+O66K1TjxbcvpbJoUajCu/LKUE0Vu/pdvNjs00/DRUXLluG4/+xnYT+/+SaUNmP7kCxQJCooCN9PrPv03XcnL/nErFsXSoqxbTz7bPGyrVtDo/iMGenvZzpmzgxti4ntOW++GQLpkCHhd3TbbcUlkiOOKD42sWqrsmzcmLn7nzxYuGpp585QbZXsqqkq/eQn4cQVq7L59tvQ5jF0aMl0mzaZ/f73oQ499o/84x8X13eXx+23h8/H97RauTJUU4wcGa7GL7vMymxTSczbhReGOvX4YHjBBSGg7bdf2KcPPihetmOH2bvvhpPVAQeE0tGvflW+wJDKjh1mEyYUNxA3aBDyc9ZZyW+mnDKluJdbOjZsCIF6y5b00n/8cTgZP/JI+tuoKlu3ht/XEUeEEsujj2a2J1c60g0WCmlrvvz8fCsoKMh1NlwN8emnYUj4Vq3C2FpNmsBZZ8Hf/hbGyEq0cyf84x+w557hHpeKWLgwPDPld7+Dyy8P8669Fh56CJo3D8OzQBh6fsKEim0DwijEvXvDl1/Cm2+WPiClWdiv+vUrvq2yrFoVBrhs2hRGj4bOnbOzHVc5kmaZWcqhVD1YuDqroCDc7DhzZggWeXnh5rpsnTzNwnPYu3QJN1Z++WU4gZ5zTngG++LF4SbMU08NJ9jKWLMmjAEWP7ikc8mkGyz8SXmuzsrPh3ffDVfxLVqEq/xsBQoID8E644xQQvn6a7j//nAn+pgx4bG6hx4KZ59d+UAB4TG+HihcJnmwcHVavXqh2ufzz+GGG7K/vTPPhKKiMAT9ww+Hqq9DDsn+dp2rrGw+z8I5l6BvX2jbNgSmLVt2H1reuerKSxbOVaF69WDIkBAoTjkFevXKdY6cS48HC+eq2IgR0KgR/OIXuc6Jc+nzaijnqthxx8H69aEHlnM1hZcsnMsBDxSupvFg4ZxzLiUPFs4551LKarCQNEjSYklLJY1JsryTpGmS5kl6U1L7uPmzJM2RtFDSZdnMp3POubJlLVhIqg88DAwGugHDJXVLSHYv8JSZ9QDGAXdG81cB3zWzXkBfYIyk/bOVV+ecc2XLZm+oPsBSM1sGIGkSMARYFJemG3Bd9H468BKAmW2LS9MYry5zrlrbvn07hYWFbN26NddZcaVo0qQJ7du3p2HDhhX6fDaDRTvg07jpQkIpId5cYBjwAHAm0FxSnpmtldQB+BtwEPBTM1uZuAFJo4BRAB07dsz8Hjjn0lJYWEjz5s3p3LkzknKdHZfAzFi7di2FhYV06dKlQuvI5hV7sl9M4hC3NwADJM0GBgCfAUUAZvZpVD11EHChpLa7rcxsgpnlm1l+mzZtMpt751zatm7dSl5engeKakoSeXl5lSr5ZTNYFALx4162B0qUDsxspZkNNbMjgLHRvPWJaYCFwLFZzKtzrpI8UFRvlT0+2QwWM4GukrpIagScC0yJTyCptaRYHm4EHo/mt5e0R/S+FXAMsDiLeXXOOVeGrAULMysCRgNTgQ+AyWa2UNI4SadHyQYCiyV9CLQFxkfzDwXekzQXeAu418zmZyuvzrmqNXFiePBTvXrh78SJlVvf2rVr6dWrF7169WLfffelXbt2u6a3bduWegXAxRdfzOLFZV+TPvzww0ysbGZrKH9SnnOu0j744AMOPfTQtNJOnAijRsHmzcXzmjYND6EaMaLyebn11ltp1qwZNyQ8oCT2LOl69epu58pkx8mflOecq5bGji0ZKCBMjx2b+W0tXbqU7t27c9lll9G7d29WrVrFqFGjyM/P57DDDmPcuHG70vbv3585c+ZQVFREy5YtGTNmDD179qRfv358+eWXANx8883cf//9u9KPGTOGPn36cMghh/DOO+8AsGnTJoYNG0bPnj0ZPnw4+fn5zJkzZ7e83XLLLRx11FG78he7cP/www854YQT6NmzJ71792b58uUA3HHHHRx++OH07NmTsdn4slLwYOGcq1IrVpRvfmUtWrSIH/3oR8yePZt27dpx1113UVBQwNy5c3n99ddZtGjRbp9Zv349AwYMYO7cufTr14/HH3886brNjPfff59f//rXuwLPb3/7W/bdd1/mzp3LmDFjmD17dtLPXnPNNcycOZP58+ezfv16XnvtNQCGDx/Oddddx9y5c3nnnXfYZ599ePnll3n11Vd5//33mTt3Ltdff32Gvp30ebBwzlWp0m6JytatUgceeCBHHXXUrunnnnuO3r1707t3bz744IOkwWKPPfZg8ODBABx55JG7ru4TDR06dLc0b7/9Nueeey4APXv25LDDDkv62WnTptGnTx969uzJW2+9xcKFC1m3bh1r1qzhtNNOA8KNdE2bNuWNN97gkksuYY899gBg7733Lv8XUUkeLJxzVWr8+NBGEa9p0zA/G/bcc89d75csWcIDDzzAP/7xD+bNm8egQYOS3nvQqFGjXe/r169PUVFR0nU3btx4tzTptANv3ryZ0aNH8+KLLzJv3jwuueSSXflI1sXVzHLeNdmDhXOuSo0YERqzO3UCKfzNVON2Kt988w3Nmzdnr732YtWqVUydOjXj2+jfvz+TJ08GYP78+UlLLlu2bKFevXq0bt2aDRs28MILLwDQqlUrWrduzcsvvwyEmx03b97MSSedxB//+Ee2bNkCwFdffZXxfKfiT8pzzlW5ESOqJjgk6t27N926daN79+4ccMABHHPMMRnfxlVXXcUFF1xAjx496N27N927d6dFixYl0uTl5XHhhRfSvXt3OnXqRN++xSMhTZw4kUsvvZSxY8fSqFEjXnjhBU499VTmzp1Lfn4+DRs25LTTTuO2227LeN7L4l1nnXOVVp6us7VdUVERRUVFNGnShCVLlnDSSSexZMkSGjTI/bV5ZbrO5j73zjlXi2zcuJETTzyRoqIizIxHH320WgSKyqr5e+Ccc9VIy5YtmTVrVq6zkXHewO2ccy4lDxbOOedS8mDhnHMuJQ8WzjnnUvJg4Zyr8QYOHLjbDXb3338/V1xxRZmfa9asGQArV67krLPOKnXdqbrl33///WyOGx3x5JNP5uuvv04n6zWGBwvnXI03fPhwJk2aVGLepEmTGD58eFqf33///Xn++ecrvP3EYPHKK6/QsmXLCq+vOvKus865jLr2WkgyInel9OoF0cjgSZ111lncfPPNfPvttzRu3Jjly5ezcuVK+vfvz8aNGxkyZAjr1q1j+/bt3H777QwZMqTE55cvX86pp57KggUL2LJlCxdffDGLFi3i0EMP3TXEBsDll1/OzJkz2bJlC2eddRa/+tWvePDBB1m5ciXHH388rVu3Zvr06XTu3JmCggJat27Nfffdt2vU2pEjR3LttdeyfPlyBg8eTP/+/XnnnXdo164d//u//7troMCYl19+mdtvv51t27aRl5fHxIkTadu2LRs3buSqq66ioKAASdxyyy0MGzaM1157jZtuuokdO3bQunVrpk2blrFj4MHCOVfj5eXl0adPH1577TWGDBnCpEmTOOecc5BEkyZNePHFF9lrr71Ys2YNRx99NKeffnqpA/M98sgjNG3alHnz5jFv3jx69+69a9n48ePZe++92bFjByeeeCLz5s3j6quv5r777mP69Om0bt26xLpmzZrFE088wXvvvYeZ0bdvXwYMGECrVq1YsmQJzz33HH/4wx84++yzeeGFFzjvvPNKfL5///68++67SOKxxx7jnnvu4Te/+Q233XYbLVq0YP788ADRdevWsXr1an784x8zY8YMunTpkvHxo7IaLCQNAh4A6gOPmdldCcs7EZ673Qb4CjjPzAol9QIeAfYCdgDjzezP2cyrcy4zyioBZFOsKioWLGJX82bGTTfdxIwZM6hXrx6fffYZX3zxBfvuu2/S9cyYMYOrr74agB49etCjR49dyyZPnsyECRMoKipi1apVLFq0qMTyRG+//TZnnnnmrpFvhw4dyj//+U9OP/10unTpQq9evYDSh0EvLCzknHPOYdWqVWzbto0uXboA8MYbb5SodmvVqhUvv/wyxx133K40mR7GPGttFpLqAw8Dg4FuwHBJ3RKS3Qs8ZWY9gHHAndH8zcAFZnYYMAi4X1JWKgAz/Sxg51xunHHGGUybNo1///vfbNmyZVeJYOLEiaxevZpZs2YxZ84c2rZtm3RY8njJSh0ff/wx9957L9OmTWPevHmccsopKddT1th7seHNofRh0K+66ipGjx7N/PnzefTRR3dtL9mQ5dkexjybDdx9gKVmtszMtgGTgCEJaboBsUq16bHlZvahmS2J3q8EviSUPjIq9izgTz4Bs/B31CgPGM7VRM2aNWPgwIFccsklJRq2169fzz777EPDhg2ZPn06n3zySZnrOe6445gYnQQWLFjAvHnzgDC8+Z577kmLFi344osvePXVV3d9pnnz5mzYsCHpul566SU2b97Mpk2bePHFFzn22GPT3qf169fTrl07AJ588sld80866SQeeuihXdPr1q2jX79+vPXWW3z88cdA5ocxz2awaAd8GjddGM2LNxcYFr0/E2guKS8+gaQ+QCPgo8QNSBolqUBSwerVq8udwap8FrBzLvuGDx/O3Llzdz2pDmDEiBEUFBSQn5/PxIkT+c53vlPmOi6//HI2btxIjx49uOeee+jTpw8Qnnp3xBFHcNhhh3HJJZeUGN581KhRDB48mOOPP77Eunr37s1FF11Enz596Nu3LyNHjuSII45Ie39uvfVWfvCDH3DssceWaA+5+eabWbduHd27d6dnz55Mnz6dNm3aMGHCBIYOHUrPnj0555xz0t5OOrI2RLmkHwDfN7OR0fT5QB8zuyouzf7AQ0AXYAYhcBxmZuuj5fsBbwIXmtm7ZW2vIkOU16sXShS75x127izXqpyr03yI8pqhug5RXgh0iJtuD6yMTxBVMQ0FkNQMGBYXKPYC/gbcnCpQVFTHjqHqKdl855xzxbJZDTUT6Cqpi6RGwLnAlPgEklpLiuXhRkLPKKL0LxIav/8nWxms6mcBO+dcTZW1YGFmRcBoYCrwATDZzBZKGifp9CjZQGCxpA+BtkDsNH02cBxwkaQ50atXpvOYy2cBO1fb1JanbtZWlT0+/lhV51ylffzxxzRv3py8vLysdt90FWNmrF27lg0bNuy6DyOmOrRZOOfqiPbt21NYWEhFeiW6qtGkSRPat29f4c97sHDOVVrDhg13u2J1tYuPOuuccy4lDxbOOedS8mDhnHMupVrTG0rSaqDsQV921xpYk4XsVGd1cZ+hbu53XdxnqJv7XZl97mRmKcfeqzXBoiIkFaTTZaw2qYv7DHVzv+viPkPd3O+q2GevhnLOOZeSBwvnnHMp1fVgMSHXGciBurjPUDf3uy7uM9TN/c76PtfpNgvnnHPpqeslC+ecc2nwYOGccy6lOhksJA2StFjSUkljcp2fbJHUQdJ0SR9IWijpmmj+3pJel7Qk+tsq13nNNEn1Jc2W9Ndououk96J9/nP0zJRaQ1JLSc9L+k90vPvVkeN8XfTbXiDpOUlNauOxlvS4pC8lLYibl/T4KngwOr/Nk9Q7E3moc8FCUn3gYWAw0A0YLqlbbnOVNUXA9WZ2KHA0cGW0r2OAaWbWFZgWTdc21xCeoxJzN/Df0T6vA36Uk1xlzwPAa2b2HaAnYd9r9XGW1A64Gsg3s+5AfcJD1mrjsf4TMChhXmnHdzDQNXqNAh7JRAbqXLAA+gBLzWyZmW0DJgFDcpynrDCzVWb27+j9BsIJpB1hf5+Mkj0JnJGbHGaHpPbAKcBj0bSAE4DnoyS1ap+jRxAfB/wRwMy2mdnX1PLjHGkA7CGpAdAUWEUtPNZmNgP4KmF2acd3COEpoxY9krqlpP0qm4e6GCzaAZ/GTRdG82o1SZ2BI4D3gLZmtgpCQAH2yV3OsuJ+4GfAzmg6D/g6enoj1L5jfgCwGngiqnp7TNKe1PLjbGafAfcCKwhBYj0wi9p9rOOVdnyzco6ri8Ei2WO8anX/YUnNgBeAa83sm1znJ5sknQp8aWaz4mcnSVqbjnkDoDfwiJkdAWyillU5JRPV0Q8BugD7A3sSqmAS1aZjnY6s/N7rYrAoBDrETbcHVuYoL1knqSEhUEw0s79Es7+IFUujv1/mKn9ZcAxwuqTlhCrGEwgljZZRVQXUvmNeCBSa2XvR9POE4FGbjzPA94CPzWy1mW0H/gJ8l9p9rOOVdnyzco6ri8FiJtA16jHRiNAgNiXHecqKqK7+j8AHZnZf3KIpwIXR+wuB/63qvGWLmd1oZu3NrDPh2P7DzEYA04GzomS1bZ8/Bz6VdEg060RgEbX4OEdWAEdLahr91mP7XWuPdYLSju8U4IKoV9TRwPpYdVVl1Mk7uCWdTLjarA88bmbjc5ylrJDUH/gnMJ/i+vubCO0Wk4GOhH+4H5hZYuNZjSdpIHCDmZ0q6QBCSWNvYDZwnpl9m8v8ZZKkXoQG/UbAMuBiwsVgrT7Okn4FnEPo+TcbGEmon69Vx1rSc8BAwlDkXwC3AC+R5PhGgfMhQu+pzcDFZlZQ6TzUxWDhnHOufOpiNZRzzrly8mDhnHMuJQ8WzjnnUvJg4ZxzLiUPFs4551LyYOFcCpJ2SJoT98rY3dGSOsePJOpcddUgdRLn6rwtZtYr15lwLpe8ZOFcBUlaLuluSe9Hr4Oi+Z0kTYueJTBNUsdofltJL0qaG72+G62qvqQ/RM9l+LukPaL0V0taFK1nUo520znAg4Vz6dgjoRrqnLhl35hZH8Ids/dH8x4iDBHdA5gIPBjNfxB4y8x6EsZuWhjN7wo8bGaHAV8Dw6L5Y4AjovVclq2dcy4dfge3cylI2mhmzZLMXw6cYGbLogEbPzezPElrgP3MbHs0f5WZtZa0GmgfP/RENHT869EDbJD0c6Chmd0u6TVgI2FYh5fMbGOWd9W5UnnJwrnKsVLel5Ymmfhxi3ZQ3JZ4CuGpjkcCs+JGUnWuynmwcK5yzon7+6/o/TuEEW8BRgBvR++nAZfDrmeE71XaSiXVAzqY2XTCg5xaAruVbpyrKn6l4lxqe0iaEzf9mpnFus82lvQe4cJreDTvauBxST8lPMHu4mj+NcAEST8ilCAuJzzhLZn6wDOSWhAeZvPf0aNSncsJb7NwroKiNot8M1uT67w4l21eDeWccy4lL1k455xLyUsWzjnnUvJg4ZxzLiUPFs4551LyYOGccy4lDxbOOedS+n/mI294Jg/yvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000/120000 [==============================] - 131s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7114666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "In the case of a two-class (binary) classification problem, the sigmoid activation function is often used in the output layer. \n",
    "The predicted probability is taken as the likelihood of the observation belonging to class 1, or inverted (1 – probability) to give the probability for class 0.\n",
    "In the case of a multi-class classification problem, the softmax activation function \n",
    "is often used on the output layer and the likelihood of the observation for each class is returned as a vector.\n",
    "'''\n",
    "\n",
    "y_prob = model.predict(x_val, verbose=1)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_classes_prob=[s.max() for s in y_prob]\n",
    "y_classes_val=y_val.argmax(axis=-1)\n",
    "\n",
    "df_val=pd.DataFrame({'pred':y_classes, \n",
    "                     'true':y_classes_val, \n",
    "                     'prob':y_classes_prob})\n",
    "len(df_val[df_val.pred==df_val.true])/len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 67s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.772"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "In the case of a two-class (binary) classification problem, the sigmoid activation function is often used in the output layer. \n",
    "The predicted probability is taken as the likelihood of the observation belonging to class 1, or inverted (1 – probability) to give the probability for class 0.\n",
    "In the case of a multi-class classification problem, the softmax activation function \n",
    "is often used on the output layer and the likelihood of the observation for each class is returned as a vector.\n",
    "'''\n",
    "\n",
    "y_prob = model.predict(x_val, verbose=1)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_classes_prob=[s.max() for s in y_prob]\n",
    "y_classes_val=y_val.argmax(axis=-1)\n",
    "\n",
    "df_val=pd.DataFrame({'pred':y_classes, \n",
    "                     'true':y_classes_val, \n",
    "                     'prob':y_classes_prob})\n",
    "len(df_val[df_val.pred==df_val.true])/len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9622186495176849 0.2799\n"
     ]
    }
   ],
   "source": [
    "df_95=df_val[df_val.prob>.95]\n",
    "print(len(df_95[df_95.pred==df_95.true])/len(df_95), len(df_95)/len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8247847099301924 0.8380166666666666\n"
     ]
    }
   ],
   "source": [
    "df_95=df_val[df_val.prob>.95]\n",
    "print(len(df_95[df_95.pred==df_95.true])/len(df_95), len(df_95)/len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103961</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108469</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.734190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93711</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.355544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.570191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.978139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82817</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0.352130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108688</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.568966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred  true      prob\n",
       "103961     1     1  0.985984\n",
       "108469    22    22  0.734190\n",
       "7313      12     4  0.962335\n",
       "93711     18     8  0.355544\n",
       "5599      15    15  0.570191\n",
       "19319     13    13  0.978139\n",
       "82817      9    24  0.352130\n",
       "108688     6     4  0.568966\n",
       "7007       0     0  0.639623\n",
       "14189      1     1  0.982786"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7141.0</td>\n",
       "      <td>0.957103</td>\n",
       "      <td>0.126478</td>\n",
       "      <td>0.229419</td>\n",
       "      <td>0.998169</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9724.0</td>\n",
       "      <td>0.956446</td>\n",
       "      <td>0.121383</td>\n",
       "      <td>0.236291</td>\n",
       "      <td>0.991681</td>\n",
       "      <td>0.998505</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.999765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2821.0</td>\n",
       "      <td>0.964629</td>\n",
       "      <td>0.105224</td>\n",
       "      <td>0.274197</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7520.0</td>\n",
       "      <td>0.950879</td>\n",
       "      <td>0.128234</td>\n",
       "      <td>0.237091</td>\n",
       "      <td>0.991907</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2284.0</td>\n",
       "      <td>0.935041</td>\n",
       "      <td>0.141478</td>\n",
       "      <td>0.236927</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18262.0</td>\n",
       "      <td>0.959980</td>\n",
       "      <td>0.115731</td>\n",
       "      <td>0.228170</td>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>619.0</td>\n",
       "      <td>0.877976</td>\n",
       "      <td>0.168429</td>\n",
       "      <td>0.258173</td>\n",
       "      <td>0.808330</td>\n",
       "      <td>0.971120</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>0.999551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9973.0</td>\n",
       "      <td>0.940191</td>\n",
       "      <td>0.136961</td>\n",
       "      <td>0.255074</td>\n",
       "      <td>0.976959</td>\n",
       "      <td>0.999343</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>0.894974</td>\n",
       "      <td>0.179073</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>0.877703</td>\n",
       "      <td>0.993165</td>\n",
       "      <td>0.999525</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob                                                              \\\n",
       "        count      mean       std       min       25%       50%       75%   \n",
       "pred                                                                        \n",
       "0      7141.0  0.957103  0.126478  0.229419  0.998169  0.999893  0.999933   \n",
       "1      9724.0  0.956446  0.121383  0.236291  0.991681  0.998505  0.999204   \n",
       "2      2821.0  0.964629  0.105224  0.274197  0.996004  0.999733  0.999881   \n",
       "3      7520.0  0.950879  0.128234  0.237091  0.991907  0.999634  0.999862   \n",
       "4      2284.0  0.935041  0.141478  0.236927  0.965517  0.997631  0.999440   \n",
       "5     18262.0  0.959980  0.115731  0.228170  0.994119  0.999392  0.999751   \n",
       "6       619.0  0.877976  0.168429  0.258173  0.808330  0.971120  0.996357   \n",
       "7      9973.0  0.940191  0.136961  0.255074  0.976959  0.999343  0.999886   \n",
       "8      1656.0  0.894974  0.179073  0.269879  0.877703  0.993165  0.999525   \n",
       "\n",
       "                \n",
       "           max  \n",
       "pred            \n",
       "0     0.999954  \n",
       "1     0.999765  \n",
       "2     0.999972  \n",
       "3     0.999965  \n",
       "4     0.999860  \n",
       "5     0.999849  \n",
       "6     0.999551  \n",
       "7     0.999947  \n",
       "8     0.999932  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('pred')[['prob']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12602.0</td>\n",
       "      <td>0.848058</td>\n",
       "      <td>0.192906</td>\n",
       "      <td>0.099420</td>\n",
       "      <td>0.793265</td>\n",
       "      <td>0.942826</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.995070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26000.0</td>\n",
       "      <td>0.809861</td>\n",
       "      <td>0.238692</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.683788</td>\n",
       "      <td>0.946383</td>\n",
       "      <td>0.980377</td>\n",
       "      <td>0.993897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2297.0</td>\n",
       "      <td>0.605833</td>\n",
       "      <td>0.191890</td>\n",
       "      <td>0.094463</td>\n",
       "      <td>0.444121</td>\n",
       "      <td>0.639296</td>\n",
       "      <td>0.778246</td>\n",
       "      <td>0.894880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3366.0</td>\n",
       "      <td>0.874512</td>\n",
       "      <td>0.173787</td>\n",
       "      <td>0.157057</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.956173</td>\n",
       "      <td>0.967872</td>\n",
       "      <td>0.974627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6441.0</td>\n",
       "      <td>0.741391</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.126705</td>\n",
       "      <td>0.554008</td>\n",
       "      <td>0.835144</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.982064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1366.0</td>\n",
       "      <td>0.386526</td>\n",
       "      <td>0.105981</td>\n",
       "      <td>0.138421</td>\n",
       "      <td>0.305284</td>\n",
       "      <td>0.385955</td>\n",
       "      <td>0.467187</td>\n",
       "      <td>0.617621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4108.0</td>\n",
       "      <td>0.498052</td>\n",
       "      <td>0.147095</td>\n",
       "      <td>0.093204</td>\n",
       "      <td>0.387617</td>\n",
       "      <td>0.518314</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.768572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2320.0</td>\n",
       "      <td>0.352670</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.114436</td>\n",
       "      <td>0.243909</td>\n",
       "      <td>0.338815</td>\n",
       "      <td>0.453435</td>\n",
       "      <td>0.642961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4780.0</td>\n",
       "      <td>0.656115</td>\n",
       "      <td>0.247266</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.423637</td>\n",
       "      <td>0.723281</td>\n",
       "      <td>0.890782</td>\n",
       "      <td>0.956166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1540.0</td>\n",
       "      <td>0.504510</td>\n",
       "      <td>0.168473</td>\n",
       "      <td>0.120028</td>\n",
       "      <td>0.371044</td>\n",
       "      <td>0.496594</td>\n",
       "      <td>0.645774</td>\n",
       "      <td>0.853527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4314.0</td>\n",
       "      <td>0.715330</td>\n",
       "      <td>0.189366</td>\n",
       "      <td>0.112852</td>\n",
       "      <td>0.583356</td>\n",
       "      <td>0.787513</td>\n",
       "      <td>0.871542</td>\n",
       "      <td>0.940572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3242.0</td>\n",
       "      <td>0.877686</td>\n",
       "      <td>0.178106</td>\n",
       "      <td>0.129092</td>\n",
       "      <td>0.897202</td>\n",
       "      <td>0.958898</td>\n",
       "      <td>0.972096</td>\n",
       "      <td>0.981479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11921.0</td>\n",
       "      <td>0.839911</td>\n",
       "      <td>0.196575</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.780404</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.971170</td>\n",
       "      <td>0.987029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1574.0</td>\n",
       "      <td>0.418690</td>\n",
       "      <td>0.133496</td>\n",
       "      <td>0.140829</td>\n",
       "      <td>0.314354</td>\n",
       "      <td>0.406837</td>\n",
       "      <td>0.524091</td>\n",
       "      <td>0.754473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10648.0</td>\n",
       "      <td>0.547153</td>\n",
       "      <td>0.193563</td>\n",
       "      <td>0.109558</td>\n",
       "      <td>0.393835</td>\n",
       "      <td>0.548929</td>\n",
       "      <td>0.714959</td>\n",
       "      <td>0.908429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>418.0</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.045120</td>\n",
       "      <td>0.103251</td>\n",
       "      <td>0.193242</td>\n",
       "      <td>0.220646</td>\n",
       "      <td>0.252260</td>\n",
       "      <td>0.344682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.130555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9300.0</td>\n",
       "      <td>0.676713</td>\n",
       "      <td>0.271094</td>\n",
       "      <td>0.113672</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.741195</td>\n",
       "      <td>0.942738</td>\n",
       "      <td>0.991517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.169295</td>\n",
       "      <td>0.028792</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.165717</td>\n",
       "      <td>0.188771</td>\n",
       "      <td>0.247617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5613.0</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.217035</td>\n",
       "      <td>0.120058</td>\n",
       "      <td>0.738421</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>0.964420</td>\n",
       "      <td>0.985283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4228.0</td>\n",
       "      <td>0.618473</td>\n",
       "      <td>0.193106</td>\n",
       "      <td>0.099853</td>\n",
       "      <td>0.471122</td>\n",
       "      <td>0.656026</td>\n",
       "      <td>0.788790</td>\n",
       "      <td>0.900154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3834.0</td>\n",
       "      <td>0.724429</td>\n",
       "      <td>0.196630</td>\n",
       "      <td>0.097521</td>\n",
       "      <td>0.595665</td>\n",
       "      <td>0.792248</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>0.959967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob                                                              \\\n",
       "        count      mean       std       min       25%       50%       75%   \n",
       "pred                                                                        \n",
       "0     12602.0  0.848058  0.192906  0.099420  0.793265  0.942826  0.977441   \n",
       "1     26000.0  0.809861  0.238692  0.087219  0.683788  0.946383  0.980377   \n",
       "2      2297.0  0.605833  0.191890  0.094463  0.444121  0.639296  0.778246   \n",
       "3      3366.0  0.874512  0.173787  0.157057  0.883541  0.956173  0.967872   \n",
       "4      6441.0  0.741391  0.234529  0.126705  0.554008  0.835144  0.945148   \n",
       "5      1366.0  0.386526  0.105981  0.138421  0.305284  0.385955  0.467187   \n",
       "6      4108.0  0.498052  0.147095  0.093204  0.387617  0.518314  0.620197   \n",
       "8      2320.0  0.352670  0.128075  0.114436  0.243909  0.338815  0.453435   \n",
       "9      4780.0  0.656115  0.247266  0.120240  0.423637  0.723281  0.890782   \n",
       "10     1540.0  0.504510  0.168473  0.120028  0.371044  0.496594  0.645774   \n",
       "11     4314.0  0.715330  0.189366  0.112852  0.583356  0.787513  0.871542   \n",
       "12     3242.0  0.877686  0.178106  0.129092  0.897202  0.958898  0.972096   \n",
       "13    11921.0  0.839911  0.196575  0.118600  0.780404  0.941785  0.971170   \n",
       "14     1574.0  0.418690  0.133496  0.140829  0.314354  0.406837  0.524091   \n",
       "15    10648.0  0.547153  0.193563  0.109558  0.393835  0.548929  0.714959   \n",
       "16      418.0  0.222347  0.045120  0.103251  0.193242  0.220646  0.252260   \n",
       "17        1.0  0.130555       NaN  0.130555  0.130555  0.130555  0.130555   \n",
       "18     9300.0  0.676713  0.271094  0.113672  0.425342  0.741195  0.942738   \n",
       "19       87.0  0.169295  0.028792  0.112522  0.147757  0.165717  0.188771   \n",
       "22     5613.0  0.813688  0.217035  0.120058  0.738421  0.924710  0.964420   \n",
       "23     4228.0  0.618473  0.193106  0.099853  0.471122  0.656026  0.788790   \n",
       "24     3834.0  0.724429  0.196630  0.097521  0.595665  0.792248  0.883907   \n",
       "\n",
       "                \n",
       "           max  \n",
       "pred            \n",
       "0     0.995070  \n",
       "1     0.993897  \n",
       "2     0.894880  \n",
       "3     0.974627  \n",
       "4     0.982064  \n",
       "5     0.617621  \n",
       "6     0.768572  \n",
       "8     0.642961  \n",
       "9     0.956166  \n",
       "10    0.853527  \n",
       "11    0.940572  \n",
       "12    0.981479  \n",
       "13    0.987029  \n",
       "14    0.754473  \n",
       "15    0.908429  \n",
       "16    0.344682  \n",
       "17    0.130555  \n",
       "18    0.991517  \n",
       "19    0.247617  \n",
       "22    0.985283  \n",
       "23    0.900154  \n",
       "24    0.959967  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('pred')[['prob']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 200)         6692600   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 200000)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               102400512 \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 109,159,937\n",
      "Trainable params: 102,467,337\n",
      "Non-trainable params: 6,692,600\n",
      "_________________________________________________________________\n",
      "Train on 8399 samples, validate on 33601 samples\n",
      "Epoch 1/2\n",
      "8399/8399 [==============================] - 125s 15ms/step - loss: 0.2489 - acc: 0.9057 - precision: 0.1104 - recall: 0.9940 - val_loss: 0.2185 - val_acc: 0.9155 - val_precision: 0.1111 - val_recall: 1.0000\n",
      "Epoch 2/2\n",
      "8399/8399 [==============================] - 121s 14ms/step - loss: 0.1594 - acc: 0.9394 - precision: 0.1111 - recall: 1.0000 - val_loss: 0.2231 - val_acc: 0.9167 - val_precision: 0.1111 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization, GlobalMaxPooling1D, GRU, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "'''\n",
    "x = GRU(units=128, activation='tanh', return_sequences=True)(embedded_sequences)\n",
    "\n",
    "x = LSTM(units=256, activation='tanh', return_sequences=False)(embedded_sequences)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#x = LSTM(units=128, activation='tanh', return_sequences=True)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "'''\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dense(units=128, activation='tanh')(x)\n",
    "preds = Dense(units=9, activation='softmax')(x) #softmax\n",
    "\n",
    "# x = Dense(units=512, activation='relu')(x)\n",
    "# x = Dense(units=128, activation='relu')(x)\n",
    "# preds = Dense(units=25, activation='sigmoid')(x) #softmax\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', #'rmsprop',\n",
    "              metrics=['acc',precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.8,\n",
    "#                     validation_data=(x_val, y_val),\n",
    "                    epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 25s 412us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19112927243113517, 0.9295742606123288, 0.1111111119389534, 1.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=500, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37694"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val[df_val.pred==df_val.true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 7, 5, 3, 4, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_95.pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
