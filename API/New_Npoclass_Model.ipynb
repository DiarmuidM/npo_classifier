{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "New Npoclass Model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002213350b614726ae550decff970d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e87c0ed162f546ab8f19650870a5fee7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_165e1bbce2274f2aa86059ec00a09628",
              "IPY_MODEL_b393796083f341a587d2495b972bf575"
            ]
          }
        },
        "e87c0ed162f546ab8f19650870a5fee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "165e1bbce2274f2aa86059ec00a09628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26446f80406e436797833424bd581ee1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94e818de175e49fcb63da727847ac49c"
          }
        },
        "b393796083f341a587d2495b972bf575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55db93bae33b4b728db84f3ef192866a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:13&lt;00:00, 26.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d3dcbddee5c4e3fbbb0c97da0bb7b8c"
          }
        },
        "26446f80406e436797833424bd581ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94e818de175e49fcb63da727847ac49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55db93bae33b4b728db84f3ef192866a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d3dcbddee5c4e3fbbb0c97da0bb7b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9839ff2b08ab42d5aceef7fea0946c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_795b00e6d8964bc6b1ae8e7dcd9d9e7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b3e018c7ed74f1197065e4585409329",
              "IPY_MODEL_f1e946af14b6447c9a0c45013a145520"
            ]
          }
        },
        "795b00e6d8964bc6b1ae8e7dcd9d9e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b3e018c7ed74f1197065e4585409329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96d4373c206a4cbfab78763149d85df9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d13ba2bf676487f939fa0f120f1b1dc"
          }
        },
        "f1e946af14b6447c9a0c45013a145520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e521ff2147f745e1b55724f51e5e029d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 39.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afc2cd4f389c415b9404a8ec2e4d7a57"
          }
        },
        "96d4373c206a4cbfab78763149d85df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d13ba2bf676487f939fa0f120f1b1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e521ff2147f745e1b55724f51e5e029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afc2cd4f389c415b9404a8ec2e4d7a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcxdG61s-_qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.set_device(0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqp5p_ra-_qj",
        "colab_type": "text"
      },
      "source": [
        "### Test the loaded models and tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHKbyGO6Qbtd",
        "colab_type": "code",
        "outputId": "2d53d3cf-fb8a-4374-b58d-bc756422e3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_path = 'gdrive/My Drive/convert to Bert/train/'\n",
        "test_path = 'gdrive/My Drive/convert to Bert/test/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrrTWzGM-_qm",
        "colab_type": "text"
      },
      "source": [
        "#### Load UCF files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m6wurxc-_qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "broad_cat_dict={'I': ['A'],\n",
        "                'II': ['B'],\n",
        "                'III': ['C', 'D'],\n",
        "                'IV': ['E', 'F', 'G', 'H'],\n",
        "                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
        "                'VI': ['Q'],\n",
        "                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
        "                'VIII': ['X'],\n",
        "                'IX': ['Y'],\n",
        "                'X': ['Z'],\n",
        "              }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYBS25xFrmLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def split_dataset(data_path):\n",
        "  file_list=os.listdir(data_path)\n",
        "  df_data=pd.DataFrame()\n",
        "  for file in file_list:\n",
        "    print(data_path+file)\n",
        "    df_data=pd.concat([df_data, pd.read_pickle(data_path+file, compression='gzip')])\n",
        "\n",
        "  df_data['mission_prgrm_spellchk']=df_data['TAXPAYER_NAME']+' '+df_data['mission_spellchk']+' '+df_data['prgrm_dsc_spellchk'] # Using spell-checked.\n",
        "  df_data['broad_cat']=df_data['NTEE1'].apply(ntee2cat)\n",
        "  print(len(df_data['mission_prgrm_spellchk']), len(df_data['NTEE1'].drop_duplicates()), len(df_data['broad_cat'].drop_duplicates()))\n",
        "  return df_data\n",
        "\n",
        "def ntee2cat(string):\n",
        "  return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M72qqJPFn4Sf",
        "colab_type": "code",
        "outputId": "5211e61e-8994-4f5a-b984-a800503345bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_train = split_dataset(train_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/convert to Bert/train/df_ucf_train.pkl.gz_1of4\n",
            "gdrive/My Drive/convert to Bert/train/df_ucf_train.pkl.gz_2of4\n",
            "gdrive/My Drive/convert to Bert/train/df_ucf_train.pkl.gz_3of4\n",
            "gdrive/My Drive/convert to Bert/train/df_ucf_train.pkl.gz_4of4\n",
            "gdrive/My Drive/convert to Bert/train/df_ucf_train.pkl.gz_0of4\n",
            "154424 25 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kVw1LCQjWnb",
        "colab_type": "code",
        "outputId": "fafa92f7-e0f4-4304-8be5-6117900c8ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df_test = split_dataset(test_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/convert to Bert/test/df_ucf_test.pkl.gz\n",
            "38607 25 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFuqOIdKZ1o1",
        "colab_type": "code",
        "outputId": "4ce83ff8-a8f0-4ce5-c242-292ddc3401a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaUGh5wF-_qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkMeZSx0-_qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "#encoding function\n",
        "def padding_text(dataset):\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "  text_list =  dataset['mission_prgrm_spellchk']\n",
        "  for text in text_list:\n",
        "    encode_plus = tokenizer.encode_plus(            \n",
        "                        text,    \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 512,        \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt')   \n",
        "    input_ids.append(encode_plus['input_ids'])\n",
        "    attention_masks.append(encode_plus['attention_mask'])\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  lb_broad_cat = preprocessing.LabelEncoder().fit_transform(dataset['broad_cat'])\n",
        "  lb_major_group = preprocessing.LabelEncoder().fit_transform(dataset['NTEE1'])\n",
        "  lb_broad_cat = torch.tensor(lb_broad_cat)\n",
        "  lb_major_group = torch.tensor(lb_major_group)\n",
        "  return input_ids, attention_masks, lb_broad_cat, lb_major_group"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76dyknRG-_q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoding train and test dataset\n",
        "input_ids_train, attention_masks_train, lb_broad_group_train, lb_major_group_train = padding_text(df_train)\n",
        "input_ids_test, attention_masks_test, lb_broad_cat_test, lb_major_group_test = padding_text(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZne6VF9-_q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import *\n",
        "\n",
        "#combining data and loading Bert\n",
        "def train_test_dataset(train_label, test_label, num_label, batch_size):\n",
        "  \n",
        "  train_dataset = TensorDataset(input_ids_train, attention_masks_train, train_label)\n",
        "  test_dataset = TensorDataset(input_ids_test, attention_masks_test, test_label)\n",
        "  \n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset),\n",
        "              batch_size = batch_size )\n",
        "\n",
        "  validation_dataloader = DataLoader(test_dataset,\n",
        "              sampler = SequentialSampler(test_dataset), \n",
        "              batch_size = batch_size)\n",
        "  \n",
        "  global model\n",
        "\n",
        "  model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                                num_labels=num_label) \n",
        "  model.cuda()\n",
        "  \n",
        "  \n",
        "  return train_dataloader, validation_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Hjw1ZwZiXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "#function for adjusting parameters\n",
        "def parameters(learning_rate, eps, num_epoch):\n",
        "  \n",
        "  global epochs\n",
        "  epochs = num_epoch\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate, \n",
        "                    eps = eps \n",
        "                  )\n",
        "  \n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, \n",
        "                                              num_training_steps = total_steps)\n",
        "  return optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBCrvwtZZl30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#function that will evaluate the accuracy of the model\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L45ZQt-ZZqAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtewSfztZvA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "#loading data into the Bert model\n",
        "\n",
        "def run_bert(train_dataloader, validation_dataloader, optimizer, scheduler):\n",
        "\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed) \n",
        "\n",
        "  loss_values = []\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      total_loss = 0\n",
        "\n",
        "      \n",
        "      model.train()\n",
        "      model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    \n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          if step % 2000 == 0 and not step == 0:\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          \n",
        "          model.zero_grad() \n",
        "          \n",
        "          outputs = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "          \n",
        "          loss = outputs[0] \n",
        "          total_loss += loss.item()\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          \n",
        "          optimizer.step()\n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "      avg_train_loss = total_loss / len(train_dataloader)            \n",
        "      \n",
        "      loss_values.append(avg_train_loss)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "          \n",
        "      #               Validation\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(\"Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      eval_loss, eval_accuracy = 0, 0\n",
        "      nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "      for batch in validation_dataloader:\n",
        "          \n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          \n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "          with torch.no_grad():        \n",
        "\n",
        "      \n",
        "              outputs = model(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=b_input_mask)\n",
        "          logits = outputs[0]\n",
        "\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "          \n",
        "          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "          \n",
        "          eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "          nb_eval_steps += 1\n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0bASJDsrAj0",
        "colab_type": "code",
        "outputId": "31be0ac7-5746-4590-e16c-99328d456101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "002213350b614726ae550decff970d5e",
            "e87c0ed162f546ab8f19650870a5fee7",
            "165e1bbce2274f2aa86059ec00a09628",
            "b393796083f341a587d2495b972bf575",
            "26446f80406e436797833424bd581ee1",
            "94e818de175e49fcb63da727847ac49c",
            "55db93bae33b4b728db84f3ef192866a",
            "7d3dcbddee5c4e3fbbb0c97da0bb7b8c",
            "9839ff2b08ab42d5aceef7fea0946c6a",
            "795b00e6d8964bc6b1ae8e7dcd9d9e7f",
            "6b3e018c7ed74f1197065e4585409329",
            "f1e946af14b6447c9a0c45013a145520",
            "96d4373c206a4cbfab78763149d85df9",
            "5d13ba2bf676487f939fa0f120f1b1dc",
            "e521ff2147f745e1b55724f51e5e029d",
            "afc2cd4f389c415b9404a8ec2e4d7a57"
          ]
        }
      },
      "source": [
        "#load broad group label\n",
        "train_dataloader, validation_dataloader= train_test_dataset(train_label = lb_major_group_train, \n",
        "                                                            test_label = lb_major_group_test, \n",
        "                                                            num_label = 25, batch_size = 8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "002213350b614726ae550decff970d5e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9839ff2b08ab42d5aceef7fea0946c6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nICEZ-3wsSV",
        "colab_type": "code",
        "outputId": "942261b8-c6dd-4674-995a-584503fb5145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "optimizer, scheduler = parameters(learning_rate = 5e-5, eps = 1e-12, num_epoch = 4)\n",
        "run_bert(train_dataloader, validation_dataloader, optimizer, scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch 2,000  of  19,303.    Elapsed: 0:15:47.\n",
            "  Batch 4,000  of  19,303.    Elapsed: 0:31:34.\n",
            "  Batch 6,000  of  19,303.    Elapsed: 0:47:19.\n",
            "  Batch 8,000  of  19,303.    Elapsed: 1:03:05.\n",
            "  Batch 10,000  of  19,303.    Elapsed: 1:18:51.\n",
            "  Batch 12,000  of  19,303.    Elapsed: 1:34:36.\n",
            "  Batch 14,000  of  19,303.    Elapsed: 1:50:21.\n",
            "  Batch 16,000  of  19,303.    Elapsed: 2:06:06.\n",
            "  Batch 18,000  of  19,303.    Elapsed: 2:21:52.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 2:32:09\n",
            "\n",
            "\n",
            "Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:11:05\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch 2,000  of  19,303.    Elapsed: 0:15:46.\n",
            "  Batch 4,000  of  19,303.    Elapsed: 0:31:34.\n",
            "  Batch 6,000  of  19,303.    Elapsed: 0:47:22.\n",
            "  Batch 8,000  of  19,303.    Elapsed: 1:03:09.\n",
            "  Batch 10,000  of  19,303.    Elapsed: 1:18:55.\n",
            "  Batch 12,000  of  19,303.    Elapsed: 1:34:41.\n",
            "  Batch 14,000  of  19,303.    Elapsed: 1:50:26.\n",
            "  Batch 16,000  of  19,303.    Elapsed: 2:06:11.\n",
            "  Batch 18,000  of  19,303.    Elapsed: 2:21:55.\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epcoh took: 2:32:12\n",
            "\n",
            "\n",
            "Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:11:05\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch 2,000  of  19,303.    Elapsed: 0:15:44.\n",
            "  Batch 4,000  of  19,303.    Elapsed: 0:31:28.\n",
            "  Batch 6,000  of  19,303.    Elapsed: 0:47:11.\n",
            "  Batch 8,000  of  19,303.    Elapsed: 1:02:55.\n",
            "  Batch 10,000  of  19,303.    Elapsed: 1:18:38.\n",
            "  Batch 12,000  of  19,303.    Elapsed: 1:34:22.\n",
            "  Batch 14,000  of  19,303.    Elapsed: 1:50:04.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZNK8tPTtTih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load broad group label\n",
        "train_dataloader, validation_dataloader= train_test_dataset(train_label = lb_broad_group_train, test_label = lb_broad_cat_test, num_label = 9, batch_size = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07xSPOUvw49R",
        "colab_type": "code",
        "outputId": "6934973a-1f1d-4bd8-efe5-714126bf3044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "optimizer, scheduler = parameters(learning_rate = 5e-5, eps = 1e-12, num_epoch = 4)\n",
        "run_bert(train_dataloader, validation_dataloader, optimizer, scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch 2,000  of  19,303.    Elapsed: 0:15:05.\n",
            "  Batch 4,000  of  19,303.    Elapsed: 0:30:09.\n",
            "  Batch 6,000  of  19,303.    Elapsed: 0:45:13.\n",
            "  Batch 8,000  of  19,303.    Elapsed: 1:00:18.\n",
            "  Batch 10,000  of  19,303.    Elapsed: 1:15:24.\n",
            "  Batch 12,000  of  19,303.    Elapsed: 1:30:29.\n",
            "  Batch 14,000  of  19,303.    Elapsed: 1:45:33.\n",
            "  Batch 16,000  of  19,303.    Elapsed: 2:00:37.\n",
            "  Batch 18,000  of  19,303.    Elapsed: 2:15:41.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 2:25:31\n",
            "\n",
            "\n",
            "Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:11:20\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3c5642542301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-ee9d46463dca>\u001b[0m in \u001b[0;36mrun_bert\u001b[0;34m(train_dataloader, validation_dataloader, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HhuGYQ2-_rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}