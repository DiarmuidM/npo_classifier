{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Bert_API.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"9xwzy6WT7mfQ","colab_type":"code","colab":{}},"source":["#set up environment\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import *\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn import preprocessing"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxSrO2-D7mfT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rF3F18Y7mfW","colab_type":"code","colab":{}},"source":["################################### Define functions ##########################\n","def npoclass(string_input):\n","    \n","    #define local functions\n","    #this function will check whether there is GPU acceleration avaliable. \n","    #If there is, the function will let the user choose whether the program should use the GPU or CPU.\n","    #If not, the program will automatically use CPU\n","    \n","    def device_selection():\n","        if torch.cuda.is_available():    \n","\n","            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","            print('Do you want to the GPU accelaration?')\n","\n","            selection = input(\"please enter 'yes' or 'no.'\")\n","\n","            if selection == 'yes':\n","\n","                device = torch.device('cuda')\n","                print('Using GPU:',torch.cuda.get_device_name(0))\n","\n","            elif selection =='no':\n","\n","                print('Using the CPU instead.')\n","                device = torch.device(\"cpu\")\n","\n","            elif selection != 'no' or selection != 'yes':\n","                print(\"Wrong selection.\\n\\n\")\n","\n","                device_selection()\n","\n","        else:\n","            print('No GPU available, using the CPU instead.')\n","            device = torch.device(\"cpu\")\n","        return device\n","\n","    #this local function will load a pretrained model and make prediction. \n","    def load_model(dir_path, labels):\n","        #load a pretrained model\n","        model_loaded = BertForSequenceClassification.from_pretrained(dir_path) \n","        tokenizer_loaded = BertTokenizer.from_pretrained(dir_path)  \n","\n","        # Tokenize all of the sentences and map the tokens to thier word IDs.\n","        input_ids = []\n","        attention_masks = []\n","\n","        # For every sentence...\n","        for sent in tqdm(string_input):\n","\n","            encoded_dict = tokenizer_loaded.encode_plus(\n","                                sent,                      \n","                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                                max_length = 256,           # Pad & truncate all sentences.\n","                                pad_to_max_length = True,\n","                                return_attention_mask = True,   # Construct attn. masks.\n","                                return_tensors = 'pt',     # Return pytorch tensors.\n","                           )\n","\n","            # Add the encoded sentence to the list.    \n","            input_ids.append(encoded_dict['input_ids'])\n","\n","            # And its attention mask (simply differentiates padding from non-padding).\n","            attention_masks.append(encoded_dict['attention_mask'])\n","\n","        # Convert the lists into tensors.\n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","\n","        #prepare dataloader\n","        batch_size = 32\n","        test_data = TensorDataset(input_ids, attention_masks)\n","        test_sampler = SequentialSampler(test_data)\n","        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","\n","        #this local function will setup timer for recording prediction time.\n","        def format_time(elapsed):\n","                '''\n","                Takes a time in seconds and returns a string hh:mm:ss\n","                '''\n","                # Round to the nearest second.\n","                elapsed_rounded = int(round((elapsed)))\n","\n","                # Format as hh:mm:ss\n","                return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","        #if the use choose to use GPU, the model will be load to GPU.\n","        if device == 'cuda':\n","            # Set the seed value all over the place to make this reproducible.\n","            seed_val = 42\n","            random.seed(seed_val)\n","            np.random.seed(seed_val)\n","            torch.manual_seed(seed_val)\n","            torch.cuda.manual_seed_all(seed_val)\n","            #load model to GPU\n","            model_loaded.cuda()\n","\n","        logits_all=[]\n","        label_ids_all=[]\n","        logits_argmax=[]\n","        logits_amax=[]\n","        t0 = time.time()\n","\n","        for batch in test_dataloader:\n","\n","            # Add batch to the pre-chosen device\n","            batch = tuple(t.to(device) for t in batch)\n","\n","            b_input_ids, b_input_mask = batch\n","\n","            with torch.no_grad():        \n","\n","                outputs = model_loaded(b_input_ids, \n","                                       token_type_ids=None, \n","                                       attention_mask=b_input_mask)\n","\n","\n","            logits = outputs[0]\n","            \n","            # Move logits and labels to CPU\n","            logits = logits.detach().cpu().numpy()\n","            \n","            #find the max value of logits\n","            logits_amax += list(np.amax(logits, axis=1))\n","            logits_argmax += list(np.argmax(logits, axis=1))\n","        \n","        print(\"  Prediction took: {:}\".format(format_time(time.time() - t0)))\n","        #use softmax to calculate the probability\n","        propability=tf.nn.softmax(logits_amax)\n","        \n","        #convert propability to a numpy array\n","        propability= tf.constant(propability).numpy()\n","        #convert logits to labels\n","        logits_all_letter=preprocessing.LabelEncoder().fit(labels).inverse_transform(logits_argmax)\n","\n","        return logits_all_letter,propability\n","\n","    #setup classification labels\n","    broad_cat = ['I','II','III','IV','V','VI',\n","                    'VII','VIII','IX','X']\n","\n","    major_group= ['A','B','C', 'D','E', 'F', 'G', 'H','I', 'J', 'K', 'L', 'M', 'N', \n","                  'O', 'P','Q','R', 'S', 'T', 'U', 'V', 'W','X','Y', 'Z']\n","    \n","    device = device_selection()\n","    \n","    #run the loading model function with major group classification\n","    major_group_label, major_group_prob = load_model(dir_path='new_classifier_mg/', labels = major_group)\n","    #run the loading model function with broad category classification\n","    broad_category_label, broad_category_prob = load_model(dir_path='new_classifier_bc/', labels = broad_cat)\n","    \n","    return major_group_label, major_group_prob, broad_category_label, broad_category_prob"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vi_9fxt87mfY","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"xplY14HV7mfY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SupGopb7mfa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZk4LM6k7mfd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wP-Ww-Gn7mff","colab_type":"text"},"source":["# Test the API"]},{"cell_type":"code","metadata":{"id":"cm9DQsWm7mff","colab_type":"code","colab":{}},"source":["# preparing test dataset\n","#we will test 10 samples\n","df_UCF_test=pd.concat([pd.read_pickle('test/df_ucf_test.pkl.gz', compression='gzip')],ignore_index=True)\n","df_UCF_test = df_UCF_test.sample(10)\n","df_UCF_test['input']= df_UCF_test['TAXPAYER_NAME']+' '+df_UCF_test['mission_spellchk']+' '+df_UCF_test['prgrm_dsc_spellchk']\n","string_input = df_UCF_test.input.values\n","\n","#prepare labels\n","broad_cat_dict={'I': ['A'],\n","                'II': ['B'],\n","                'III': ['C', 'D'],\n","                'IV': ['E', 'F', 'G', 'H'],\n","                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n","                'VI': ['Q'],\n","                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n","                'VIII': ['X'],\n","                'IX': ['Y'],\n","                'X': ['Z'],\n","               }\n","def ntee2cat(string):\n","    global broad_cat_dict\n","    return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n","#add true broad_cat labels to the test dataset\n","df_UCF_test['broad_cat']=df_UCF_test['NTEE1'].apply(ntee2cat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyjX2Cax7mfh","colab_type":"code","colab":{},"outputId":"06dfc4b0-3647-45af-d341-31184daaeb53"},"source":["major_group_label, major_group_prob, broad_category_label, broad_category_prob = npoclass(string_input)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["No GPU available, using the CPU instead.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 445.29it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["  Prediction took: 0:00:01\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 443.59it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["  Prediction took: 0:00:01\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7PD-85wO7mfk","colab_type":"code","colab":{},"outputId":"3ca1bfff-398c-4415-e0d6-3c047718712f"},"source":["print('broad category_label:', broad_category_label)\n","print('broad category probability:', broad_category_prob)\n","print('major_group_label:', major_group_label)\n","print('major_group_probability:', major_group_prob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["broad category_label: ['V' 'II' 'V' 'I' 'V' 'VII' 'V' 'VII' 'II' 'I']\n","broad category probability: [0.12579422 0.01758762 0.09651593 0.03289149 0.00776044 0.17845915\n"," 0.11803251 0.16834667 0.11491693 0.13969506]\n","major_group_label: ['K' 'B' 'M' 'A' 'A' 'S' 'J' 'W' 'B' 'A']\n","major_group_probability: [0.05267935 0.00246418 0.03420285 0.00445164 0.00111741 0.20181774\n"," 0.03183997 0.25103763 0.1722936  0.24809568]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ipqI8ekW7mfm","colab_type":"code","colab":{},"outputId":"231d40b9-e600-4a20-a339-7d4767934010"},"source":["#see true broad category labels\n","df_UCF_test['broad_cat'].values\n","#got one prediction wrong"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['V', 'III', 'V', 'I', 'V', 'VII', 'V', 'VII', 'II', 'I'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"aBMiE6HF7mfo","colab_type":"code","colab":{}},"source":["t_major=pd.DataFrame([major_group_label, major_group_prob]).T.rename(columns={0:'pred', 1:'prob'})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIVk2JJh7mfq","colab_type":"code","colab":{},"outputId":"b4c9e258-1a72-469c-812a-51bc1cec191c"},"source":["t_major"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pred</th>\n","      <th>prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>K</td>\n","      <td>0.0526793</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>0.00246418</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M</td>\n","      <td>0.0342029</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A</td>\n","      <td>0.00445164</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A</td>\n","      <td>0.00111741</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>S</td>\n","      <td>0.201818</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>J</td>\n","      <td>0.03184</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>W</td>\n","      <td>0.251038</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>B</td>\n","      <td>0.172294</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>A</td>\n","      <td>0.248096</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  pred        prob\n","0    K   0.0526793\n","1    B  0.00246418\n","2    M   0.0342029\n","3    A  0.00445164\n","4    A  0.00111741\n","5    S    0.201818\n","6    J     0.03184\n","7    W    0.251038\n","8    B    0.172294\n","9    A    0.248096"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"VEdCVD6I7mfs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SG5WPHgG7mfu","colab_type":"code","colab":{},"outputId":"be4f5885-1e16-4740-e04c-9c2664ca19f3"},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pred</th>\n","      <th>pro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>S</td>\n","      <td>0.0681582</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>S</td>\n","      <td>0.162789</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E</td>\n","      <td>0.095232</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E</td>\n","      <td>0.0291983</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","      <td>0.164544</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>E</td>\n","      <td>0.0182485</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>B</td>\n","      <td>0.18929</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>C</td>\n","      <td>0.0552726</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>A</td>\n","      <td>0.211201</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>X</td>\n","      <td>0.00606566</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  pred         pro\n","0    S   0.0681582\n","1    S    0.162789\n","2    E    0.095232\n","3    E   0.0291983\n","4    M    0.164544\n","5    E   0.0182485\n","6    B     0.18929\n","7    C   0.0552726\n","8    A    0.211201\n","9    X  0.00606566"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"id":"PMs-9e7I7mfw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTst7CHr7mfx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPvH_8ln7mfz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBZXPg7A7mf1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiGuD5kQ7mf3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SqyKYlA7mf7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}