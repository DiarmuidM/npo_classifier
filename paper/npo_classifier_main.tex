\documentclass[12pt]{article}
\usepackage[style=apa]{biblatex}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{lipsum}
\usepackage[symbol]{footmisc}
\usepackage{graphicx}
\usepackage[capposition=top]{floatrow}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{bibentry}
\usepackage[letterpaper, left=1in,top=1in,right=1in,bottom=1in]{geometry}
\usepackage{setspace}
\usepackage{epstopdf}
\usepackage{amssymb}
\usepackage{lineno}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{array}
\usepackage{color,soul}
\usepackage{tabularx}
\usepackage{rotating}
\usepackage{lscape}
\usepackage{subcaption}
\usepackage{longtable}
\usepackage{siunitx}
\usepackage{appendix}
\usepackage{pdfpages}
\usepackage{titlesec}
\usepackage{mfirstuc}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{color,soul}
\usepackage{todonotes}

\renewcommand{\baselinestretch}{1.5}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\bibliography{../reference/classification.bib}
\setcounter{tocdepth}{2}


\title{\textbf{\capitalisewords{Classification of nonprofit organizations: A supervised machine-learning approach}}}
\author{%
\textsc{Ji Ma and Isha Kanani} \thanks{J.M.: maji@austin.utexas.edu, LBJ School of Public Affairs and RGK Center for Philanthropy and Community Service; I.K.: ishakanani@utexas.edu, School of Information.} \\[1ex] % Your name \thanks{}
\normalsize University of Texas at Austin \\ % Your institution
% \normalsize {Email: maji@austin.utexas.edu} \\ % Your email address
}


\date{\today} % Leave empty to omit a date \today

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

\begin{abstract}
\noindent This research note reports the use of supervised machine-learning algorithms in classifying the nonprofit organizations in the United States. Mission statements and project descriptions are collected from the 990 forms as text data, and classifications using National Taxonomy of Exempt Entities are collected from the National Center for Charitable Statistics at the Urban Institute. Three text classification algorithms are experimented: Na\"ive Bayes, Random Forest, and Neural Network. The Neural Network classification achieves the best results with an average accuracy of 9*.9\% (standard deviation **), recall *** (standard deviation **), and precision *** (SD **). An open-source Python package \textit{npocat} is developed and shared using the trained algorithms. Future projects are discussed.

% The National Taxonomy of Exempt Entities (NTEE) has been used for classifying the nonprofit organizations in the United States for several decades. However, major countries in the world do not have a classification system for the nonprofit sector. This paper achieves three major goals: 1) devising a machine learning model which can classify the nonprofits using mission statements, 2) inventing a functional classification system which can be applied to different countries, 3) test the accuracy of the model and classification system. We first created a classification system cross different countries by matching existing standards, then compiled the training and testing datasets for China (data from China Foundation Center and Research Infrastructure of Chinese Foundations), United Kingdom (data from ****), and United States (data from National Center for Charitable Statistics and Internal Revenue Service). We finally test the accuracy of major text classification algorithms using country-specific training datasets and a pooled dataset. Implications and limitations are discussed.
\end{abstract}
\clearpage

\listoftodos
\clearpage

\section{Introduction}

Although the voluntary and philanthropic organizations have long been existent for numerous centuries, the so-called ``nonprofit sector'' was only coined in the 1970s by scholars, policy makers, and nonprofit practitioners \parencite{HallHistoricalOverviewPhilanthropy2006}. A major reason for assembling the diverse organizations as a conceptual whole is to legitimize the existence of these organizations and the benefits these organizations receive \parencite{HallHistoricalOverviewPhilanthropy2006,BarmanClassificatoryStrugglesNonprofit2013}. From Durkheim's \citeyear{DurkheimElementaryFormsReligious2012} perspective, the order and structure of a society can be reflected by a classification system. The National Taxonomy of Exempt Entities (NTEE) developed by the National Center for Charitable Statistics (NCCS), the most widely used classification system, is one of the efforts legitimizing the existence of nonprofit sector \parencite{Hodgkinsonnewresearchplanning1991,HodgkinsonMappingnonprofitsector1990}. As \textcite[105]{BarmanClassificatoryStrugglesNonprofit2013} cite \textcite[601]{ClarkeSimpleTechnologyComplex1996}: ``The ways in which different entities (people, animals, plants, diseases, etc.) are organized into classificatory groups reveal something of the social, cultural, symbolic, and political contexts within which classifications occur.''
\todo[inline]{NTEE practical use \parencite{Hodgkinsonnewresearchplanning1991,HodgkinsonMappingnonprofitsector1990}.}

The development of NTEE classifications can date back to the 1980s. 
\todo[inline]{Brief history and introduction of NTEE.}
\parencites{HodgkinsonMappingnonprofitsector1990}[16]{NationalCenterforCharitableStatisticsGuideUsingNCCS2006}

The NTEE classifications has been used for numerous practical and academic purposes. For example, it provides a framework on which the social and economic activities of nonprofits can be mapped and compared with other types of organizations in a society \parencite[e.g.,][]{RoegerNonprofitSectorIts2015}. Scholars also use NTEE codes for sampling purposes \parencite[e.g.,][]{OktenDeterminantsdonationsprivate2000,CarmanEvaluationCapacityNonprofit2010} or as independent variables \parencite{SloanEffectsNonprofitAccountability2009}. The invention of an international classification system, although challenging, can be the cornerstone for studying ``global civil society'' \parencite{VakilConfrontingclassificationproblem1997,Salamonsearchnonprofitsector1992,Salamoninternationalclassificationnonprofit1996}.

The NTEE classification system, although one of the best we have, still has several major drawbacks. First, because it only assign one major category code to an organization, it cannot accurately describe a nonprofit organization's programs which are usually diverse and across several domains \parencite[303]{GronbjergUsingNTEEclassify1994}. Although another classification system assigning purpose codes to programs was developed \parencite{LampkinIntroducingNonprofitProgram2001}, it is not widely used \hl{(why?)}. Second, the assignment of NTEE codes is not complete because it is ``based on an assessment of program descriptions contained in Parts 3 and 8 of the Form 990'' and ``program descriptions were only available for some organizations'' \parencite[16]{NationalCenterforCharitableStatisticsGuideUsingNCCS2006}. A recent study found the number of organizations in Washington State with a specific NTEE code could be significantly increased if the mission statements were used for coding \parencite{FyallNTEECodesOpportunities2018}. Third, NTEE codes are static but nonprofit organizations' activities may change over time. Recoding existent NTEE assignments is extremely onerous for human.
\todo[inline]{NTEE limitations: \textcite{Salamonsearchnonprofitsector1992}.}

\todo[inline]{Contribution of this study.}

% By using supervised machine-learning techniques, this study advanced the NTEE classification system from the following perspective: 1) A series of datasets for training models was developed, 2) the accuracy and efficiency of popular text-classification algorithms were compared, 3) existent empirical studies were replicated to test the validity of our machine-learning approach. According to the results of experimentation, validation, and replication, the combination of \hl{\textit{ABC} algorithm} and trained datasets produced the best results.

\section{Method}

\subsection{Working with Texts and Research Workflow}

The classification of texts is a typical task of automatic content analysis, and three types of methods are common to this task: dictionary, supervised, and unsupervised methods \parencite[268-269]{GrimmerTextDataPromise2013}. The dictionary methods use a predefined dictionary of words to classifying the texts. Although accurate, this approach is not capable to deal with the variations and contexts of language. An improved solution is to use supervised methods which are computer algorithms that can ``learn'' the linguistic patters in a dataset classified by human coders. Unlike the dictionary and supervised methods which require predefined categories of interest, unsupervised methods can discover linguistic patters in texts without inputting any knowledge of classification. However, the validity of unsupervised methods is a serious challenge because the classifications returned may not be theoretically meaningful. This study employs supervised methods to make the use of existing classifications and human-coded records and deal with linguistic variations and contexts. 

\todo[inline]{Research workflow.}


\subsection{Datasets and Sampling}

There are two types of datasets for supervised text classification: training dataset and testing dataset. Both datasets are collections of text records that have been classified by human coders. The machine-learning algorithms can ``learn'' the linguistic patters from the training dataset and then classify the records in testing dataset using the patters learned. The results generated by algorithms can be compared with those coded by human coders, and ultimate goal is to use trained models to replace human. The quality of training dataset is decisive because it must be a representative sample of the whole corpus. The training dataset can be generated by randomly sampling the whole corpus, but a better strategy is proportional sampling according to the distribution of classification scheme \parencite[278]{GrimmerTextDataPromise2013}.

\subsubsection{Text Data}
\todo[inline]{How NTEE codes are assigned: by whom according to what? Where to obtain text data?}
\parencites{HodgkinsonMappingnonprofitsector1990}[16]{NationalCenterforCharitableStatisticsGuideUsingNCCS2006}

\subsubsection{Classification Data}
BMF file. 

\subsubsection{Sampling}
\todo[inline]{Why and how to do the bootstrap sampling \parencite[596]{Erceg-HurnModernrobuststatistical2008}.}
NTEE classification confidence rating (A/B/C).


Figure \ref{fig:NTEE_dist} shows the proportions of NTEE major categories from 1989 to 2015 ... 
\todo[inline]{Figures or tables describing the patterns of datasets.}

\subsection{Machine-Learning Algorithms}
\todo[inline]{Introduction to the algorithms.}

This study uses three supervised machine-learning classification algorithms: Na\"ive Bayes, Random Forest, and Neural Network. Other than these three individual methods, an ensemble approach that combines all the three models is also experimented. 

\subsubsection{Na\"ive Bayes Classification}

Na\"ive Bayes Classification is a machine learning algorithm that works on probabilistic approach. Given a set of features, this classifier predicts the class with the highest probability of the feature set. The algorithm is primarily built on Baye\'s theorem.

$$ P(A \mid B) = \frac{P(B \mid A) \, P(A)}{P(B)} $$

Baye\'s theorem gives probability of the occurrence of class A, while B is provided. B here is subset of all parameters. Baye\'s theorem assumes all parameters to be independent of each other, it simply follows principles of conditional probability.

In the context of text classification: The classifier depends on bags of word representation, which consists of all important words for classification and their frequency. In training data set, each "text" is converted to bag of word, and given as an input along with it's "label" {need to define text and label to use it throughout the paper}. For testing purpose, the classifier is given a bag of words and asked to predict the label with the highest probability for given set.

\subsubsection{Random Forest Classification}

Random forest classifier consists of a group of decision trees. Each decision tree is trained with unique subset of the training set. During the prediction, each forest predicts the class of the input on it's own and the final class predicted is derived from predictions of all decision trees.

\subsubsection{Neural Network Classification}

Intro and mechanism.

\subsection{Measuring Algorithm Performance}

The performance of a classification algorithm can be measured by {accuracy}, {precision}, and {recall}. The \textit{accuracy} measures the percentage of correctly classified organizations as showed in Eq. \ref{accuracy}, where $i$ is one of the three classification algorithms (i.e., NB, RF, and NN), $Org^{correct}$ is the number of organizations correctly classified by the algorithm $i$, and $Org^{total}$ is the total organizations to be classified. For example, $Accuracy^{RF}=0.6$ indicates that, when RF classifies an organization, the chance of getting right is 60\%.

\begin{equation} \label{accuracy}
    Accuracy^i=\frac{Org^{correct}}{Org^{total}}
\end{equation}

The \textit{precision} and \textit{recall} measures the performance of a classifier on a specific category. In Eq. \ref{precision}, $k$ is one of the NTEE codes, $Org^{correct}_{k}$ is the number of organizations correctly classified as $k$ by algorithm $i$, and ${Org^{i}_{k}}$ is the number of organizations classified as $k$ by algorithm $i$. $Org^{correct}_{k}$ will always be smaller than or equal to ${Org^{i}_{k}}$ because ML algorithms can hardly predict everything right. For example, $Precision^{NN}_{B}=0.75$ indicates that 75\% of all the organizations classified as ``education'' by the NN algorithm are correct.

\begin{equation} \label{precision}
    Precision^{i}_{k}=\frac{Org^{correct}_{k}}{Org^{i}_{k}}
\end{equation}

Given a human coder labels an organization as category \textit{k}, the \textit{recall} measures the chance the classifier \textit{i} also identifies the organization as \textit{k}. In Eq. \ref{recall}, $Org^{hum}_{k}$ is the number of organizations that has been classified as $k$ by human coders. For example, $Recall^{NN}_{B}=0.80$ denotes that 80\% of the organizations classified as ``education'' by human coders are correctly identified by the NN algorithm.

\begin{equation} \label{recall}
    Recall^{i}_{k}=\frac{Org^{correct}_{k}}{Org^{hum}_{k}}
\end{equation}


\section{Results}

\subsection{Confusion Matrix}

% \subsection{Applying the International Nonprofit Classification System: Descriptive analysis}
% \subsection{Applying the International Nonprofit Classification System: Replication of empirical studies}


\singlespacing
\printbibliography

\end{document}